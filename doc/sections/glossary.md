# Glossary for GFT (General Fine-Tuning)

<ol>

<li id="#Adapter"> Adapter </li>

<li id="#ASR"> Automatic Speech Recognition (<i>aka</i> ASR, ctc) </li>

<li id="#Arguments"> Arguments to functions (see <a href="arguments/arguments.md">list of arguments</a>)</li>

<li id="#Benchmark"> Benchmark: a part of a dataset; we will refer to the GLUE dataset as consisting of a number of benchmarks: COLA, MNLI, QQP, etc.</li>

<li id="#Checkpoint"> Checkpoint</li>

<li id="#Classify"> Data (<i>aka</i> text-classification) </li>

<li id="#Configuration"> Configuration: we will avoid the use of this term since is refers to many different things in different contexts </li>

<li id="#Data"> Data (<i>aka</i> dataset): datasets consist of three splits.  Each split consists of a list of rows.  Rows have columns such as input features (such as: text, question) and output features (such as labels) </li>

<li id="#Equation"> Equation (<i>aka</i> eqn) </li>

<li id="#Evaluation"> Evaluation (<i>aka</i> eval) </li>

<li id="#Function"> Function </li>

<li id="#Fit"> Fit </li>

<li id="#Hyperparameter"> Hyperparameter: Hyperparameter tuning can improve performance considerably.  The most important hyperparameters are batch size, learning rate and stopping rules (number of epochs) </li>

<li id="#Metric"> Metric </li>

<li id="#Model"> Model </li>

<li id="#Predict"> Predict </li>

<li id="#Regress"> Regress (<i>aka</i> regression) </li>

<li id="#Split"> Split : one of three splits</li>

<li id="#Splits"> Splits: typically train, validation and test. </li>

<li id="#Summary"> Summary </li>

<li id="#Task"> Task </li>

</ol>
