# dataset: id --> 0 models
# dataset: acronym_identification --> 0 models
# dataset: ade_corpus_v2 --> 3 models
ade_corpus_v2	jsylee/scibert_scivocab_uncased-finetuned-ner
ade_corpus_v2	abhibisht89/spanbert-large-cased-finetuned-ade_corpus_v2
ade_corpus_v2	anindabitm/sagemaker-BioclinicalBERT-ADR
# dataset: adversarial_qa --> 0 models
# dataset: aeslc --> 0 models
# dataset: afrikaans_ner_corpus --> 0 models
# dataset: ag_news --> 7 models
ag_news	mrm8488/bert-mini-finetuned-age_news-classification
ag_news	nateraw/bert-base-uncased-ag-news
ag_news	joeddav/distilbert-base-uncased-agnews-student
ag_news	andi611/distilbert-base-uncased-ner-agnews
ag_news	lucasresck/bert-base-cased-ag-news
ag_news	mrm8488/distilroberta-finetuned-age_news-classification
ag_news	fabriceyhc/bert-base-uncased-ag_news
# dataset: ai2_arc --> 1 models
ai2_arc	LIAMF-USP/aristo-roberta
# dataset: air_dialogue --> 0 models
# dataset: ajgt_twitter_ar --> 0 models
# dataset: allegro_reviews --> 0 models
# dataset: allocine --> 1 models
allocine	cmarkea/distilcamembert-base-sentiment
# dataset: alt --> 0 models
# dataset: amazon_polarity --> 1 models
amazon_polarity	fabriceyhc/bert-base-uncased-amazon_polarity
# dataset: amazon_reviews_multi --> 46 models
amazon_reviews_multi	cmarkea/distilcamembert-base-sentiment
amazon_reviews_multi	lewtun/xlm-roberta-base-finetuned-marc
amazon_reviews_multi	lewtun/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	philschmid/distilbert-base-multilingual-cased-sentiment
amazon_reviews_multi	philschmid/distilbert-base-multilingual-cased-sentiment-2
amazon_reviews_multi	milyiyo/electra-base-gen-finetuned-amazon-review
amazon_reviews_multi	begar/xlm-roberta-base-finetuned-marc
amazon_reviews_multi	Giannipinelli/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	milyiyo/selectra-small-finetuned-amazon-review
amazon_reviews_multi	IsabellaKarabasz/roberta-base-bne-finetuned-amazon_reviews_multi
amazon_reviews_multi	Krassy/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	Lazaro97/results
amazon_reviews_multi	Hormigo/roberta-base-bne-finetuned-amazon_reviews_multi
amazon_reviews_multi	TomO/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	Yuri/xlm-roberta-base-finetuned-marc
amazon_reviews_multi	lewtun/xlm-roberta-base-finetuned-marc-en-hslu
amazon_reviews_multi	arjuntheprogrammer/distilbert-base-multilingual-cased-sentiment-2
amazon_reviews_multi	mateocolina/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	milyiyo/electra-small-finetuned-amazon-review
amazon_reviews_multi	Pratibha/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	Proggleb/roberta-base-bne-finetuned-amazon_reviews_multi
amazon_reviews_multi	laurauzcategui/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	lewtun/roberta-base-bne-finetuned-amazon_reviews_multi
amazon_reviews_multi	nepalprabin/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	ashish-chouhan/xlm-roberta-base-finetuned-marc
amazon_reviews_multi	claudio75/xlm-roberta-base-finetuned-marc
amazon_reviews_multi	d4niel92/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	yokonav/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	anditya/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	fjluque/roberta-base-bne-finetuned-amazon_reviews_multi
amazon_reviews_multi	lewtun/roberta-base-bne-finetuned-amazon_reviews_multi-finetuned-amazon_reviews_multi
amazon_reviews_multi	lewtun/xlm-roberta-base-finetuned-marc-de
amazon_reviews_multi	lewtun/xlm-roberta-base-finetuned-marc-en-dummy
amazon_reviews_multi	daveccampbell/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	jx88/xlm-roberta-base-finetuned-marc-en-j-run
amazon_reviews_multi	milyiyo/distilbert-base-uncased-finetuned-amazon-review
amazon_reviews_multi	milyiyo/multi-minilm-finetuned-amazon-review
amazon_reviews_multi	ninahrostozova/xlm-roberta-base-finetuned-marc
amazon_reviews_multi	shaer/xlm-roberta-base-finetuned-marc-en-test-run
amazon_reviews_multi	tkesonia/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	csalamea/roberta-base-bne-finetuned-amazon_reviews_multi
amazon_reviews_multi	danwilbury/xlm-roberta-base-finetuned-marc-en
amazon_reviews_multi	hackertec/roberta-base-bne-finetuned-amazon_reviews_multi-taller
amazon_reviews_multi	hackertec/roberta-base-bne-finetuned-amazon_reviews_multi
amazon_reviews_multi	pgperrone/roberta-base-bne-finetuned-amazon_reviews_multi
amazon_reviews_multi	reza/xlm-roberta-base-finetuned-marc-en
# dataset: amazon_us_reviews --> 0 models
# dataset: ambig_qa --> 0 models
# dataset: americas_nli --> 0 models
# dataset: ami --> 6 models
ami	pyannote/segmentation
ami	pyannote/voice-activity-detection
ami	pyannote/speaker-diarization
ami	pyannote/speaker-segmentation
ami	pyannote/overlapped-speech-detection
ami	ami-wav2vec2/wav2vec2-base-ami_single-vumichien
# dataset: amttl --> 0 models
# dataset: anli --> 8 models
anli	ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli
anli	vicgalle/xlm-roberta-large-xnli-anli
anli	MoritzLaurer/xtremedistil-l6-h256-mnli-fever-anli-ling-binary
anli	MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli
anli	MoritzLaurer/DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary
anli	AdapterHub/bert-base-uncased-pf-anli_r3
anli	usc-isi/sbert-roberta-large-anli-mnli-snli
anli	AdapterHub/roberta-base-pf-anli_r3
# dataset: app_reviews --> 0 models
# dataset: aqua_rat --> 0 models
# dataset: aquamuse --> 0 models
# dataset: ar_cov19 --> 0 models
# dataset: ar_res_reviews --> 0 models
# dataset: ar_sarcasm --> 0 models
# dataset: arabic_billion_words --> 10 models
arabic_billion_words	qarib/bert-base-qarib
arabic_billion_words	flax-community/arabic-t5-small
arabic_billion_words	jhu-clsp/roberta-large-eng-ara-128k
arabic_billion_words	qarib/bert-base-qarib60_860k
arabic_billion_words	qarib/bert-base-qarib60_1970k
arabic_billion_words	qarib/bert-base-qarib60_1790k
arabic_billion_words	qarib/bert-base-qarib_far_6500k
arabic_billion_words	qarib/bert-base-qarib_far_8280k
arabic_billion_words	qarib/bert-base-qarib_far_9920k
arabic_billion_words	qarib/bert-base-qarib_far
# dataset: arabic_pos_dialect --> 0 models
# dataset: arabic_speech_corpus --> 5 models
arabic_speech_corpus	elgeish/wav2vec2-large-xlsr-53-arabic
arabic_speech_corpus	jonatasgrosman/wav2vec2-large-xlsr-53-arabic
arabic_speech_corpus	elgeish/wav2vec2-large-xlsr-53-levantine-arabic
arabic_speech_corpus	mohammed/wav2vec2-large-xlsr-arabic
arabic_speech_corpus	mohammed/ar
# dataset: arcd --> 2 models
arcd	salti/bert-base-multilingual-cased-finetuned-squad
arcd	salti/AraElectra-base-finetuned-ARCD
# dataset: arsentd_lev --> 0 models
# dataset: art --> 2 models
art	AdapterHub/bert-base-uncased-pf-art
art	AdapterHub/roberta-base-pf-art
# dataset: arxiv_dataset --> 1 models
arxiv_dataset	Callidior/bert2bert-base-arxiv-titlegen
# dataset: ascent_kb --> 0 models
# dataset: aslg_pc12 --> 0 models
# dataset: asnq --> 0 models
# dataset: asset --> 0 models
# dataset: assin --> 0 models
# dataset: assin2 --> 0 models
# dataset: atomic --> 0 models
# dataset: autshumato --> 0 models
# dataset: babi_qa --> 0 models
# dataset: banking77 --> 4 models
banking77	philschmid/BERT-Banking77
banking77	mrm8488/distilroberta-finetuned-banking77
banking77	philschmid/DistilBERT-Banking77
banking77	philschmid/RoBERTa-Banking77
# dataset: bbaw_egyptian --> 0 models
# dataset: bbc_hindi_nli --> 0 models
# dataset: bc2gm_corpus --> 0 models
# dataset: beans --> 8 models
beans	nickmuchi/vit-base-beans
beans	nateraw/vit-base-beans
beans	nateraw/vit-base-beans-demo
beans	nateraw/vit-base-beans-demo-v3
beans	nateraw/resnet50-beans-dummy-sagemaker
beans	nateraw/timm-resnet18-beans-test
beans	nateraw/vit-base-beans-demo-v2
beans	nateraw/timm-resnet18-beans-test-2
# dataset: best2009 --> 0 models
# dataset: bianet --> 0 models
# dataset: bible_para --> 1 models
bible_para	mrm8488/mbart-large-finetuned-bible-es-en-translation
# dataset: big_patent --> 1 models
big_patent	google/bigbird-pegasus-large-bigpatent
# dataset: billsum --> 3 models
billsum	Frederick0291/t5-small-finetuned-billsum
billsum	stevhliu/t5-small-finetuned-billsum-ca_test
billsum	andrejmiscic/simcls-scorer-billsum
# dataset: bing_coronavirus_query_set --> 0 models
# dataset: biomrc --> 0 models
# dataset: biosses --> 0 models
# dataset: blbooks --> 0 models
# dataset: blbooksgenre --> 0 models
# dataset: blended_skill_talk --> 9 models
blended_skill_talk	facebook/blenderbot-400M-distill
blended_skill_talk	facebook/blenderbot_small-90M
blended_skill_talk	facebook/blenderbot-3B
blended_skill_talk	facebook/blenderbot-90M
blended_skill_talk	facebook/blenderbot-1B-distill
blended_skill_talk	hyunwoongko/reddit-3B
blended_skill_talk	hyunwoongko/blenderbot-9B
blended_skill_talk	hyunwoongko/reddit-9B
blended_skill_talk	sshleifer/bb3b-tok
# dataset: blimp --> 0 models
# dataset: blog_authorship_corpus --> 0 models
# dataset: bn_hate_speech --> 0 models
# dataset: bnl_newspapers --> 0 models
# dataset: bookcorpus --> 235 models
bookcorpus	bert-base-uncased
bookcorpus	distilbert-base-uncased
bookcorpus	roberta-base
bookcorpus	bert-base-cased
bookcorpus	roberta-large
bookcorpus	albert-base-v2
bookcorpus	distilbert-base-cased
bookcorpus	bert-large-uncased-whole-word-masking-finetuned-squad
bookcorpus	bert-large-uncased
bookcorpus	xlnet-base-cased
bookcorpus	google/bigbird-roberta-base
bookcorpus	bert-large-cased
bookcorpus	albert-base-v1
bookcorpus	bert-large-uncased-whole-word-masking
bookcorpus	funnel-transformer/small
bookcorpus	albert-xxlarge-v2
bookcorpus	funnel-transformer/medium
bookcorpus	bert-large-cased-whole-word-masking-finetuned-squad
bookcorpus	albert-large-v2
bookcorpus	google/canine-s
bookcorpus	xlnet-large-cased
bookcorpus	facebook/muppet-roberta-base
bookcorpus	google/bigbird-roberta-large
bookcorpus	albert-xxlarge-v1
bookcorpus	facebook/muppet-roberta-large
bookcorpus	albert-xlarge-v2
bookcorpus	bert-large-cased-whole-word-masking
bookcorpus	google/canine-c
bookcorpus	funnel-transformer/intermediate
bookcorpus	albert-large-v1
bookcorpus	albert-xlarge-v1
bookcorpus	funnel-transformer/small-base
bookcorpus	funnel-transformer/large
bookcorpus	funnel-transformer/xlarge
bookcorpus	funnel-transformer/medium-base
bookcorpus	Intel/bert-base-uncased-sparse-90-unstructured-pruneofa
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-0k
bookcorpus	funnel-transformer/large-base
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-20k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-140k
bookcorpus	Intel/bert-large-uncased-sparse-90-unstructured-pruneofa
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-40k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-120k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-160k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-100k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-200k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-180k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-300k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-60k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-80k
bookcorpus	mlcorelib/deberta-base-uncased
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-400k
bookcorpus	mlcorelib/debertav2-base-uncased
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-700k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-600k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-500k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-900k
bookcorpus	funnel-transformer/intermediate-base
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-800k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-1000k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-1100k
bookcorpus	Intel/bert-base-uncased-sparse-85-unstructured-pruneofa
bookcorpus	byeongal/bert-base-uncased
bookcorpus	Barytes/hellohf
bookcorpus	benyong/testmodel
bookcorpus	funnel-transformer/xlarge-base
bookcorpus	Mary222/made-ai-dungeon
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-1400k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-600k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-120k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-400k
bookcorpus	ayansinha/false-positives-scancode-bert-base-uncased-L8-1
bookcorpus	tftransformers/albert-base-v2
bookcorpus	tftransformers/bert-base-cased
bookcorpus	tftransformers/bert-large-cased
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-1300k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-1500k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-1600k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-1100k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-1600k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-300k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-200k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-80k
bookcorpus	ayansinha/lic-class-scancode-bert-base-cased-L32-1
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-1600k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-160k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-1700k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-300k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-400k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-100k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-1100k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-1200k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-1800k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-1300k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-1400k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-180k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-100k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-1700k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-2000k
bookcorpus	sramasamy8/testModel
bookcorpus	tftransformers/albert-base-v1
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-1200k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-1700k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-1900k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-1000k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-1100k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-1300k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-2000k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-200k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-11
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-17
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-19
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-0k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-1400k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-140k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-160k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-1900k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-400k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-40k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-600k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-60k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-800k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-900k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-120k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-1900k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-2000k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-200k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-40k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-800k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-80k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-900k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-1000k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-1200k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-140k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-160k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-1800k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-20k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-40k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-700k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-800k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-8
bookcorpus	tftransformers/bert-base-uncased
bookcorpus	tftransformers/bert-large-uncased-whole-word-masking
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-1800k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-2000k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-100k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-1200k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-120k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-140k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-1500k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-1800k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-180k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-500k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-700k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-10
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-12
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-14
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-1000k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-1500k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-1700k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-2000k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-300k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-500k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-80k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-20
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-21
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-23
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-1000k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-100k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-400k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-700k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-0k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-1300k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-1400k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-1500k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-1600k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-300k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-500k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-600k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-60k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-6
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-7
bookcorpus	flax-community/bigband
bookcorpus	tftransformers/albert-xlarge-v1
bookcorpus	tftransformers/albert-xlarge-v2
bookcorpus	tftransformers/albert-xxlarge-v1
bookcorpus	tftransformers/bert-large-cased-whole-word-masking
bookcorpus	tftransformers/bert-large-uncased
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-0-1400k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-0k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-1900k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-20k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-40k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-600k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-60k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-800k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-80k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-1-900k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-13
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-15
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-16
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-18
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-120k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-1300k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-1600k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-180k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-200k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-20k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-2-700k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-22
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-24
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-0k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-1200k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-140k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-1500k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-160k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-1700k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-1800k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-20k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-500k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-3-60k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-1100k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-180k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-1900k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-4-900k
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-5
bookcorpus	MultiBertGunjanPatrick/multiberts-seed-9
bookcorpus	kjackson/distilbert-base-uncased-finetuned-emotion
bookcorpus	matrix/test
bookcorpus	tftransformers/albert-xxlarge-v2
# dataset: bookcorpusopen --> 0 models
# dataset: boolq --> 3 models
boolq	AdapterHub/bert-base-uncased-pf-boolq
boolq	AdapterHub/roberta-base-pf-boolq
boolq	andi611/distilbert-base-uncased-qa-boolq
# dataset: bprec --> 0 models
# dataset: break_data --> 2 models
break_data	mrm8488/t5-base-finetuned-break_data
break_data	mrm8488/t5-base-finetuned-break_data-question-retrieval
# dataset: brwac --> 1 models
brwac	dlb/electra-base-portuguese-uncased-brwac
# dataset: bsd_ja_en --> 0 models
# dataset: bswac --> 0 models
# dataset: c3 --> 0 models
# dataset: c4 --> 213 models
c4	t5-small
c4	t5-base
c4	t5-large
c4	t5-3b
c4	google/t5-v1_1-large
c4	google/t5-v1_1-small
c4	google/t5-v1_1-base
c4	google/fnet-base
c4	google/t5-base-lm-adapt
c4	rinna/japanese-gpt-1b
c4	deepmind/language-perceiver
c4	google/t5-small-lm-adapt
c4	google/t5-large-lm-adapt
c4	t5-11b
c4	google/t5-v1_1-xl
c4	google/t5-xl-lm-adapt
c4	google/t5-large-ssm
c4	google/t5-large-ssm-nq
c4	fgaim/t5-small-squad-v2
c4	google/t5-small-ssm-nq
c4	google/t5-v1_1-xxl
c4	gustavecortal/fr-boris-8bit
c4	google/t5-xxl-lm-adapt
c4	Cedille/fr-boris
c4	sonoisa/t5-base-japanese-mC4-Wikipedia
c4	google/t5-xl-ssm-nq
c4	google/t5-small-ssm
c4	tftransformers/t5-small
c4	google/t5-efficient-large-nl36
c4	google/t5-efficient-small-nl16
c4	tftransformers/t5-base
c4	google/t5-efficient-large-nh24
c4	google/t5-efficient-large
c4	google/t5-efficient-tiny
c4	google/t5-efficient-xl
c4	google/fnet-large
c4	google/t5-efficient-base
c4	google/t5-efficient-small
c4	google/t5-efficient-base-nl24
c4	microsoft/ssr-base
c4	google/t5-efficient-tiny-nh1
c4	baffo32/t5-base-ptmap
c4	google/t5-efficient-small-nl24
c4	google/t5-efficient-small-nl32
c4	google/t5-11b-ssm-wq
c4	google/t5-xxl-ssm-nq
c4	google/t5-3b-ssm-nqo
c4	google/t5-3b-ssm
c4	google/t5-11b-ssm-tqa
c4	google/t5-efficient-large-dl8
c4	google/t5-11b-ssm-nq
c4	google/t5-efficient-base-nl4
c4	google/t5-efficient-small-el16
c4	google/t5-efficient-small-nl22
c4	google/t5-efficient-xl-nl12
c4	google/t5-efficient-xl-nl16
c4	seduerr/pai-tl
c4	google/t5-efficient-large-dm256
c4	google/t5-efficient-small-el48
c4	google/t5-efficient-xxl
c4	google/t5-11b-ssm
c4	google/t5-efficient-base-nl36
c4	google/t5-efficient-small-dm768
c4	google/t5-efficient-tiny-el2
c4	tau/t5-v1_1-large-rss
c4	google/t5-11b-ssm-nqo
c4	google/t5-3b-ssm-nq
c4	google/t5-efficient-small-el32
c4	google/t5-xxl-ssm-tqa
c4	seduerr/t5-small-pytorch
c4	tftransformers/t5-large
c4	google/t5-efficient-large-nh4
c4	google/t5-efficient-small-dl2
c4	google/t5-efficient-tiny-el8
c4	google/t5-xxl-ssm-wq
c4	google/t5-xxl-ssm-wqo
c4	google/t5-efficient-base-dl2
c4	google/t5-efficient-base-dl4
c4	google/t5-efficient-base-dl6
c4	google/t5-efficient-base-dl8
c4	google/t5-efficient-base-dm1000
c4	google/t5-efficient-base-el16
c4	google/t5-efficient-base-ff1000
c4	google/t5-efficient-base-ff12000
c4	google/t5-efficient-base-kv256
c4	google/t5-efficient-base-nh32
c4	google/t5-efficient-base-nl2
c4	google/t5-efficient-large-dl16
c4	google/t5-efficient-large-dl2
c4	google/t5-efficient-large-el2
c4	google/t5-efficient-large-kv256
c4	google/t5-efficient-large-nl2
c4	google/t5-efficient-mini-nl24
c4	google/t5-efficient-small-dl12
c4	google/t5-efficient-small-dl4
c4	google/t5-efficient-small-dm128
c4	google/t5-efficient-small-el8-dl4
c4	google/t5-efficient-small-el8
c4	google/t5-efficient-small-ff12000
c4	google/t5-efficient-small-ff9000
c4	google/t5-efficient-small-kv16
c4	google/t5-efficient-small-kv256
c4	google/t5-efficient-small-kv32
c4	google/t5-efficient-small-nl20
c4	google/t5-efficient-small-nl36
c4	google/t5-efficient-small-nl4
c4	google/t5-efficient-small-nl40
c4	google/t5-efficient-small-nl8
c4	google/t5-efficient-tiny-dl6
c4	google/t5-efficient-tiny-el12
c4	google/t5-efficient-tiny-ff12000
c4	google/t5-efficient-tiny-ff6000
c4	google/t5-efficient-tiny-ff9000
c4	google/t5-efficient-tiny-nh16
c4	google/t5-efficient-tiny-nh8
c4	google/t5-efficient-tiny-nl2
c4	google/t5-efficient-tiny-nl24
c4	google/t5-efficient-tiny-nl32
c4	google/t5-efficient-tiny-nl8
c4	google/t5-efficient-xl-nl2
c4	google/t5-efficient-xl-nl28
c4	google/t5-efficient-xl-nl6
c4	google/t5-large-ssm-nqo
c4	google/t5-xxl-ssm-tqao
c4	google/t5-efficient-base-dm2000
c4	google/t5-efficient-base-dm256
c4	google/t5-efficient-base-dm512
c4	google/t5-efficient-base-el2
c4	google/t5-efficient-base-el4
c4	google/t5-efficient-base-el6
c4	google/t5-efficient-base-el8
c4	google/t5-efficient-base-ff2000
c4	google/t5-efficient-base-ff6000
c4	google/t5-efficient-base-ff9000
c4	google/t5-efficient-base-kv128
c4	google/t5-efficient-base-kv16
c4	google/t5-efficient-base-kv32
c4	google/t5-efficient-base-nh16
c4	google/t5-efficient-base-nh24
c4	google/t5-efficient-base-nh8
c4	google/t5-efficient-base-nl16
c4	google/t5-efficient-base-nl32
c4	google/t5-efficient-base-nl40
c4	google/t5-efficient-base-nl48
c4	google/t5-efficient-base-nl8
c4	google/t5-efficient-large-dl12
c4	google/t5-efficient-large-dl32
c4	google/t5-efficient-large-dl4
c4	google/t5-efficient-large-dl6
c4	google/t5-efficient-large-dm128
c4	google/t5-efficient-large-dm2000
c4	google/t5-efficient-large-dm512
c4	google/t5-efficient-large-dm768
c4	google/t5-efficient-large-el12
c4	google/t5-efficient-large-el4
c4	google/t5-efficient-large-el6
c4	google/t5-efficient-large-el8
c4	google/t5-efficient-large-kv128
c4	google/t5-efficient-large-kv16
c4	google/t5-efficient-large-kv32
c4	google/t5-efficient-large-nh12
c4	google/t5-efficient-large-nh2
c4	google/t5-efficient-large-nh32
c4	google/t5-efficient-large-nh8-nl32
c4	google/t5-efficient-large-nh8
c4	google/t5-efficient-large-nl10
c4	google/t5-efficient-large-nl12
c4	google/t5-efficient-large-nl16
c4	google/t5-efficient-large-nl20
c4	google/t5-efficient-large-nl32
c4	google/t5-efficient-large-nl4
c4	google/t5-efficient-large-nl8
c4	google/t5-efficient-mini-nl12
c4	google/t5-efficient-mini-nl6
c4	google/t5-efficient-mini-nl8
c4	google/t5-efficient-mini
c4	google/t5-efficient-small-dl16
c4	google/t5-efficient-small-dl8
c4	google/t5-efficient-small-dm1000
c4	google/t5-efficient-small-dm2000
c4	google/t5-efficient-small-dm256
c4	google/t5-efficient-small-el12
c4	google/t5-efficient-small-el16-dl1
c4	google/t5-efficient-small-el16-dl2
c4	google/t5-efficient-small-el16-dl4
c4	google/t5-efficient-small-el16-dl8
c4	google/t5-efficient-small-el2
c4	google/t5-efficient-small-el4
c4	google/t5-efficient-small-el64
c4	google/t5-efficient-small-el8-dl1
c4	google/t5-efficient-small-el8-dl2
c4	google/t5-efficient-small-ff1000
c4	google/t5-efficient-small-ff3000
c4	google/t5-efficient-small-ff6000
c4	google/t5-efficient-small-kv128
c4	google/t5-efficient-small-nl2
c4	google/t5-efficient-small-nl48
c4	google/t5-efficient-tiny-dl2
c4	google/t5-efficient-tiny-dl8
c4	google/t5-efficient-tiny-el6
c4	google/t5-efficient-tiny-ff2000
c4	google/t5-efficient-tiny-ff3000
c4	google/t5-efficient-tiny-nh32
c4	google/t5-efficient-tiny-nl12
c4	google/t5-efficient-tiny-nl16
c4	google/t5-efficient-tiny-nl6
c4	google/t5-efficient-xl-nl4
c4	google/t5-efficient-xl-nl8
c4	google/t5-efficient-xxl-nl4
c4	google/t5-xxl-ssm-nqo
c4	google/t5-xxl-ssm
c4	google/t5-11b-ssm-tqao
c4	google/t5-11b-ssm-wqo
# dataset: cail2018 --> 0 models
# dataset: caner --> 0 models
# dataset: capes --> 0 models
# dataset: casino --> 0 models
# dataset: catalonia_independence --> 2 models
catalonia_independence	JonatanGk/roberta-base-bne-finetuned-catalonia-independence-detector
catalonia_independence	JonatanGk/roberta-base-ca-finetuned-catalonia-independence-detector
# dataset: cats_vs_dogs --> 5 models
cats_vs_dogs	nateraw/vit-base-cats-vs-dogs
cats_vs_dogs	nateraw/my-cool-timm-model-2
cats_vs_dogs	akahana/vit-base-cats-vs-dogs
cats_vs_dogs	ismgar01/vit-base-cats-vs-dogs
cats_vs_dogs	nateraw/my-cool-timm-model-3
# dataset: cawac --> 0 models
# dataset: cbt --> 0 models
# dataset: cc100 --> 15 models
cc100	rinna/japanese-roberta-base
cc100	sonoisa/t5-base-japanese
cc100	nlp-waseda/roberta-base-japanese
cc100	rinna/japanese-gpt2-medium
cc100	rinna/japanese-gpt-1b
cc100	rinna/japanese-gpt2-xsmall
cc100	rinna/japanese-gpt2-small
cc100	sonoisa/byt5-small-japanese
cc100	yellowback/gpt-neo-japanese-1.3B
cc100	jhu-clsp/roberta-large-eng-ara-128k
cc100	sonoisa/vl-t5-base-japanese
cc100	Andrija/SRoBERTa-F
cc100	amitness/nepbert
cc100	yohida/yoshida_gpt
cc100	Andrija/SRoBERTa-XL
# dataset: cc_news --> 3 models
cc_news	google/bigbird-roberta-base
cc_news	google/bigbird-roberta-large
cc_news	flax-community/bigband
# dataset: ccaligned_multilingual --> 0 models
# dataset: cdsc --> 0 models
# dataset: cdt --> 0 models
# dataset: cedr --> 1 models
cedr	cointegrated/rubert-tiny2-cedr-emotion-detection
# dataset: cfq --> 0 models
# dataset: chr_en --> 0 models
# dataset: cifar10 --> 6 models
cifar10	nateraw/vit-base-patch16-224-cifar10
cifar10	keras-io/supervised-contrastive-learning-cifar10
cifar10	keras-io/randaugment
cifar10	nielsr/vit-base-patch16-224-in21k-finetuned-cifar10
cifar10	michaelbenayoun/vit-base-beans
cifar10	keras-io/convmixer
# dataset: cifar100 --> 0 models
# dataset: circa --> 0 models
# dataset: civil_comments --> 0 models
# dataset: clickbait_news_bg --> 0 models
# dataset: climate_fever --> 0 models
# dataset: clinc_oos --> 15 models
clinc_oos	transformersbook/distilbert-base-uncased-distilled-clinc
clinc_oos	transformersbook/distilbert-base-uncased-finetuned-clinc
clinc_oos	abdelkader/distilbert-base-uncased-distilled-clinc
clinc_oos	paintingpeter/distilbert-base-uncased-distilled-clinc
clinc_oos	moshew/BERT-tiny-finetuned-clinc
clinc_oos	abdelkader/distilbert-base-uncased-finetuned-clinc
clinc_oos	hadxu/distilbert-base-uncased-finetuned-clinc
clinc_oos	arianpasquali/distilbert-base-uncased-finetuned-clinc
clinc_oos	moshew/BERT-small-finetuned-clinc
clinc_oos	moshew/distilbert-base-uncased-finetuned-clinc
clinc_oos	moshew/BERT-miny-finetuned-clinc
clinc_oos	moshew/BERT-small-distilled-clinc
clinc_oos	moshew/BERT-tiny-distilled-clinc
clinc_oos	paintingpeter/distilbert-base-uncased-finetuned-clinc
clinc_oos	msavel-prnt/distilbert-base-uncased-finetuned-clinc
# dataset: clue --> 0 models
# dataset: cmrc2018 --> 0 models
# dataset: cmu_hinglish_dog --> 0 models
# dataset: cnn_dailymail --> 47 models
cnn_dailymail	sshleifer/distilbart-cnn-6-6
cnn_dailymail	sshleifer/distilbart-cnn-12-6
cnn_dailymail	sshleifer/distilbart-xsum-12-1
cnn_dailymail	sshleifer/distilbart-xsum-1-1
cnn_dailymail	plguillou/t5-base-fr-sum-cnndm
cnn_dailymail	microsoft/prophetnet-large-uncased-cnndm
cnn_dailymail	sshleifer/distilbart-xsum-12-6
cnn_dailymail	ainize/bart-base-cnn
cnn_dailymail	HHousen/distil-led-large-cnn-16384
cnn_dailymail	sshleifer/distilbart-xsum-12-3
cnn_dailymail	sshleifer/distilbart-cnn-12-3
cnn_dailymail	mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization
cnn_dailymail	deutsche-telekom/mt5-small-sum-de-en-v1
cnn_dailymail	kiri-ai/t5-base-qa-summary-emotion
cnn_dailymail	bochaowei/t5-small-finetuned-cnn-wei0
cnn_dailymail	bochaowei/t5-small-finetuned-cnn-wei1
cnn_dailymail	google/roberta2roberta_L-24_cnn_daily_mail
cnn_dailymail	philschmid/tf-distilbart-cnn-12-6
cnn_dailymail	flax-community/t5-base-cnn-dm
cnn_dailymail	sshleifer/distilbart-xsum-6-6
cnn_dailymail	T-Systems-onsite/mt5-small-sum-de-en-v2
cnn_dailymail	patrickvonplaten/bert2bert_cnn_daily_mail
cnn_dailymail	Ayham/roberta_gpt2_summarization_cnn_dailymail
cnn_dailymail	sshleifer/distilbart-xsum-9-6
cnn_dailymail	Ayham/albert_gpt2_summarization_cnndm
cnn_dailymail	philippelaban/keep_it_simple
cnn_dailymail	philippelaban/summary_loop46
cnn_dailymail	Ayham/bert_distilgpt2_summarization_cnn_dailymail
cnn_dailymail	mrm8488/bert-mini2bert-mini-finetuned-cnn_daily_mail-summarization
cnn_dailymail	Ayham/bert_gpt2_summarization_cnndm
cnn_dailymail	flax-community/t5-base-dutch-demo
cnn_dailymail	philippelaban/summary_loop10
cnn_dailymail	andrejmiscic/simcls-scorer-cnndm
cnn_dailymail	mrm8488/roberta-med-small2roberta-med-small-finetuned-cnn_daily_mail-summarization
cnn_dailymail	Ayham/distilbert_distilgpt2_summarization_cnn_dailymail
cnn_dailymail	philippelaban/summary_loop24
cnn_dailymail	Ayham/roberta_roberta_summarization_cnn_dailymail
cnn_dailymail	echarlaix/bart-base-cnn-r2-19.4-d35-hybrid
cnn_dailymail	Ayham/xlnet_gpt2_summarization_cnn_dailymail
cnn_dailymail	Ayham/bert_bert_summarization_cnn_dailymail
cnn_dailymail	Ayham/albert_distilgpt2_summarization_cnn_dailymail
cnn_dailymail	Ayham/xlnet_distilgpt2_summarization_cnn_dailymail
cnn_dailymail	Ayham/distilbert_gpt2_summarization_cnndm
cnn_dailymail	Ayham/roberta_distilgpt2_summarization_cnn_dailymail
cnn_dailymail	Ayham/xlmroberta_large_gpt2_summarization_cnndm
cnn_dailymail	Ayham/albert_gpt2_Full_summarization_cnndm
cnn_dailymail	echarlaix/bart-base-cnn-r2-18.7-d23-hybrid
# dataset: coached_conv_pref --> 0 models
# dataset: coarse_discourse --> 0 models
# dataset: codah --> 0 models
# dataset: code_search_net --> 13 models
code_search_net	huggingface/CodeBERTa-small-v1
code_search_net	Salesforce/codet5-base
code_search_net	huggingface/CodeBERTa-language-id
code_search_net	Salesforce/codet5-small
code_search_net	Salesforce/codet5-base-multi-sum
code_search_net	dbernsohn/roberta-java
code_search_net	flax-sentence-embeddings/st-codesearch-distilroberta-base
code_search_net	dbernsohn/roberta-javascript
code_search_net	dbernsohn/roberta-go
code_search_net	tals/roberta_python
code_search_net	dbernsohn/roberta-python
code_search_net	dbernsohn/roberta-php
code_search_net	SaulLu/cotet5_small_fix
# dataset: code_x_glue_cc_clone_detection_big_clone_bench --> 0 models
# dataset: code_x_glue_cc_clone_detection_poj104 --> 0 models
# dataset: code_x_glue_cc_cloze_testing_all --> 0 models
# dataset: code_x_glue_cc_cloze_testing_maxmin --> 0 models
# dataset: code_x_glue_cc_code_completion_line --> 0 models
# dataset: code_x_glue_cc_code_completion_token --> 0 models
# dataset: code_x_glue_cc_code_refinement --> 0 models
# dataset: code_x_glue_cc_code_to_code_trans --> 0 models
# dataset: code_x_glue_cc_defect_detection --> 0 models
# dataset: code_x_glue_ct_code_to_text --> 2 models
code_x_glue_ct_code_to_text	stmnk/codet5-small-code-summarization-python
code_x_glue_ct_code_to_text	nielsr/codet5-small-code-summarization-ruby
# dataset: code_x_glue_tc_nl_code_search_adv --> 0 models
# dataset: code_x_glue_tc_text_to_code --> 0 models
# dataset: code_x_glue_tt_text_to_text --> 0 models
# dataset: com_qa --> 2 models
com_qa	AdapterHub/bert-base-uncased-pf-comqa
com_qa	AdapterHub/roberta-base-pf-comqa
# dataset: common_gen --> 3 models
common_gen	mrm8488/t5-base-finetuned-common_gen
common_gen	mrm8488/GPT-2-finetuned-common_gen
common_gen	gagan3012/k2t-new
# dataset: common_language --> 4 models
common_language	anton-l/wav2vec2-base-lang-id
common_language	ivanlau/language-detection-fine-tuned-on-xlm-roberta-base
common_language	anton-l/sew-mid-100k-ft-common-language
common_language	anton-l/distilhubert-ft-common-language
# dataset: common_voice --> 520 models
common_voice	facebook/wav2vec2-large-xlsr-53
common_voice	facebook/wav2vec2-xls-r-300m
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-english
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-russian
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-german
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-spanish
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn
common_voice	facebook/wav2vec2-large-xlsr-53-french
common_voice	facebook/wav2vec2-large-xlsr-53-spanish
common_voice	facebook/wav2vec2-large-robust-ft-swbd-300h
common_voice	facebook/wav2vec2-xls-r-1b
common_voice	Rajaram1996/wav2vec2-large-xlsr-53-tamil
common_voice	ydshieh/wav2vec2-large-xlsr-53-chinese-zh-cn-gpt
common_voice	voidful/wav2vec2-xlsr-multilingual-56
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-japanese
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-french
common_voice	facebook/wav2vec2-large-robust
common_voice	elgeish/wav2vec2-large-xlsr-53-arabic
common_voice	KBLab/wav2vec2-large-voxrex-swedish
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-italian
common_voice	m3hrdadfi/wav2vec2-large-xlsr-turkish
common_voice	lighteternal/wav2vec2-large-xlsr-53-greek
common_voice	imvladikon/wav2vec2-large-xlsr-53-hebrew
common_voice	patrickvonplaten/wav2vec2-large-xlsr-53-spanish-with-lm
common_voice	facebook/wav2vec2-large-robust-ft-libri-960h
common_voice	airesearch/wav2vec2-large-xlsr-53-th
common_voice	facebook/wav2vec2-xlsr-53-espeak-cv-ft
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-portuguese
common_voice	ctl/wav2vec2-large-xlsr-cantonese
common_voice	facebook/wav2vec2-large-xlsr-53-german
common_voice	Zaid/wav2vec2-large-xlsr-53-arabic-egyptian
common_voice	sakares/wav2vec2-large-xlsr-thai-demo
common_voice	m3hrdadfi/wav2vec2-large-xlsr-persian
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-dutch
common_voice	jonatasgrosman/wav2vec2-large-english
common_voice	anton-l/wav2vec2-large-xlsr-53-russian
common_voice	facebook/wav2vec2-large-xlsr-53-italian
common_voice	m3hrdadfi/wav2vec2-large-xlsr-persian-v3
common_voice	voidful/wav2vec2-large-xlsr-53-tw-gpt
common_voice	facebook/wav2vec2-xls-r-1b-21-to-en
common_voice	lgris/wav2vec2-large-xlsr-open-brazilian-portuguese
common_voice	facebook/wav2vec2-large-xlsr-53-dutch
common_voice	facebook/fastspeech2-en-200_speaker-cv4
common_voice	anuragshas/wav2vec2-large-xlsr-53-vietnamese
common_voice	maxidl/wav2vec2-large-xlsr-german
common_voice	lgris/wav2vec2-large-xlsr-open-brazilian-portuguese-v2
common_voice	facebook/tts_transformer-ru-cv7_css10
common_voice	facebook/wav2vec2-xls-r-2b
common_voice	facebook/wav2vec2-xls-r-1b-en-to-15
common_voice	boris/xlsr-en-punctuation
common_voice	jiobiala24/wav2vec2-base-checkpoint-10
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-polish
common_voice	skylord/wav2vec2-large-xlsr-hindi
common_voice	flozi00/wav2vec2-large-xlsr-53-german-with-lm
common_voice	microsoft/unispeech-large-1500h-cv
common_voice	facebook/wav2vec2-lv-60-espeak-cv-ft
common_voice	cahya/wav2vec2-base-turkish-artificial-cv
common_voice	anton-l/wav2vec2-large-xlsr-53-tatar
common_voice	ttop324/wav2vec2-live-japanese
common_voice	KBLab/wav2vec2-large-xlsr-53-swedish
common_voice	facebook/tts_transformer-zh-cv7_css10
common_voice	facebook/tts_transformer-en-200_speaker-cv4
common_voice	shahukareem/wav2vec2-large-xlsr-53-dhivehi
common_voice	shiwangi27/wave2vec2-large-xlsr-hindi
common_voice	gmihaila/wav2vec2-large-xlsr-53-romanian
common_voice	facebook/wav2vec2-xls-r-300m-21-to-en
common_voice	Galuh/wav2vec2-large-xlsr-indonesian
common_voice	facebook/tts_transformer-fr-cv7_css10
common_voice	facebook/wav2vec2-xls-r-300m-en-to-15
common_voice	dragonSwing/wav2vec2-base-vn-270h
common_voice	facebook/wav2vec2-xls-r-2b-22-to-16
common_voice	vneralla/xlrs-53-finnish
common_voice	flozi00/wav2vec-xlsr-german
common_voice	facebook/tts_transformer-vi-cv7
common_voice	NTQAI/wav2vec2-large-japanese
common_voice	speechbrain/asr-crdnn-commonvoice-fr
common_voice	cahya/wav2vec2-base-turkish-artificial
common_voice	facebook/tts_transformer-tr-cv7
common_voice	glob-asr/wav2vec2-xls-r-300m-spanish-large-LM
common_voice	vumichien/wav2vec2-large-xlsr-japanese-hiragana
common_voice	vumichien/wav2vec2-large-xlsr-japanese
common_voice	GleamEyeBeast/Mandarin
common_voice	arampacha/wav2vec2-xls-r-1b-uk
common_voice	saattrupdan/wav2vec2-xls-r-300m-cv8-da
common_voice	jiobiala24/wav2vec2-base-checkpoint-12
common_voice	patrickvonplaten/wav2vec2-xlsr-53-es-kenlm
common_voice	birgermoell/lm-swedish
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-hungarian
common_voice	microsoft/unispeech-large-multi-lingual-1500h-cv
common_voice	jonatasgrosman/wav2vec2-large-fr-voxpopuli-french
common_voice	joorock12/wav2vec2-large-xlsr-italian
common_voice	speechbrain/asr-crdnn-commonvoice-it
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-arabic
common_voice	facebook/tts_transformer-ar-cv7
common_voice	lgris/bp400-xlsr
common_voice	marcel/wav2vec2-large-xlsr-53-german
common_voice	facebook/wav2vec2-large-xlsr-53-portuguese
common_voice	robinhad/wav2vec2-xls-r-300m-uk
common_voice	Baybars/wav2vec2-xls-r-300m-cv8-turkish
common_voice	m3hrdadfi/wav2vec2-large-xlsr-persian-v2
common_voice	edugp/wav2vec2-xls-r-300m-36-tokens-es
common_voice	ccoreilly/wav2vec2-large-100k-voxpopuli-catala
common_voice	mpoyraz/wav2vec2-xls-r-300m-cv6-turkish
common_voice	w11wo/wav2vec2-xls-r-300m-zh-HK-lm-v2
common_voice	Rubens/Wav2Vec2-Large-XLSR-53-Portuguese
common_voice	Amrrs/wav2vec2-large-xlsr-53-tamil
common_voice	MehdiHosseiniMoghadam/wav2vec2-large-xlsr-53-Czech
common_voice	azuur/wav2vec2-base-gn-demo
common_voice	KBLab/wav2vec2-large-voxpopuli-sv-swedish
common_voice	ayameRushia/wav2vec2-large-xls-r-300m-id
common_voice	indonesian-nlp/wav2vec2-large-xlsr-indonesian
common_voice	samitizerxu/wav2vec2-xls-r-300m-zh-CN
common_voice	facebook/wav2vec2-xls-r-2b-21-to-en
common_voice	jiobiala24/wav2vec2-base-checkpoint-11.1
common_voice	indonesian-nlp/wav2vec2-luganda
common_voice	jhonparra18/wav2vec2-large-xls-r-300m-spanish-custom
common_voice	comodoro/wav2vec2-xls-r-300m-cs
common_voice	reichenbach/wav2vec2-large-xls-r-300m-pa-in
common_voice	w11wo/wav2vec2-xls-r-300m-zh-HK-v2
common_voice	gabrieljg/wav2vec2-common_voice-es-demo
common_voice	reichenbach/wav2vec2-large-xls-r-300m-hi
common_voice	facebook/wav2vec2-large-xlsr-53-polish
common_voice	manifoldix/xlsr-fa-lm
common_voice	samitizerxu/wav2vec2-xls-r-300m-es
common_voice	ozcangundes/wav2vec2-large-xlsr-53-turkish
common_voice	lgris/sew-tiny-portuguese-cv
common_voice	akashsivanandan/wav2vec2-large-xls-r-300m-tamil-colab-final
common_voice	anuragshas/wav2vec2-xls-r-300m-mr-cv8-with-lm
common_voice	edugp/wav2vec2-xls-r-300m-36-tokens-with-lm-es
common_voice	facebook/wav2vec2-xls-r-2b-en-to-15
common_voice	microsoft/unispeech-1350-en-353-fr-ft-1h
common_voice	shahukareem/wav2vec2-large-xlsr-53-dhivehi-v2
common_voice	Gerasimos/wav2vec2-large-xls-r-300m-greek
common_voice	hgharibi/wav2vec2-xls-r-300m-fa-colab
common_voice	MehdiHosseiniMoghadam/wav2vec2-large-xlsr-53-Dutch
common_voice	RuudVelo/wav2vec2-large-xls-r-300m-nl
common_voice	cahya/wav2vec2-large-xlsr-turkish
common_voice	cahya/wav2vec2-base-turkish-cv8
common_voice	mobedkova/wav2vec2-large-xls-r-300m-ru-test
common_voice	joorock12/wav2vec2-large-xlsr-portuguese
common_voice	speechbrain/asr-crdnn-commonvoice-de
common_voice	comodoro/wav2vec2-xls-r-300m-pl-cv8
common_voice	Ilyes/wav2vec2-large-xlsr-53-french_punctuation
common_voice	emre/wav2vec2-xls-r-300m-Russian-small
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-finnish
common_voice	reach-vb/wav2vec2-large-xls-r-1B-common_voice7-lv-ft
common_voice	vachonni/wav2vec2-large-xls-r-300m-dansk-CV-80
common_voice	anton-l/wav2vec2-large-xlsr-53-ukrainian
common_voice	PereLluis13/Wav2Vec2-Large-XLSR-53-catalan
common_voice	anuragshas/wav2vec2-large-xlsr-53-rm-vallader
common_voice	samitizerxu/wav2vec2-xls-r-300m-eo
common_voice	lgris/bp500-xlsr
common_voice	pcuenq/wav2vec2-large-xlsr-53-es
common_voice	techiaith/wav2vec2-xlsr-ft-cy
common_voice	saattrupdan/alvenir-wav2vec2-base-cv8-da
common_voice	shivam/wav2vec2-xls-r-300m-hindi
common_voice	DrishtiSharma/wav2vec2-large-xls-r-300m-or-dx12
common_voice	cahya/wav2vec2-base-turkish-cv7
common_voice	mattchurgin/xls-r-eng
common_voice	AndrewMcDowell/wav2vec2-xls-r-1b-japanese-hiragana-katakana
common_voice	cahya/wav2vec2-large-xlsr-turkish-artificial-cv
common_voice	gagan3012/wav2vec2-xlsr-nepali
common_voice	mrm8488/wav2vec2-large-xlsr-53-spanish
common_voice	reichenbach/wav2vec2-large-xls-r-300m-as
common_voice	nouamanetazi/wav2vec2-xls-r-300m-ar
common_voice	maher13/arabic-iti
common_voice	samitizerxu/wav2vec2-xls-r-300m-lg
common_voice	w11wo/wav2vec2-xls-r-300m-zh-HK-lm-v3
common_voice	Saitomar/wav2vec2-large-xls-r-300m-hindi-kaggle
common_voice	tugstugi/wav2vec2-large-xlsr-53-mongolian
common_voice	arampacha/wav2vec2-xls-r-1b-hy
common_voice	arampacha/wav2vec2-xls-r-300m-hy
common_voice	comodoro/wav2vec2-xls-r-300m-sk-cv8
common_voice	mvip/wav2vec2-large-xls-r-300m-tr
common_voice	reach-vb/wav2vec2-large-xls-r-1B-common_voice-sl-ft
common_voice	shivam/xls-r-300m-hindi
common_voice	anantoj/wav2vec2-xls-r-300m-zh-CN
common_voice	birgermoell/wav2vec2-large-xlsr-finnish
common_voice	patrickvonplaten/wav2vec2-xls-r-phoneme-300m-sv
common_voice	Rubens/Wav2Vec2-Large-XLSR-53-a-Portuguese
common_voice	ccoreilly/wav2vec2-large-xlsr-catala
common_voice	softcatala/wav2vec2-large-100k-voxpopuli-catala
common_voice	arampacha/wav2vec2-xls-r-1b-ka
common_voice	emre/wav2vec2-large-xlsr-53-W2V2-TATAR-SMALL
common_voice	glob-asr/wav2vec2-large-xls-r-300m-spanish-small
common_voice	manandey/wav2vec2-large-xlsr-tamil
common_voice	mrm8488/wav2vec2-large-xlsr-53-ukrainian
common_voice	aapot/wav2vec2-large-xlsr-53-finnish
common_voice	anuragshas/wav2vec2-xls-r-1b-hi-cv8
common_voice	ghofrani/common6
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-greek
common_voice	joorock12/wav2vec2-large-xlsr-portuguese-a
common_voice	w11wo/wav2vec2-xls-r-300m-zh-HK
common_voice	chompk/wav2vec2-large-xlsr-thai-tokenized
common_voice	gagan3012/wav2vec2-xlsr-chuvash
common_voice	jiobiala24/wav2vec2-base-checkpoint-8
common_voice	lgris/bp500-base10k_voxpopuli
common_voice	patrickvonplaten/wav2vec2-xls-r-phoneme-300m-tr
common_voice	samitizerxu/wav2vec2-xls-r-300m-fr
common_voice	shivam/xls-r-hindi
common_voice	HarrisDePerceptron/xls-r-300m-ur-cv7
common_voice	KBLab/wav2vec2-base-voxpopuli-sv-swedish
common_voice	MehdiHosseiniMoghadam/wav2vec2-large-xlsr-53-French
common_voice	gagan3012/wav2vec2-xlsr-khmer
common_voice	leonardvorbeck/wav2vec2-large-robust-LS960
common_voice	Ilyes/wav2vec2-large-xlsr-53-french
common_voice	LegolasTheElf/Wav2Vec2_xls_r_300m_hi_cv7
common_voice	Nhut/wav2vec2-large-xlsr-french
common_voice	alexcleu/wav2vec2-large-xlsr-polish
common_voice	anuragshas/wav2vec2-large-xlsr-as
common_voice	azunre/wav2vec2large-xlsr-akan
common_voice	comodoro/wav2vec2-xls-r-300m-hsb-cv8
common_voice	flax-community/wav2vec2-spanish
common_voice	jhonparra18/wav2vec2-xls-r-300m-spanish-large-noLM
common_voice	kika2000/wav2vec2-large-xls-r-300m-kika4_my-colab
common_voice	m3hrdadfi/wav2vec2-large-xlsr-georgian
common_voice	manandey/wav2vec2-large-xlsr-punjabi
common_voice	microsoft/unispeech-1350-en-168-es-ft-1h
common_voice	patrickvonplaten/wav2vec2-common_voice-tr-demo
common_voice	scottykwok/wav2vec2-large-xlsr-cantonese
common_voice	Priyajay/xls-r-ab-test
common_voice	cahya/output
common_voice	dragonSwing/digits-recognizer
common_voice	glob-asr/base-spanish-asr
common_voice	jcmc/wav2vec2-large-xlsr-53-ir
common_voice	lgris/seasr_2022_base_10k_8khz_pt
common_voice	pere/xls-test
common_voice	birgermoell/wav2vec2-swedish-common-voice
common_voice	cahya/wav2vec2-large-xlsr-indonesian-mix
common_voice	harshit345/xlsr_wav2vec_english
common_voice	jonatasgrosman/wav2vec2-large-xlsr-53-persian
common_voice	lucio/wav2vec2-large-xlsr-luganda
common_voice	ajaiswal1008/wav2vec2-large-xls-r-300m-hi-colab_new
common_voice	ceyda/wav2vec2-large-xlsr-53-turkish
common_voice	chaitanya97/wav2vec2-large-xls-r-300m-hindi-colab
common_voice	emre/wav2vec2-large-xlsr-53-demo-colab
common_voice	emre/wav2vec2-xls-r-300m-Tr-med-CommonVoice8
common_voice	jhonparra18/wav2vec2-large-xls-r-300m-guarani-small
common_voice	qqhann/wav2vec2-large-xlsr-japanese-0325-1200
common_voice	GleamEyeBeast/Mandarin_naive
common_voice	HarrisDePerceptron/xls-r-300m-ur-cv8-hi
common_voice	anton-l/wav2vec2-large-xlsr-53-chuvash
common_voice	bayartsogt/wav2vec2-large-xlsr-mongolian
common_voice	emre/wav2vec2-xls-r-300m-Br-small
common_voice	jiobiala24/wav2vec2-base-checkpoint-9
common_voice	lgris/bp-commonvoice100-xlsr
common_voice	lgris/wav2vec2-large-xls-r-300m-pt-cv
common_voice	lucio/wav2vec2-large-xlsr-kinyarwanda
common_voice	marma/wav2vec2-large-xlsr-swedish
common_voice	microsoft/unispeech-1350-en-90-it-ft-1h
common_voice	mohammed/wav2vec2-large-xlsr-arabic
common_voice	nouamanetazi/wav2vec2-xls-r-300m-ar-with-lm
common_voice	othrif/wav2vec2-large-xlsr-arabic
common_voice	patrickvonplaten/wav2vec2-common_voice-tr-demo-dist
common_voice	Arnold/wav2vec2-large-xlsr-hausa2-demo-colab
common_voice	Maniac/wav2vec2-xls-r-60-urdu
common_voice	dragonSwing/wav2vec2-base-vietnamese
common_voice	dundar/wav2vec2-large-xlsr-53-turkish
common_voice	emre/wav2vec2-xls-r-300m-as-CV8-v1
common_voice	emre/wav2vec2-xls-r-300m-gl-CV8
common_voice	jejomi/xls-r-ta
common_voice	not-tanh/wav2vec2-large-xlsr-53-vietnamese
common_voice	ravishs/wav2vec2-large-xls-r-300m-tamil-colab
common_voice	vasilis/wav2vec2-large-xlsr-53-swedish
common_voice	Arnold/wav2vec2-hausa2-demo-colab
common_voice	Marxav/wav2vec2-large-xlsr-53-breton
common_voice	adresgezgini/wav2vec-tr-lite-AG
common_voice	anton-l/wav2vec2-large-xlsr-53-latvian
common_voice	ayameRushia/wav2vec2-large-xls-r-300m-japanese
common_voice	baaastien/xls-r-ab-test
common_voice	emre/wav2vec2-xls-r-300m-W2V2-XLSR-300M-YAKUT-SMALL
common_voice	gchhablani/wav2vec2-large-xlsr-hu
common_voice	inergi/wav2vec2-from-scratch-finetune-dummy
common_voice	jiobiala24/wav2vec2-base-checkpoint-7.1
common_voice	DrishtiSharma/wav2vec2-large-xls-r-300m-ab-v4
common_voice	Ilyes/wav2vec2-xls-fr
common_voice	LuisG07/wav2vec2-large-xlsr-53-spanish
common_voice	Mofe/speech-sprint-test
common_voice	Santiagot1105/wav2vec2-large-xlsr-finetune-es-Test
common_voice	Temur/wav2vec2-Georgian-Daytona
common_voice	chaitanya97/wav2vec2-large-xls-r-3
common_voice	chmanoj/xls-r-demo-test
common_voice	danurahul/wav2vec2-large-xlsr-or
common_voice	emre/wav2vec2-large-xlsr-53-sah-CV8
common_voice	emre/wav2vec2-xls-r-300m-ab-CV8
common_voice	flax-community/wav2vec2-dhivehi
common_voice	gchhablani/wav2vec2-large-xlsr-it
common_voice	gchhablani/wav2vec2-large-xlsr-or
common_voice	jimregan/wav2vec2-large-xlsr-irish-basic
common_voice	krirk/wav2vec2-large-xls-r-300m-turkish-colab
common_voice	leonardvorbeck/wav2vec2-large-robust-SB300
common_voice	m3hrdadfi/wav2vec2-large-xlsr-estonian
common_voice	mbsouksu/wav2vec2-large-xlsr-turkish-large
common_voice	patrickvonplaten/wav2vec2-large-xls-r-300m-common_voice-tr-ft
common_voice	patrickvonplaten/wav2vec2-xls-r-1b-common_voice-tr-ft
common_voice	simonsr/wav2vec2-large-xlsr-dutch
common_voice	softcatala/wav2vec2-large-xlsr-catala
common_voice	Baybars/wav2vec2-xls-r-1b-turkish
common_voice	DrishtiSharma/wav2vec2-xls-r-pa-IN-a1
common_voice	FitoDS/xls-r-ab-test
common_voice	Iskaj/newnew
common_voice	Priyajay/xls-r-kn-test
common_voice	addy88/wav2vec2-large-xls-r-300m-hindi-colab
common_voice	anton-l/wav2vec2-large-xlsr-53-mongolian
common_voice	anuragshas/wav2vec2-large-xlsr-53-dv
common_voice	anuragshas/wav2vec2-xlsr-53-tamil
common_voice	ayameRushia/wav2vec2-large-xls-r-300m-ar
common_voice	bharat-raghunathan/Tamil-Wav2Vec-xls-r-300m-Tamil-colab
common_voice	cahya/wav2vec2-large-xlsr-basque
common_voice	cahya/wav2vec2-large-xlsr-breton
common_voice	danurahul/wav2vec2-large-xlsr-pa-IN
common_voice	deepdml/output
common_voice	edugp/wav2vec2-xls-r-300m-cv8-es
common_voice	gchhablani/wav2vec2-large-xlsr-cnh
common_voice	gchhablani/wav2vec2-large-xlsr-ia
common_voice	gchhablani/wav2vec2-large-xlsr-pt
common_voice	gorkemgoknar/wav2vec2-large-xlsr-53-turkish
common_voice	harshit345/xlsr-53-wav2vec-greek
common_voice	iarfmoose/wav2vec2-large-xlsr-kyrgyz
common_voice	infinitejoy/Wav2Vec2-Large-XLSR-53-Tamil
common_voice	jiobiala24/wav2vec2-base-checkpoint-3
common_voice	kika2000/wav2vec2-large-xls-r-300m-kika_my-colab
common_voice	lgris/bp-voxforge1-xlsr
common_voice	manandey/wav2vec2-large-xlsr-_irish
common_voice	manandey/wav2vec2-large-xlsr-breton
common_voice	microsoft/unispeech-1350-en-17h-ky-ft-1h
common_voice	mrshu/wav2vec2-large-xlsr-slovene
common_voice	nouamanetazi/xls-r-ab-test
common_voice	patrickvonplaten/hello_2b_3
common_voice	patrickvonplaten/wav2vec2-common_voice-tamil
common_voice	rafiulrumy/wav2vec2-large-xlsr-53-demo-colab
common_voice	stefan-it/wav2vec2-large-xlsr-53-basque
common_voice	Iskaj/hf-challenge-test
common_voice	Mahalakshmi/wav2vec2-xls-r-300m-demo-colab
common_voice	MehdiHosseiniMoghadam/wav2vec2-large-xlsr-53-Georgian
common_voice	PereLluis13/wav2vec2-large-xlsr-53-greek
common_voice	Thanish/wav2vec2-large-xlsr-tamil
common_voice	anantoj/wav2vec2-xls-r-300m-zh-CN-lm
common_voice	anton-l/wav2vec2-large-xlsr-53-romanian
common_voice	anuragshas/wav2vec2-large-xlsr-53-ia
common_voice	anuragshas/wav2vec2-large-xlsr-53-odia
common_voice	anuragshas/wav2vec2-large-xlsr-53-sah
common_voice	anuragshas/wav2vec2-xlsr-53-pa-in
common_voice	arampacha/wav2vec2-xls-r-300m-hy-cv
common_voice	ayameRushia/wav2vec2-large-xls-r-300m-mn-2
common_voice	birgermoell/wav2vec2-large-xlrs-estonian
common_voice	birgermoell/wav2vec2-large-xlsr-hungarian
common_voice	cahya/wav2vec2-large-xlsr-indonesian
common_voice	chmanoj/xls-r-300m-sv
common_voice	cpierse/wav2vec2-large-xlsr-53-irish
common_voice	crang/wav2vec2-large-xlsr-53-tatar
common_voice	flax-community/wav2vec2-base-persian
common_voice	gagan3012/xls-r-300m-pa
common_voice	ghofrani/common7
common_voice	glob-asr/wav2vec2-large-xls-r-300m-guarani-small
common_voice	infinitejoy/Wav2Vec2-Large-XLSR-53-Assamese
common_voice	infinitejoy/Wav2Vec2-Large-XLSR-53-Odia
common_voice	ivangtorre/wav2vec2-large-xlsr-53-basque
common_voice	jcmc/wav2vec2-xls-r-1b-ir
common_voice	jfealko/wav2vec2-large-xls-r-300m-russian-colab
common_voice	joheras/xls-r-ab-spanish
common_voice	lgris/bp-cetuc100-xlsr
common_voice	lgris/bp-mls100-xlsr
common_voice	lgris/bp500-base100k_voxpopuli
common_voice	m3hrdadfi/wav2vec2-large-xlsr-lithuanian
common_voice	manandey/wav2vec2-large-xlsr-assamese
common_voice	manandey/wav2vec2-large-xlsr-estonian
common_voice	marcel/wav2vec2-large-xlsr-german-demo
common_voice	masapasa/xls-r-ab-test
common_voice	mrm8488/wav2vec2-large-xlsr-53-breton
common_voice	pablouribe/xls-r-ab-test
common_voice	patrickvonplaten/hello_2b
common_voice	pcuenq/wav2vec2-large-xlsr-53-eu
common_voice	rafiulrumy/wav2vec2-large-xlsr-hindi-demo-colab
common_voice	sammy786/wav2vec2-large-xlsr-mongolian
common_voice	tomascufaro/wav2vec2-large-xls-r-300m-spanish-custom
common_voice	tomascufaro/wav2vec2-large-xls-r-300m-spanish-small-v3
common_voice	tomascufaro/wav2vec2-large-xls-r-300m-spanish-small
common_voice	BSen/wav2vec2-large-xls-r-300m-turkish-colab
common_voice	DewiBrynJones/wav2vec2-large-xlsr-welsh
common_voice	Ilyes/wav2vec2-large-xlsr-53-french_BPE
common_voice	MehdiHosseiniMoghadam/wav2vec2-large-xlsr-53-Swedish
common_voice	StevenLimcorn/wav2vec2-xls-r-300m-zh-TW
common_voice	Tommi/wav2vec2-large-xlsr-53-finnish
common_voice	adilism/wav2vec2-large-xlsr-kyrgyz
common_voice	anton-l/wav2vec2-large-xlsr-53-kyrgyz
common_voice	anton-l/wav2vec2-large-xlsr-53-sakha
common_voice	anuragshas/wav2vec2-xls-r-300m-pa-IN-cv8-with-lm
common_voice	anuragshas/wav2vec2-xlsr-53-rm-vallader-with-lm
common_voice	ayameRushia/wav2vec2-large-xlsr-indonesia
common_voice	birgermoell/wav2vec2-common_voice-tr-demo
common_voice	cahya/wav2vec2-large-xlsr-indonesian-artificial
common_voice	ceyda/wav2vec2-base-760-turkish
common_voice	chaitanya97/wav2vec2-large-xls-r-300m-turkish-colab
common_voice	cpierse/wav2vec2-large-xlsr-53-esperanto
common_voice	csikasote/wav2vec2-large-xls-r-300m-turkish
common_voice	emeson77/wav2vec2-large-xls-r-300m-turkish-colab
common_voice	emre/wav2vec2-xls-r-300m-Turkish-Tr-med
common_voice	emre/wav2vec2-xls-r-300m-Turkish-Tr-small
common_voice	gagan3012/wav2vec2-large-xls-r-300m-hindi
common_voice	gagan3012/xls-r-300m-hi
common_voice	gchhablani/wav2vec2-large-xlsr-eo
common_voice	ghofrani/common8
common_voice	hf-test/xls-r-ab-test
common_voice	infinitejoy/wav2vec2-large-xls-r-300m-odia-cv8
common_voice	jimregan/wav2vec2-large-xls-r-300m-irish-colab
common_voice	jiobiala24/wav2vec2-base-checkpoint-1
common_voice	jiobiala24/wav2vec2-base-checkpoint-2
common_voice	jiobiala24/wav2vec2-base-checkpoint-6
common_voice	joorock12/model-sid-voxforge-cv-cetuc-0
common_voice	lgris/bp-commonvoice10-xlsr
common_voice	lgris/bp-lapsbm1-xlsr
common_voice	lgris/bp-tedx100-xlsr
common_voice	mohammed/ar
common_voice	naleraphael/rasr_sample
common_voice	nikhil6041/wav2vec2-large-xlsr-hindi-demo-colab
common_voice	nimrah/wav2vec2-large-xls-r-300m-hindi-colab
common_voice	nimrah/wav2vec2-large-xls-r-300m-my_hindi_presentation-colab
common_voice	nouamanetazi/wav2vec2-xls-r-300m-tr
common_voice	patrickvonplaten/wav2vec2-large-xls-r-300m-turkish-colab
common_voice	patrickvonplaten/wav2vec2-large-xlsr-53-common_voice-tr-ft
common_voice	patrickvonplaten/wav2vec2-large-xlsr-turkish-demo-colab
common_voice	patrickvonplaten/wav2vec2-xlarge-dotdotdot-common_voice-tr-demo
common_voice	project2you/wav2vec2-large-xlsr-53-demo-colab
common_voice	reach-vb/wav2vec2-large-xls-r-1B-common_voice7-lt-ft
common_voice	skylord/wav2vec2-large-xlsr-greek-1
common_voice	tonyalves/wav2vec2-300M-teste2
common_voice	tonyalves/wav2vec2-large-xls-r-300m-pt-colab
common_voice	wietsedv/wav2vec2-large-xlsr-53-dutch
common_voice	wietsedv/wav2vec2-large-xlsr-53-frisian
common_voice	xsway/wav2vec2-large-xlsr-georgian
common_voice	yerevann/x-r-hy
common_voice	Akashpb13/xlsr_maltese_wav2vec2
common_voice	Monsia/test-model-lg-data
common_voice	Siyam/wav2vec2-large-xls-r-300m-hindi-colab
common_voice	Subhashini17/wav2vec2-large-xls-r-300m-ta-colab-new1
common_voice	Subhashini17/wav2vec2-large-xls-r-300m-ta-colab
common_voice	aniltrkkn/wav2vec2-large-xlsr-53-turkish
common_voice	anton-l/wav2vec2-large-xlsr-53-hungarian
common_voice	anton-l/wav2vec2-large-xlsr-53-lithuanian
common_voice	anton-l/wav2vec2-large-xlsr-53-slovenian
common_voice	anuragshas/wav2vec2-large-xls-r-300m-ur
common_voice	anuragshas/wav2vec2-large-xlsr-53-hsb
common_voice	birgermoell/wav2vec2-luganda
common_voice	crang/wav2vec2-large-xlsr-53-frisian
common_voice	emre/wav2vec-tr-lite-AG
common_voice	emre/wav2vec2-large-xlsr-53-W2V2-TR-MED
common_voice	emre/wav2vec2-xls-r-300m-hy-AM-CV8-v1
common_voice	gagan3012/wav2vec2-xlsr-punjabi
common_voice	gchhablani/wav2vec2-large-xlsr-rm-sursilv
common_voice	iarfmoose/wav2vec2-large-xlsr-frisian
common_voice	iarfmoose/wav2vec2-large-xlsr-sorbian
common_voice	indonesian-nlp/wav2vec2-large-xlsr-indonesian-baseline
common_voice	infinitejoy/wav2vec2-large-xls-r-300m-indonesian
common_voice	jawaharreddy247/wav2vec2-large-xlsr-hindhi-demo-colab
common_voice	jimregan/wav2vec2-large-xlsr-latvian-cv
common_voice	jimregan/wav2vec2-large-xlsr-upper-sorbian-mixed
common_voice	jiobiala24/wav2vec2-base-checkpoint-5
common_voice	joorock12/wav2vec2-cv-coral-30ep
common_voice	juierror/wav2vec2-large-xls-r-thai-test
common_voice	kika2000/wav2vec2-large-xls-r-300m-kika10
common_voice	kmfoda/wav2vec2-large-xlsr-arabic
common_voice	lgris/bp-sid10-xlsr
common_voice	li666/wav2vec2-large-xls-r-300m-zh-CN-colab
common_voice	lilitket/wav2vec2-large-xls-r-300m-turkish-colab
common_voice	lucio/wav2vec2-large-xlsr-kinyarwanda-apostrophied
common_voice	manandey/wav2vec2-large-xlsr-mongolian
common_voice	masapasa/wav2vec2-large-xls-r-300m-turkish-colab
common_voice	mbien/wav2vec2-large-xlsr-polish
common_voice	mrm8488/wav2vec2-large-xlsr-53-esperanto
common_voice	mrm8488/wav2vec2-large-xlsr-53-euskera
common_voice	nikhil6041/wav2vec2-large-xlsr-hindi_commonvoice
common_voice	osyvokon/xslr-commonvoice
common_voice	patrickvonplaten/hello_2b_2
common_voice	patrickvonplaten/wav2vec2-large-xlsr-129-turkish-colab
common_voice	qqhann/w2v_hf_jsut_xlsr53
common_voice	rafiulrumy/wav2vec2-large-xlsr-hindi-demo-colab_2
common_voice	saied/wav2vec2-large-xls-r-300m-persian-colab
common_voice	seccily/wav2vec-lt-lite
common_voice	shiyue/wav2vec2-common_voice-tr-demo
common_voice	skylord/wav2vec2-large-xlsr-greek-2
common_voice	tonyalves/wav2vec2-300m-teste4
common_voice	vasilis/wav2vec2-large-xlsr-53-estonian
common_voice	voidful/wav2vec2-large-xlsr-53-hk
common_voice	AndrewMcDowell/wav2vec2-xls-r-1b-arabic
common_voice	Bharathdamu/wav2vec2-large-xls-r-300m-hindi-colab
common_voice	Bharathdamu/wav2vec2-large-xls-r-300m-hindi
common_voice	DeividasM/wav2vec2-large-xlsr-53-lithuanian
common_voice	DrishtiSharma/wav2vec2-large-xls-r-300m-as-with-LM-v2
common_voice	FarisHijazi/wav2vec2-large-xls-r-300m-turkish-colab
common_voice	MehdiHosseiniMoghadam/wav2vec2-large-xlsr-53-German
common_voice	Semih/wav2vec2_Irish_Large
common_voice	Wiam/wav2vec2-large-xlsr-arabic-demo-colab
common_voice	akashsivanandan/wav2vec2-large-xls-r-300m-tamil-colab
common_voice	anton-l/wav2vec2-large-xlsr-53-estonian
common_voice	anuragshas/wav2vec2-large-xls-r-300m-hi
common_voice	anuragshas/wav2vec2-large-xlsr-53-rm-sursilv
common_voice	artursz/wav2vec2-large-xls-r-300m-lv-v05
common_voice	ayameRushia/wav2vec2-large-xlsr-indo-base
common_voice	birgermoell/swedish-common-voice-vox-voxpopuli
common_voice	cahya/wav2vec2-large-xlsr-turkish-artificial
common_voice	ceyda/wav2vec2-large-xlsr-53-sakha
common_voice	dundar/wav2vec2-large-xlsr-53-lithuanian
common_voice	emre/wav2vec2-xls-r-300m-Tr-med-CommonVoice8-Tr-med-CommonVoice8
common_voice	emre/wav2vec2-xls-r-300m-Turkish-Tr-small-CommonVoice8
common_voice	jcmc/wav2vec-1b-cv8-ir-n
common_voice	jiobiala24/wav2vec2-base-checkpoint-4
common_voice	joorock12/wav2vec2-large-100k-voxpopuli-pt
common_voice	joorock12/wav2vec2-large-xlsr-53-spanish
common_voice	kika2000/wav2vec2-large-xls-r-300m-kika5_my-colab
common_voice	munggok/xlsr_indonesia
common_voice	nikhil6041/wav2vec2-large-xlsr-tamil-commonvoice
common_voice	nithinholla/wav2vec2-large-xlsr-53-dutch
common_voice	nvshubhsharma/wav2vec2-large-xlsr-hindi-colab
common_voice	patrickvonplaten/wav2vec2-xls-r-100m-common_voice-tr-ft
common_voice	skylord/greek_lsr_1
common_voice	sourabharsh/wav2vec2_10july
common_voice	zhichao158/wav2vec2-xls-r-common_voice-tr-ft
common_voice	shibli/wav2vec2-large-xls-r-300m-pun-colab
common_voice	jfealko/wav2vec2-large-xls-r-300m-russian-colab-localtest3
# dataset: commonsense_qa --> 5 models
commonsense_qa	AdapterHub/bert-base-uncased-pf-commonsense_qa
commonsense_qa	danlou/albert-xxlarge-v2-finetuned-csqa
commonsense_qa	danlou/aristo-roberta-finetuned-csqa
commonsense_qa	AdapterHub/roberta-base-pf-commonsense_qa
commonsense_qa	danlou/roberta-large-finetuned-csqa
# dataset: competition_math --> 1 models
competition_math	pszemraj/distill-pegasus-CompMath
# dataset: compguesswhat --> 0 models
# dataset: conceptnet5 --> 0 models
# dataset: conll2000 --> 4 models
conll2000	flair/chunk-english-fast
conll2000	flair/chunk-english
conll2000	AdapterHub/bert-base-uncased-pf-conll2000
conll2000	AdapterHub/roberta-base-pf-conll2000
# dataset: conll2002 --> 11 models
conll2002	pdelobelle/robbert-v2-dutch-base
conll2002	DTAI-KULeuven/robbertje-1-gb-bort
conll2002	DTAI-KULeuven/robbertje-1-gb-shuffled
conll2002	StivenLancheros/mBERT-base-cased-NER-CONLL
conll2002	DTAI-KULeuven/robbertje-1-gb-non-shuffled
conll2002	jirmauritz/robbert-v2-dutch-base
conll2002	StivenLancheros/bert-base-spanish-wwm-cased-finetuned-ner-false
conll2002	DTAI-KULeuven/robbertje-1-gb-merged
conll2002	dshvadskiy/bert-finetuned-ner
conll2002	StivenLancheros/roberta-base-bne-finetuned-ner-finetuned2-ner
conll2002	StivenLancheros/xlm-roberta-base-finetuned-ner-false
# dataset: conll2003 --> 118 models
conll2003	flair/ner-english
conll2003	dslim/bert-base-NER
conll2003	flair/ner-english-large
conll2003	flair/ner-german
conll2003	flair/ner-french
conll2003	flair/ner-dutch
conll2003	flair/ner-english-fast
conll2003	flair/ner-multi
conll2003	Jean-Baptiste/roberta-large-ner-english
conll2003	flair/ner-german-large
conll2003	elastic/distilbert-base-uncased-finetuned-conll03-english
conll2003	elastic/distilbert-base-cased-finetuned-conll03-english
conll2003	flair/ner-dutch-large
conll2003	flair/ner-spanish-large
conll2003	philschmid/distilroberta-base-ner-conll2003
conll2003	sberbank-ai/bert-base-NER-reptile-5-datasets
conll2003	huggingface-course/bert-finetuned-ner
conll2003	AdapterHub/roberta-base-pf-conll2003
conll2003	dominiqueblok/roberta-base-finetuned-ner
conll2003	AdapterHub/bert-base-uncased-pf-conll2003_pos
conll2003	AdapterHub/bert-base-uncased-pf-conll2003
conll2003	flair/ner-multi-fast
conll2003	ArBert/albert-base-v2-finetuned-ner
conll2003	brandon25/deberta-base-finetuned-ner
conll2003	dbmdz/t5-base-conll03-english
conll2003	julien-c/flair-de-ner
conll2003	merve/distilbert-base-uncased-finetuned-ner
conll2003	Jorgeutd/albert-base-v2-finetuned-ner
conll2003	StivenLancheros/mBERT-base-cased-NER-CONLL
conll2003	osanseviero/flair-ner-english
conll2003	vesteinn/XLMR-ENIS-finetuned-ner
conll2003	Jorgeutd/bert-large-uncased-finetuned-ner
conll2003	histinct7002/distilbert-base-uncased-finetuned-ner
conll2003	AdapterHub/roberta-base-pf-conll2003_pos
conll2003	andi611/bert-large-uncased-whole-word-masking-ner-conll2003
conll2003	vitvit/xlm-roberta-base-finetuned-ner
conll2003	andi611/bert-large-uncased-whole-word-masking-squad2-with-ner-conll2003-with-neg-with-repeat
conll2003	gagan3012/bert-tiny-finetuned-ner
conll2003	jatinshah/bert-finetuned-ner
conll2003	andi611/distilbert-base-uncased-squad2-with-ner-with-neg-with-multi-with-repeat
conll2003	ArBert/roberta-base-finetuned-ner-kmeans
conll2003	StivenLancheros/bert-base-multilingual-cased-finetuned-ner
conll2003	leonadase/distilbert-base-uncased-finetuned-ner
conll2003	nishmithaur/distilbert-base-uncased-finetuned-ner
conll2003	ramybaly/ner_conll2003
conll2003	Minowa/distilbert-base-uncased-finetuned-ner
conll2003	Shenyancheng/distilbert-base-uncased-finetuned-ner
conll2003	Vibharkchauhan/distilbert-base-uncased-finetuned-ner
conll2003	aidj/distilbert-base-uncased-finetuned-ner
conll2003	andi611/bert-large-uncased-whole-word-masking-squad2-with-ner-Pwhatisthe-conll2003-with-neg-with-repeat
conll2003	julien-c/flair-ner
conll2003	mackseem/distilbert-base-uncased-finetuned-ner
conll2003	xkang/bert-finetuned-ner
conll2003	StivenLancheros/bert-large-cased-finetuned-ner
conll2003	andi611/bert-large-uncased-ner-conll2003
conll2003	andi611/distilbert-base-uncased-ner-conll2003
conll2003	andi611/roberta-base-ner-conll2003
conll2003	hyerim/distilbert-base-uncased-finetuned-ner
conll2003	indridinn/distilbert-base-uncased-finetuned-ner
conll2003	ncduy/bert-finetuned-ner
conll2003	peterhsu/bert-finetuned-ner
conll2003	vitvit/XLMRFineTuneonEnglishNERFrozenBase
conll2003	Buntan/bert-finetuned-ner
conll2003	StivenLancheros/roberta-base-bne-finetuned-ner
conll2003	StivenLancheros/xlm-roberta-base-finetuned-ner-false-finetuned-ner-2002-1
conll2003	Tahsin/BERT-finetuned-conll2003-POS
conll2003	andi611/bert-base-cased-ner-conll2003
conll2003	brandon25/distilbert-base-uncased-finetuned-ner
conll2003	cogito233/distilbert-base-uncased-finetuned-ner
conll2003	delpart/distilbert-base-uncased-finetuned-ner
conll2003	mbateman/bert-finetuned-ner
conll2003	naram92/distilbert-base-uncased-finetuned-ner
conll2003	sarasarasara/sara-model
conll2003	ueb1/distilbert-base-uncased-finetuned-ner
conll2003	vitvit/XLMRFineTuneonEnglishNERFrozenBase30epochs
conll2003	Duc/distilbert-base-uncased-finetuned-ner
conll2003	Emmanuel/bert-finetuned-ner
conll2003	Evgeneus/distilbert-base-uncased-finetuned-ner
conll2003	SongRb/distilbert-base-uncased-finetuned-ner
conll2003	V3RX2000/distilbert-base-uncased-finetuned-ner
conll2003	Yv/bert-finetuned-ner
conll2003	al00014/distilbert-base-uncased-finetuned-ner
conll2003	andi611/bert-base-uncased-ner-conll2003
conll2003	andi611/distilbert-base-uncased-squad2-with-ner-with-neg-with-multi
conll2003	andi611/distilbert-base-uncased-squad2-with-ner-with-neg
conll2003	andi611/distilbert-base-uncased-squad2-with-ner
conll2003	cfisicaro/distilbert-base-uncased-finetuned-ner
conll2003	codingJacob/distilbert-base-uncased-finetuned-ner
conll2003	deval/distilbert-base-uncased-finetuned-ner
conll2003	gagan3012/distilbert-base-uncased-finetuned-ner
conll2003	jcai1/bert-finetuned-ner
conll2003	lewtun/bert-finetuned-ner
conll2003	malduwais/distilbert-base-uncased-finetuned-ner
conll2003	srosy/distilbert-base-uncased-finetuned-ner
conll2003	stefan-jo/bert-finetuned-ner
conll2003	zhihao/distilbert-base-uncased-finetuned-ner
conll2003	Ann2020/distilbert-base-uncased-finetuned-ner
conll2003	Fiddi/distilbert-base-uncased-finetuned-ner
conll2003	Hank/distilbert-base-uncased-finetuned-ner
conll2003	KamSut/distilbert-base-uncased-finetuned-ner
conll2003	SEISHIN/distilbert-base-uncased-finetuned-ner
conll2003	StivenLancheros/spanberta-base-cased-ner-conll02-finetuned-ner
conll2003	Wende/bert-finetuned-ner1
conll2003	adityavithaldas/distilbert-base-uncased-finetuned-ner
conll2003	andi611/bert-large-uncased-whole-word-masking-squad2-with-ner-Pistherea-conll2003-with-neg-with-repeat
conll2003	andi611/distilbert-base-uncased-qa-with-ner
conll2003	andi611/distilbert-base-uncased-squad2-with-ner-with-neg-with-repeat
conll2003	butchland/bert-finetuned-ner
conll2003	charlecheng/distilbert-base-uncased-finetuned-ner
conll2003	laurievb/distilbert-base-uncased-finetuned-ner
conll2003	momo/distilbert-base-uncased-finetuned-ner
conll2003	ncduy/distilbert-base-uncased-finetuned-ner
conll2003	peterhung/roberta-base-finetuned-pos
conll2003	prao/distilbert-base-uncased-finetuned-ner
conll2003	suwani/try_connll-finetuned-ner
conll2003	thomaszz/distilbert-base-uncased-finetuned-ner
conll2003	zald/distilbert-base-uncased-finetuned-ner
conll2003	spasis/bert-finetuned-ner
# dataset: conllpp --> 0 models
# dataset: consumer-finance-complaints --> 0 models
# dataset: conv_ai --> 0 models
# dataset: conv_ai_2 --> 0 models
# dataset: conv_ai_3 --> 0 models
# dataset: conv_questions --> 0 models
# dataset: coqa --> 1 models
coqa	kiri-ai/t5-base-qa-summary-emotion
# dataset: cord19 --> 2 models
cord19	jakelever/coronabert
cord19	malteos/aspect-cord19-scibert-scivocab-uncased
# dataset: cornell_movie_dialog --> 1 models
cornell_movie_dialog	Supiri/t5-base-conversation
# dataset: cos_e --> 0 models
# dataset: cosmos_qa --> 3 models
cosmos_qa	AdapterHub/bert-base-uncased-pf-cosmos_qa
cosmos_qa	mamlong34/t5_small_cosmos_qa
cosmos_qa	AdapterHub/roberta-base-pf-cosmos_qa
# dataset: counter --> 0 models
# dataset: covid_qa_castorini --> 0 models
# dataset: covid_qa_deepset --> 7 models
covid_qa_deepset	shaina/covid_qa_distillBert
covid_qa_deepset	abhijithneilabraham/longformer_covid_qa
covid_qa_deepset	juliusco/biobert-base-cased-v1.1-squad-finetuned-covbiobert
covid_qa_deepset	shainahub/covid_qa_distillbert
covid_qa_deepset	juliusco/distilbert-base-uncased-finetuned-squad
covid_qa_deepset	juliusco/distilbert-base-uncased-finetuned-covdistilbert
covid_qa_deepset	juliusco/biobert-base-cased-v1.1-squad-finetuned-covdrobert
# dataset: covid_qa_ucsd --> 0 models
# dataset: covid_tweets_japanese --> 0 models
# dataset: covost2 --> 25 models
covost2	facebook/s2t-wav2vec2-large-en-de
covost2	facebook/wav2vec2-xls-r-1b-21-to-en
covost2	facebook/wav2vec2-xls-r-1b-en-to-15
covost2	facebook/wav2vec2-xls-r-300m-21-to-en
covost2	facebook/wav2vec2-xls-r-300m-en-to-15
covost2	facebook/wav2vec2-xls-r-2b-22-to-16
covost2	facebook/xm_transformer_600m-es_en-multi_domain
covost2	facebook/s2t-small-covost2-en-de-st
covost2	facebook/wav2vec2-xls-r-2b-21-to-en
covost2	facebook/s2t-wav2vec2-large-en-ar
covost2	facebook/xm_transformer_600m-en_zh-multi_domain
covost2	facebook/wav2vec2-xls-r-2b-en-to-15
covost2	facebook/s2t-wav2vec2-large-en-ca
covost2	facebook/xm_transformer_600m-ru_en-multi_domain
covost2	facebook/s2t-small-covost2-fr-en-st
covost2	facebook/xm_transformer_600m-fr_en-multi_domain
covost2	facebook/s2t-wav2vec2-large-en-tr
covost2	facebook/s2t-small-covost2-es-en-st
covost2	facebook/s2t-small-covost2-en-fa-st
covost2	facebook/xm_transformer_600m-en_ar-multi_domain
covost2	facebook/s2t-small-covost2-en-ca-st
covost2	facebook/s2t-small-covost2-de-en-st
covost2	facebook/xm_transformer_600m-en_tr-multi_domain
covost2	facebook/s2t-small-covost2-ca-en-st
covost2	facebook/s2t-small-covost2-en-et-st
# dataset: cppe-5 --> 0 models
# dataset: craigslist_bargains --> 0 models
# dataset: crawl_domain --> 0 models
# dataset: crd3 --> 0 models
# dataset: crime_and_punish --> 0 models
# dataset: crows_pairs --> 0 models
# dataset: cryptonite --> 0 models
# dataset: cs_restaurants --> 0 models
# dataset: cuad --> 5 models
cuad	akdeniz27/roberta-base-cuad
cuad	marshmellow77/roberta-base-cuad
cuad	akdeniz27/deberta-v2-xlarge-cuad
cuad	akdeniz27/roberta-large-cuad
cuad	mrm8488/T5-base-finetuned-cuad
# dataset: curiosity_dialogs --> 0 models
# dataset: daily_dialog --> 1 models
daily_dialog	ethzanalytics/GPT-J-6B-8bit-Convo-D3E
# dataset: dane --> 2 models
dane	saattrupdan/nbailab-base-ner-scandi
dane	chcaa/da_dacy_large_trf
# dataset: danish_political_comments --> 0 models
# dataset: dart --> 0 models
# dataset: datacommons_factcheck --> 0 models
# dataset: dbpedia_14 --> 1 models
dbpedia_14	fabriceyhc/bert-base-uncased-dbpedia_14
# dataset: dbrd --> 6 models
dbrd	pdelobelle/robbert-v2-dutch-base
dbrd	DTAI-KULeuven/robbertje-1-gb-bort
dbrd	DTAI-KULeuven/robbertje-1-gb-shuffled
dbrd	DTAI-KULeuven/robbertje-1-gb-non-shuffled
dbrd	jirmauritz/robbert-v2-dutch-base
dbrd	DTAI-KULeuven/robbertje-1-gb-merged
# dataset: deal_or_no_dialog --> 0 models
# dataset: definite_pronoun_resolution --> 0 models
# dataset: dengue_filipino --> 0 models
# dataset: dialog_re --> 0 models
# dataset: diplomacy_detection --> 0 models
# dataset: disaster_response_messages --> 0 models
# dataset: discofuse --> 1 models
discofuse	google/roberta2roberta_L-24_discofuse
# dataset: discovery --> 0 models
# dataset: disfl_qa --> 0 models
# dataset: doc2dial --> 0 models
# dataset: docred --> 4 models
docred	nielsr/coref-bert-base
docred	nielsr/coref-bert-large
docred	nielsr/coref-roberta-large
docred	nielsr/coref-roberta-base
# dataset: doqa --> 0 models
# dataset: dream --> 0 models
# dataset: drop --> 3 models
drop	nielsr/nt5-small-rc1
drop	AdapterHub/bert-base-uncased-pf-drop
drop	AdapterHub/roberta-base-pf-drop
# dataset: duorc --> 4 models
duorc	AdapterHub/bert-base-uncased-pf-duorc_s
duorc	AdapterHub/bert-base-uncased-pf-duorc_p
duorc	AdapterHub/roberta-base-pf-duorc_p
duorc	AdapterHub/roberta-base-pf-duorc_s
# dataset: dutch_social --> 0 models
# dataset: dyk --> 0 models
# dataset: e2e_nlg --> 0 models
# dataset: e2e_nlg_cleaned --> 0 models
# dataset: ecb --> 0 models
# dataset: ecthr_cases --> 0 models
# dataset: eduge --> 0 models
# dataset: ehealth_kd --> 0 models
# dataset: eitb_parcc --> 0 models
# dataset: electricity_load_diagrams --> 0 models
# dataset: eli5 --> 3 models
eli5	yjernite/bart_eli5
eli5	Madhour/gpt2-eli5
eli5	pszemraj/t5-base-askscience
# dataset: eli5_category --> 2 models
eli5_category	jsgao/bart-eli5c
eli5_category	jsgao/bert-eli5c-retriever
# dataset: emea --> 0 models
# dataset: emo --> 3 models
emo	lordtt13/emo-mobilebert
emo	AdapterHub/bert-base-uncased-pf-emo
emo	AdapterHub/roberta-base-pf-emo
# dataset: emotion --> 58 models
emotion	bhadresh-savani/distilbert-base-uncased-emotion
emotion	nateraw/bert-base-uncased-emotion
emotion	mrm8488/t5-base-finetuned-emotion
emotion	bhadresh-savani/roberta-base-emotion
emotion	bhadresh-savani/bert-base-uncased-emotion
emotion	mrm8488/t5-small-finetuned-emotion
emotion	AdapterHub/bert-base-uncased-pf-emotion
emotion	transformersbook/distilbert-base-uncased-finetuned-emotion
emotion	Emanuel/bertweet-emotion-base
emotion	bhadresh-savani/albert-base-v2-emotion
emotion	Emanuel/twitter-emotion-deberta-v3-base
emotion	trnt/twitter_emotions
emotion	osanseviero/distilbert-base-uncased-finetuned-emotion
emotion	reatiny/distilbert-base-uncased-finetuned-emotion
emotion	MhF/distilbert-base-uncased-finetuned-emotion
emotion	ncduy/bert-base-cased-finetuned-emotion
emotion	JaviBJ/sagemaker-distilbert-emotion
emotion	victen/distilbert-base-uncased-finetuned-emotion
emotion	Crives/distilbert-base-uncased-finetuned-emotion
emotion	Jorgeutd/sagemaker-roberta-base-emotion
emotion	Tommy930/distilbert-base-uncased-finetuned-emotion
emotion	lvargas/distilbert-base-uncased-finetuned-emotion2
emotion	srosy/distilbert-base-uncased-finetuned-emotion
emotion	asalics/distilbert-base-uncased-finetuned-emotion
emotion	timtarusov/distilbert-base-uncased-finetuned-emotion
emotion	mattmcclean/distilbert-base-uncased-finetuned-emotion
emotion	carlosaguayo/distilbert-base-uncased-finetuned-emotion
emotion	Tahsin/distilbert-base-uncased-finetuned-emotion
emotion	philschmid/deberta-v3-xsmall-emotion
emotion	Fengkai/distilbert-base-uncased-finetuned-emotion
emotion	bergum/xtremedistil-emotion
emotion	bergum/xtremedistil-l6-h384-emotion
emotion	lewtun/minilm-finetuned-emotion
emotion	anindabitm/sagemaker-distilbert-emotion
emotion	cscottp27/distilbert-base-uncased-finetuned-emotion
emotion	hadxu/distilbert-base-uncased-finetuned-emotion
emotion	lewtun/distilbert-base-uncased-finetuned-emotion-test-01
emotion	marcelcastrobr/sagemaker-distilbert-emotion
emotion	milyiyo/minilm-finetuned-emotion
emotion	nickmuchi/minilm-finetuned-emotion_nm
emotion	abdelkader/distilbert-base-uncased-finetuned-emotion
emotion	jonc/distilbert-base-uncased-finetuned-emotion
emotion	jpabbuehl/sagemaker-distilbert-emotion
emotion	lewtun/results
emotion	masapasa/sagemaker-distilbert-emotion
emotion	pdroberts/distilbert-base-uncased-finetuned-emotion
emotion	philschmid/MiniLMv2-L12-H384-emotion
emotion	gbade786/distilbert-base-uncased-finetuned-emotion
emotion	marcelcastrobr/sagemaker-distilbert-emotion-2
emotion	philschmid/MiniLMv2-L6-H384-emotion
emotion	Worldman/distilbert-base-uncased-finetuned-emotion
emotion	coldfir3/distilbert-base-uncased-finetuned-emotion
emotion	philschmid/sagemaker-distilbert-emotion
emotion	tiesan/distilbert-base-uncased-finetuned-emotion
emotion	AdapterHub/roberta-base-pf-emotion
emotion	Yaia/distilbert-base-uncased-finetuned-emotion
emotion	dmiller1/distilbert-base-uncased-finetuned-emotion
emotion	EnsarEmirali/distilbert-base-uncased-finetuned-emotion
# dataset: emotone_ar --> 0 models
# dataset: empathetic_dialogues --> 0 models
# dataset: enriched_web_nlg --> 0 models
# dataset: eraser_multi_rc --> 0 models
# dataset: esnli --> 0 models
# dataset: eth_py150_open --> 0 models
# dataset: ethos --> 0 models
# dataset: eu_regulatory_ir --> 0 models
# dataset: eurlex --> 0 models
# dataset: euronews --> 0 models
# dataset: europa_eac_tm --> 0 models
# dataset: europa_ecdc_tm --> 0 models
# dataset: europarl_bilingual --> 0 models
# dataset: event2Mind --> 1 models
event2Mind	mrm8488/t5-base-finetuned-e2m-intent
# dataset: evidence_infer_treatment --> 0 models
# dataset: exams --> 0 models
# dataset: factckbr --> 0 models
# dataset: fake_news_english --> 0 models
# dataset: fake_news_filipino --> 0 models
# dataset: farsi_news --> 0 models
# dataset: fashion_mnist --> 0 models
# dataset: fever --> 8 models
fever	ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli
fever	MoritzLaurer/xtremedistil-l6-h256-mnli-fever-anli-ling-binary
fever	MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli
fever	MoritzLaurer/DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary
fever	nielsr/coref-bert-base
fever	nielsr/coref-bert-large
fever	nielsr/coref-roberta-large
fever	nielsr/coref-roberta-base
# dataset: few_rel --> 0 models
# dataset: financial_phrasebank --> 7 models
financial_phrasebank	mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis
financial_phrasebank	ahmedrachid/FinancialBERT-Sentiment-Analysis
financial_phrasebank	oandreae/financial_sentiment_model
financial_phrasebank	nickmuchi/distilroberta-finetuned-finclass
financial_phrasebank	warwickai/fin-perceiver
financial_phrasebank	TomW/TOMFINSEN
financial_phrasebank	nuriafari/my_model
# dataset: finer --> 0 models
# dataset: flores --> 0 models
# dataset: flue --> 1 models
flue	cmarkea/distilcamembert-base-nli
# dataset: food101 --> 1 models
food101	nateraw/food
# dataset: fquad --> 4 models
fquad	JDBN/t5-base-fr-qg-fquad
fquad	illuin/camembert-base-fquad
fquad	lincoln/barthez-squadFR-fquad-piaf-question-generation
fquad	lincoln/camembert-squadFR-fquad-piaf-answer-extraction
# dataset: freebase_qa --> 0 models
# dataset: gap --> 4 models
gap	nielsr/coref-bert-base
gap	nielsr/coref-bert-large
gap	nielsr/coref-roberta-large
gap	nielsr/coref-roberta-base
# dataset: gem --> 2 models
gem	sibyl/BART-commongen
gem	sibyl/BART-large-commongen
# dataset: generated_reviews_enth --> 1 models
generated_reviews_enth	poom-sci/WangchanBERTa-finetuned-sentiment
# dataset: generics_kb --> 0 models
# dataset: german_legal_entity_recognition --> 0 models
# dataset: germaner --> 1 models
germaner	philschmid/gbert-base-germaner
# dataset: germeval_14 --> 3 models
germeval_14	fhswf/bert_de_ner
germeval_14	abhilash1910/albert-german-ner
germeval_14	dbmdz/flair-distilbert-ner-germeval14
# dataset: giga_fren --> 0 models
# dataset: gigaword --> 15 models
gigaword	funnel-transformer/small
gigaword	funnel-transformer/medium
gigaword	funnel-transformer/intermediate
gigaword	lanwuwei/GigaBERT-v3-Arabic-and-English
gigaword	funnel-transformer/small-base
gigaword	funnel-transformer/large
gigaword	funnel-transformer/xlarge
gigaword	funnel-transformer/medium-base
gigaword	a1noack/bart-large-gigaword
gigaword	funnel-transformer/large-base
gigaword	jhu-clsp/roberta-large-eng-ara-128k
gigaword	funnel-transformer/intermediate-base
gigaword	google/roberta2roberta_L-24_gigaword
gigaword	google/pegasus-gigaword
gigaword	funnel-transformer/xlarge-base
# dataset: glucose --> 0 models
# dataset: glue --> 184 models
glue	Alireza1044/albert-base-v2-sst2
glue	DeepPavlov/xlm-roberta-large-en-ru-mnli
glue	Jiva/xlm-roberta-large-it-mnli
glue	Bhumika/roberta-base-finetuned-sst2
glue	gchhablani/bert-base-cased-finetuned-cola
glue	kinit/slovakbert-sts-stsb
glue	gchhablani/bert-base-cased-finetuned-qqp
glue	gchhablani/bert-base-cased-finetuned-sst2
glue	gchhablani/fnet-base-finetuned-sst2
glue	mujeensung/roberta-base_mnli_bc
glue	gchhablani/bert-base-cased-finetuned-mnli
glue	mujeensung/albert-base-v2_mnli_bc
glue	mrm8488/deberta-v3-large-finetuned-mnli
glue	ikevin98/bert-base-uncased-finetuned-sst2
glue	gchhablani/bert-base-cased-finetuned-qnli
glue	nielsr/coref-bert-base
glue	09panesara/distilbert-base-uncased-finetuned-cola
glue	Alireza1044/albert-base-v2-cola
glue	gchhablani/bert-base-cased-finetuned-rte
glue	gchhablani/bert-base-cased-finetuned-mrpc
glue	nielsr/coref-bert-large
glue	mrm8488/deberta-v3-small-finetuned-mnli
glue	philschmid/tiny-bert-sst2-distilled
glue	123abhiALFLKFO/distilbert-base-uncased-finetuned-cola
glue	mrm8488/deberta-v3-small-finetuned-cola
glue	gchhablani/bert-base-cased-finetuned-stsb
glue	mrm8488/deberta-v3-small-finetuned-sst2
glue	BearThreat/distilbert-base-uncased-finetuned-cola
glue	younes9/AI-DAY-distilbert-base-uncased-finetuned-cola
glue	2umm3r/distilbert-base-uncased-finetuned-cola
glue	Jikiwa/testing
glue	mrm8488/deberta-v3-small-finetuned-mrpc
glue	Alireza1044/albert-base-v2-mrpc
glue	Alireza1044/albert-base-v2-qnli
glue	Hinova/distilbert-base-uncased-finetuned-cola
glue	Jungwoo/distilbert-base-uncased-finetuned-cola
glue	mrm8488/deberta-v3-small-finetuned-qnli
glue	Alstractor/distilbert-base-uncased-finetuned-cola
glue	Eldar/bert-fine-tune-cola
glue	jimmyliao/distilbert-base-uncased-finetuned-cola
glue	Alireza1044/albert-base-v2-mnli
glue	Alireza1044/albert-base-v2-stsb
glue	Amalq/distilbert-base-uncased-finetuned-cola
glue	anirudh21/albert-base-v2-finetuned-wnli
glue	Alireza1044/albert-base-v2-rte
glue	Alireza1044/albert-base-v2-wnli
glue	Blaine-Mason/hackMIT-finetuned-sst2
glue	SEISHIN/distilbert-base-uncased-finetuned-mnli
glue	Alireza1044/albert-base-v2-qqp
glue	DongHyoungLee/distilbert-base-uncased-finetuned-cola
glue	MelissaTESSA/distilbert-base-uncased-finetuned-cola
glue	Riad/finetuned-bert-mrpc
glue	gchhablani/bert-large-cased-finetuned-wnli
glue	Kien/distilbert-base-uncased-finetuned-cola
glue	MINYOUNG/distilbert-base-uncased-finetuned-cola
glue	anirudh21/albert-base-v2-finetuned-qnli
glue	anirudh21/albert-base-v2-finetuned-rte
glue	anirudh21/bert-base-uncased-finetuned-rte
glue	sylviachency/distilbert-base-uncased-finetuned-cola
glue	xysmalobia/sequence_classification
glue	JBNLRY/distilbert-base-uncased-finetuned-cola
glue	MisbaHF/distilbert-base-uncased-finetuned-cola
glue	Roberta55/deberta-base-mnli-finetuned-cola
glue	V3RX2000/distilbert-base-uncased-finetuned-cola
glue	VirenS13117/distilbert-base-uncased-finetuned-cola
glue	ajrae/bert-base-uncased-finetuned-mrpc
glue	anirudh21/bert-base-uncased-finetuned-cola
glue	gchhablani/fnet-large-finetuned-cola
glue	gchhablani/fnet-large-finetuned-sst2
glue	histinct7002/distilbert-base-uncased-finetuned-cola
glue	Hyeon/distilbert-base-uncased-finetuned-cola
glue	ZZDDBBCC/distilbert-base-uncased-finetuned-cola
glue	anirudh21/albert-large-v2-finetuned-wnli
glue	anirudh21/bert-base-uncased-finetuned-mrpc
glue	anirudh21/distilbert-base-uncased-finetuned-rte
glue	gchhablani/fnet-base-finetuned-mnli
glue	gchhablani/fnet-base-finetuned-stsb
glue	jaesun/distilbert-base-uncased-finetuned-cola
glue	SongRb/distilbert-base-uncased-finetuned-cola
glue	anirudh21/albert-large-v2-finetuned-rte
glue	anirudh21/distilbert-base-uncased-finetuned-qnli
glue	anirudh21/xlnet-base-cased-finetuned-rte
glue	beomi/distilbert-base-uncased-finetuned-cola
glue	blizrys/distilbert-base-uncased-finetuned-mnli
glue	jxuhf/roberta-base-finetuned-cola
glue	philschmid/bert-mini-sst2-distilled
glue	vesteinn/XLMR-ENIS-finetuned-sst2
glue	waboucay/distilbert-base-uncased-finetuned-cola
glue	Motahar/distilbert-sst2-mahtab
glue	NaliniK/distilbert-base-uncased-finetuned-cola
glue	Pkrawczak/distilbert-base-uncased-finetuned-cola
glue	adamlin/filter
glue	anirudh21/albert-xlarge-v2-finetuned-mrpc
glue	anirudh21/distilbert-base-uncased-finetuned-sst2
glue	anirudh21/electra-base-discriminator-finetuned-rte
glue	gchhablani/bert-base-cased-finetuned-wnli
glue	gchhablani/bert-large-cased-finetuned-cola
glue	gchhablani/bert-large-cased-finetuned-mrpc
glue	leeyujin/distilbert-base-uncased-finetuned-cola
glue	mattchurgin/distilbert-sst2
glue	usami/distilbert-base-uncased-finetuned-cola
glue	anirudh21/albert-xlarge-v2-finetuned-wnli
glue	anirudh21/albert-xxlarge-v2-finetuned-wnli
glue	anirudh21/bert-base-uncased-finetuned-wnli
glue	anirudh21/distilbert-base-uncased-finetuned-cola
glue	anirudh21/distilbert-base-uncased-finetuned-mrpc
glue	banri/distilbert-base-uncased-finetuned-cola
glue	edbeeching/test-trainer-to-hub
glue	federicopascual/distilbert-base-uncased-finetuned-cola
glue	fznmhmmd/distilbert-base-uncased-finetuned-cola
glue	gchhablani/bert-large-cased-finetuned-rte
glue	gchhablani/fnet-base-finetuned-cola
glue	gchhablani/fnet-large-finetuned-mrpc
glue	jery33/distilbert-base-uncased-finetuned-cola
glue	ksmcg/name
glue	sciarrilli/distilbert-base-uncased-cola
glue	sgugger/bert-finetuned-mrpc
glue	anirudh21/bert-base-uncased-finetuned-qnli
glue	anirudh21/distilbert-base-uncased-finetuned-wnli
glue	anirudh21/xlnet-base-cased-finetuned-wnli
glue	athar/distilbert-base-uncased-finetuned-cola
glue	avneet/distilbert-base-uncased-finetuned-cola
glue	avneet/distilbert-base-uncased-finetuned-sst2
glue	blizrys/distilbert-base-uncased-finetuned-cola
glue	caioamb/distilbert-base-uncased-finetuned-cola
glue	gchhablani/fnet-base-finetuned-mrpc
glue	gchhablani/fnet-base-finetuned-rte
glue	gchhablani/fnet-base-finetuned-wnli
glue	gchhablani/fnet-large-finetuned-qqp
glue	harithapliyal/distilbert-base-uncased-finetuned-cola
glue	linkpipi/distilbert-base-uncased-finetuned-sst2
glue	mattchurgin/distilbert-mrpc
glue	riyadhctg/distilbert-base-uncased-finetuned-cola
glue	sgugger/finetuned-bert-mrpc
glue	sgugger/finetuned-bert
glue	shokiokita/distilbert-base-uncased-finetuned-mrpc
glue	tbochens/test-train
glue	xysmalobia/test-trainer
glue	ychu4/distilbert-base-uncased-finetuned-cola
glue	gchhablani/fnet-large-finetuned-cola-copy4
glue	gchhablani/fnet-large-finetuned-rte
glue	gchhablani/fnet-large-finetuned-wnli
glue	hcjang1987/distilbert-base-uncased-finetuned-cola
glue	jacobduncan00/hackMIT-finetuned-sst2
glue	mollypak/distilbert-base-uncased-finetuned-cola
glue	navsad/navid_test_bert
glue	oemga38/distilbert-base-uncased-finetuned-cola
glue	oseibrefo/distilbert-base-uncased-finetuned-cola
glue	oumeima/finetuned-bert-mrpc
glue	sgugger/bert-fine-tuned-cola
glue	sgugger/glue-mrpc
glue	shokiokita/distilbert-base-uncased-finetuned-cola
glue	tucan9389/distilbert-base-uncased-finetuned-cola
glue	vesteinn/XLMR-ENIS-finetuned-stsb
glue	anirudh21/electra-base-discriminator-finetuned-wnli
glue	gauravtripathy/distilbert-base-uncased-finetuned-cola
glue	gchhablani/fnet-large-finetuned-cola-copy2
glue	gchhablani/fnet-large-finetuned-cola-copy3
glue	hchc/distilbert-base-uncased-finetuned-cola
glue	jpabbuehl/distilbert-base-uncased-finetuned-cola
glue	mflorinsky/distilbert-base-uncased-finetuned-cola
glue	pooyaphoenix/distilbert-base-uncased-finetuned-cola
glue	pranav1015/distilbert-base-uncased-finetuned-cola
glue	s87204/distilbert-base-uncased-finetuned-cola
glue	sgugger/distilbert-base-uncased-finetuned-cola
glue	vesteinn/XLMR-ENIS-finetuned-cola
glue	zhc/distilbert-base-uncased-finetuned-mrpc-test
glue	D3xter1922/electra-base-discriminator-finetuned-cola
glue	gchhablani/fnet-base-finetuned-qqp
glue	gchhablani/fnet-large-finetuned-cola-copy
glue	gchhablani/fnet-large-finetuned-stsb
glue	kdo6301/bert-base-uncased-finetuned-cola
glue	patrickvonplaten/bert-base-cased_fine_tuned_glue_mrpc_demo
glue	gchhablani/fnet-base-finetuned-qnli
glue	vkk1710/xlnet-base-cased-finetuned-qqp
glue	Kumicho/distilbert-base-uncased-finetuned-cola
glue	nielsr/coref-roberta-large
glue	zhangle/distilbert-base-uncased-finetuned-cola
glue	ajrae/bert-base-uncased-finetuned-cola
glue	nielsr/coref-roberta-base
glue	zhaoyang/BertFinetuning
glue	z3c1f4/distilbert-base-uncased-finetuned-cola
glue	kapilchauhan/distilbert-base-uncased-finetuned-cola
glue	kdo6301/bert-base-uncased-finetuned-cola-2
# dataset: gnad10 --> 1 models
gnad10	Mathking/bert-base-german-cased-gnad10
# dataset: go_emotions --> 11 models
go_emotions	joeddav/distilbert-base-uncased-go-emotions-student
go_emotions	arpanghoshal/EmoRoBERTa
go_emotions	bhadresh-savani/bert-base-go-emotion
go_emotions	kiri-ai/t5-base-qa-summary-emotion
go_emotions	bergum/xtremedistil-l6-h384-go-emotion
go_emotions	justin871030/bert-base-uncased-goemotions-ekman-finetuned
go_emotions	poom-sci/bert-base-uncased-multi-emotion
go_emotions	justin871030/bert-base-uncased-goemotions-group-finetuned
go_emotions	justin871030/bert-base-uncased-goemotions-original-finetuned
go_emotions	bhadresh-savani/distilbert-base-uncased-go-emotion
go_emotions	bsingh/roberta_goEmotion
# dataset: gooaq --> 0 models
# dataset: google_wellformed_query --> 1 models
google_wellformed_query	salesken/query_wellformedness_score
# dataset: grail_qa --> 0 models
# dataset: great_code --> 0 models
# dataset: greek_legal_code --> 0 models
# dataset: guardian_authorship --> 0 models
# dataset: gutenberg_time --> 0 models
# dataset: hans --> 0 models
# dataset: hansards --> 0 models
# dataset: hard --> 0 models
# dataset: harem --> 1 models
harem	ricardo-filho/bert-base-portuguese-cased-finetuned-ner
# dataset: has_part --> 0 models
# dataset: hate_offensive --> 0 models
# dataset: hate_speech18 --> 1 models
hate_speech18	Narrativaai/deberta-v3-small-finetuned-hate_speech18
# dataset: hate_speech_filipino --> 0 models
# dataset: hate_speech_offensive --> 0 models
# dataset: hate_speech_pl --> 0 models
# dataset: hate_speech_portuguese --> 0 models
# dataset: hatexplain --> 2 models
hatexplain	Hate-speech-CNERG/bert-base-uncased-hatexplain
hatexplain	Hate-speech-CNERG/bert-base-uncased-hatexplain-rationale-two
# dataset: hausa_voa_ner --> 0 models
# dataset: hausa_voa_topics --> 0 models
# dataset: hda_nli_hindi --> 0 models
# dataset: head_qa --> 0 models
# dataset: health_fact --> 0 models
# dataset: hebrew_projectbenyehuda --> 0 models
# dataset: hebrew_sentiment --> 0 models
# dataset: hebrew_this_world --> 0 models
# dataset: hellaswag --> 3 models
hellaswag	AdapterHub/bert-base-uncased-pf-hellaswag
hellaswag	AdapterHub/roberta-base-pf-hellaswag
hellaswag	prajjwal1/roberta_hellaswag
# dataset: hendrycks_test --> 0 models
# dataset: hind_encorp --> 0 models
# dataset: hindi_discourse --> 0 models
# dataset: hippocorpus --> 0 models
# dataset: hkcancor --> 0 models
# dataset: hlgd --> 0 models
# dataset: hope_edi --> 0 models
# dataset: hotpot_qa --> 2 models
hotpot_qa	AdapterHub/bert-base-uncased-pf-hotpotqa
hotpot_qa	AdapterHub/roberta-base-pf-hotpotqa
# dataset: hover --> 0 models
# dataset: hrenwac_para --> 0 models
# dataset: hrwac --> 2 models
hrwac	Andrija/SRoBERTa-F
hrwac	Andrija/SRoBERTa-XL
# dataset: humicroedit --> 0 models
# dataset: hybrid_qa --> 0 models
# dataset: hyperpartisan_news_detection --> 0 models
# dataset: iapp_wiki_qa_squad --> 0 models
# dataset: id_clickbait --> 0 models
# dataset: id_liputan6 --> 3 models
id_liputan6	cahya/t5-base-indonesian-summarization-cased
id_liputan6	cahya/bert2gpt-indonesian-summarization
id_liputan6	cahya/bert2bert-indonesian-summarization
# dataset: id_nergrit_corpus --> 0 models
# dataset: id_newspapers_2018 --> 2 models
id_newspapers_2018	cahya/bert-base-indonesian-1.5G
id_newspapers_2018	cahya/distilbert-base-indonesian
# dataset: id_panl_bppt --> 0 models
# dataset: id_puisi --> 0 models
# dataset: igbo_english_machine_translation --> 0 models
# dataset: igbo_monolingual --> 0 models
# dataset: igbo_ner --> 0 models
# dataset: ilist --> 0 models
# dataset: imdb --> 42 models
imdb	aychang/roberta-base-imdb
imdb	mrm8488/t5-small-finetuned-imdb-sentiment
imdb	mrm8488/t5-base-finetuned-imdb-sentiment
imdb	lvwerra/distilbert-imdb
imdb	huggingface-course/distilbert-base-uncased-finetuned-imdb
imdb	ykacer/bert-base-cased-imdb-sequence-classification
imdb	AdapterHub/bert-base-uncased-pf-imdb
imdb	keras-io/bidirectional-lstm-imdb
imdb	nateraw/codecarbon-text-classification
imdb	peterhsu/distilbert-base-uncased-finetuned-imdb
imdb	thatdramebaazguy/movie-roberta-base
imdb	sukhendrasingh/finetuning-sentiment-model-3000-samples
imdb	xkang/distilbert-base-uncased-finetuned-imdb-whole-word-masking
imdb	XSY/albert-base-v2-imdb-calssification
imdb	artemis13fowl/distilbert-base-uncased-finetuned-imdb
imdb	federicopascual/finetuning-sentiment-model-3000-samples
imdb	mbateman/distilbert-base-uncased-finetuned-imdb
imdb	CennetOguz/distilbert-base-uncased-finetuned-imdb
imdb	fabriceyhc/bert-base-uncased-imdb
imdb	AdapterHub/roberta-base-pf-imdb
imdb	federicopascual/finetuning-sentiment-analysis-model-3000-samples
imdb	lannelin/bert-imdb-1hidden
imdb	federicopascual/finetune-sentiment-analysis-model-3000-samples
imdb	federicopascual/finetuned-sentiment-analysis-model
imdb	federicopascual/finetuning-sentiment-model-3000-samples-testcopy
imdb	jatinshah/distilbert-base-uncased-finetuned-imdb
imdb	julien-c/distilbert-sagemaker-1609802168
imdb	lewtun/MiniLM-L12-H384-uncased-finetuned-imdb
imdb	kurianbenoy/distilbert-base-uncased-finetuned-sst-2-english-finetuned-imdb
imdb	mrp/distilbert-base-uncased-finetuned-imdb
imdb	wrmurray/roberta-base-finetuned-imdb
imdb	lewtun/bert-base-uncased-finetuned-imdb
imdb	longnhit07/distilbert-base-uncased-finetuned-imdb
imdb	Leisa/distilbert-base-uncased-finetuned-imdb
imdb	mrm8488/gpt2-imdb-neutral
imdb	minemile/distilbert-base-uncased-finetuned-imdb
imdb	ncduy/distilbert-base-uncased-finetuned-imdb
imdb	raphaelmerx/distilbert-base-uncased-finetuned-imdb
imdb	xkang/distilbert-base-uncased-finetuned-imdb
imdb	kurianbenoy/distilbert-base-uncased-finetuned-imdb
imdb	kyo/distilbert-base-uncased-finetuned-imdb
imdb	lewtun/distilbert-base-uncased-finetuned-imdb
# dataset: imdb_urdu_reviews --> 0 models
# dataset: imppres --> 0 models
# dataset: indic_glue --> 0 models
# dataset: indonli --> 2 models
indonli	StevenLimcorn/indo-roberta-indonli
indonli	w11wo/indonesian-roberta-base-indonli
# dataset: indonlu --> 8 models
indonlu	ayameRushia/bert-base-indonesian-1.5G-sentiment-analysis-smsa
indonlu	w11wo/indonesian-roberta-base-sentiment-classifier
indonlu	StevenLimcorn/indonesian-roberta-base-emotion-classifier
indonlu	ayameRushia/indobert-base-uncased-finetuned-indonlu-smsa
indonlu	ayameRushia/roberta-base-indonesian-sentiment-analysis-smsa
indonlu	sahri/indonesiasentiment
indonlu	ayameRushia/roberta-base-indonesian-1.5G-sentiment-analysis-smsa
indonlu	w11wo/indonesian-roberta-base-posp-tagger
# dataset: inquisitive_qg --> 0 models
# dataset: interpress_news_category_tr --> 0 models
# dataset: interpress_news_category_tr_lite --> 0 models
# dataset: irc_disentangle --> 0 models
# dataset: isixhosa_ner_corpus --> 0 models
# dataset: isizulu_ner_corpus --> 0 models
# dataset: iwslt2017 --> 0 models
# dataset: jeopardy --> 0 models
# dataset: jfleg --> 2 models
jfleg	vennify/t5-base-grammar-correction
jfleg	KES/T5-KES
# dataset: jigsaw_toxicity_pred --> 0 models
# dataset: jigsaw_unintended_bias --> 0 models
# dataset: jnlpba --> 3 models
jnlpba	sciarrilli/biobert-base-cased-v1.2-finetuned-ner
jnlpba	sberbank-ai/bert-base-NER-reptile-5-datasets
jnlpba	raynardj/ner-gene-dna-rna-jnlpba-pubmed
# dataset: journalists_questions --> 0 models
# dataset: kan_hope --> 0 models
# dataset: kannada_news --> 0 models
# dataset: kd_conv --> 0 models
# dataset: kde4 --> 12 models
kde4	huggingface-course/marian-finetuned-kde4-en-to-fr
kde4	Jour/m2m100_418M-fr
kde4	sgugger/marian-finetuned-kde4-en-to-fr
kde4	lewtun/marian-finetuned-kde4-en-to-fr
kde4	nickmuchi/kde4-marian-finetuned-en-fr
kde4	Leisa/marian-finetuned-kde4-en-to-fr
kde4	mbateman/marian-finetuned-kde4-en-to-fr
kde4	ncduy/marian-finetuned-kde4-en-to-fr
kde4	peterhsu/marian-finetuned-kde4-en-to-zh_TW
kde4	NDugar/m2m100_418M-fr
kde4	mrp/marian-finetuned-kde4-en-to-fr
kde4	jatinshah/marian-finetuned-kde4-en-to-fr
# dataset: kelm --> 0 models
# dataset: kilt_tasks --> 0 models
# dataset: kilt_wikipedia --> 0 models
# dataset: kinnews_kirnews --> 0 models
# dataset: klue --> 15 models
klue	Huffon/klue-roberta-base-nli
klue	bespin-global/klue-sentence-roberta-base
klue	ainize/klue-bert-base-mrc
klue	Huffon/sentence-klue-roberta-base
klue	bespin-global/klue-bert-base-mrc
klue	Taekyoon/neg_komrc_train
klue	Jihyun22/bert-base-finetuned-nli
klue	JIWON/bert-base-finetuned-nli
klue	tucan9389/kcbert-base-finetuned
klue	eliza-dukim/bert-base-finetuned-sts-deprecated
klue	eliza-dukim/bert-base-finetuned-sts
klue	eliza-dukim/bert-base-finetuned-ynat
klue	ehddnr301/bert-base-ehddnr-ynat
klue	zgotter/bert-base-finetuned-ynat
klue	tucan9389/kcbert-base-finetuned-squad
# dataset: kor_3i4k --> 1 models
kor_3i4k	bespin-global/klue-roberta-small-3i4k-intent-classification
# dataset: kor_hate --> 0 models
# dataset: kor_ner --> 0 models
# dataset: kor_nli --> 0 models
# dataset: kor_nlu --> 1 models
kor_nlu	bespin-global/klue-sentence-roberta-base-kornlu
# dataset: kor_qpair --> 0 models
# dataset: kor_sae --> 0 models
# dataset: kor_sarcasm --> 0 models
# dataset: labr --> 1 models
labr	mofawzy/bert-labr-unbalanced
# dataset: lama --> 0 models
# dataset: lambada --> 0 models
# dataset: large_spanish_corpus --> 6 models
large_spanish_corpus	flax-community/spanish-t5-small
large_spanish_corpus	mrm8488/spanish-gpt2
large_spanish_corpus	Narrativa/spanish-gpt2-finetuned-rap-lyrics
large_spanish_corpus	mrm8488/electricidad-small-discriminator
large_spanish_corpus	mrm8488/convbert-small-spanish
large_spanish_corpus	mrm8488/convbert-base-spanish
# dataset: laroseda --> 0 models
# dataset: lc_quad --> 0 models
# dataset: lener_br --> 4 models
lener_br	pierreguillou/ner-bert-large-cased-pt-lenerbr
lener_br	pierreguillou/ner-bert-base-cased-pt-lenerbr
lener_br	Luciano/bertimbau-large-lener_br
lener_br	Luciano/bertimbau-base-lener_br
# dataset: lex_glue --> 0 models
# dataset: liar --> 0 models
# dataset: librispeech_asr --> 65 models
librispeech_asr	facebook/wav2vec2-base-960h
librispeech_asr	facebook/wav2vec2-base
librispeech_asr	facebook/wav2vec2-large-960h-lv60-self
librispeech_asr	facebook/wav2vec2-large-lv60
librispeech_asr	facebook/hubert-large-ls960-ft
librispeech_asr	facebook/wav2vec2-large-960h
librispeech_asr	facebook/s2t-small-librispeech-asr
librispeech_asr	patrickvonplaten/wav2vec2_tiny_random_robust
librispeech_asr	facebook/hubert-xlarge-ls960-ft
librispeech_asr	facebook/wav2vec2-large-960h-lv60
librispeech_asr	ntu-spml/distilhubert
librispeech_asr	facebook/hubert-base-ls960
librispeech_asr	facebook/wav2vec2-base-100h
librispeech_asr	facebook/wav2vec2-large-robust-ft-libri-960h
librispeech_asr	facebook/wav2vec2-large
librispeech_asr	facebook/s2t-wav2vec2-large-en-de
librispeech_asr	patrickvonplaten/wav2vec2-base
librispeech_asr	facebook/s2t-large-librispeech-asr
librispeech_asr	microsoft/unispeech-sat-base-100h-libri-ft
librispeech_asr	asapp/sew-tiny-100k-ft-ls100h
librispeech_asr	asapp/sew-tiny-100k
librispeech_asr	asapp/sew-d-tiny-100k-ft-ls100h
librispeech_asr	facebook/s2t-medium-librispeech-asr
librispeech_asr	asapp/sew-d-tiny-100k
librispeech_asr	microsoft/unispeech-sat-base
librispeech_asr	OthmaneJ/distil-wav2vec2
librispeech_asr	facebook/s2t-wav2vec2-large-en-ar
librispeech_asr	facebook/s2t-wav2vec2-large-en-ca
librispeech_asr	asapp/sew-small-100k
librispeech_asr	asapp/sew-d-base-plus-400k
librispeech_asr	microsoft/unispeech-sat-base-sd
librispeech_asr	asapp/sew-d-mid-k127-100k
librispeech_asr	asapp/sew-mid-100k
librispeech_asr	vitouphy/wav2vec2-xls-r-300m-english
librispeech_asr	facebook/s2t-wav2vec2-large-en-tr
librispeech_asr	microsoft/unispeech-sat-base-sv
librispeech_asr	asapp/sew-d-small-100k
librispeech_asr	iamtarun/wav2vec-osr
librispeech_asr	asapp/sew-d-mid-100k
librispeech_asr	asapp/sew-d-base-plus-400k-ft-ls100h
librispeech_asr	asapp/sew-d-base-100k
librispeech_asr	tommy19970714/wav2vec2-base-960h
librispeech_asr	asapp/sew-d-base-plus-100k
librispeech_asr	asapp/sew-d-mid-400k
librispeech_asr	asapp/sew-d-mid-k127-400k
librispeech_asr	osanseviero/asr-with-transformers-wav2vec2
librispeech_asr	patrickvonplaten/wav2vec2-base-100h-2nd-try
librispeech_asr	speech-seq2seq/wav2vec2-2-bert-large
librispeech_asr	speech-seq2seq/wav2vec2-2-gpt2-medium-no-adapter-frozen-enc
librispeech_asr	speech-seq2seq/wav2vec2-2-gpt2-medium
librispeech_asr	speech-seq2seq/wav2vec2-2-roberta-large-no-adapter-frozen-enc
librispeech_asr	valhalla/s2t_librispeech_large
librispeech_asr	asapp/sew-d-mid-k127-400k-ft-ls100h
librispeech_asr	valhalla/s2t_librispeech_small
librispeech_asr	valhalla/s2t_librispeech_medium
librispeech_asr	asapp/sew-d-mid-400k-ft-ls100h
librispeech_asr	speech-seq2seq/wav2vec2-2-roberta-large
librispeech_asr	speech-seq2seq/wav2vec2-2-bert-large-no-adapter-frozen-enc
librispeech_asr	sanchit-gandhi/wav2vec2-2-gpt2-no-adapter
librispeech_asr	flax-community/wav2vec2-german
librispeech_asr	vuiseng9/wav2vec2-base-100h
librispeech_asr	sanchit-gandhi/wav2vec2-2-bart-large-frozen-enc
librispeech_asr	speech-seq2seq/wav2vec2-2-bart-large-no-adapter-frozen-enc
librispeech_asr	speech-seq2seq/wav2vec2-2-bert-large-no-adapter
librispeech_asr	speech-seq2seq/wav2vec2-2-gpt2-no-adapter
# dataset: librispeech_lm --> 0 models
# dataset: limit --> 0 models
# dataset: lince --> 9 models
lince	sagorsarker/codeswitch-hineng-ner-lince
lince	sagorsarker/codeswitch-spaeng-lid-lince
lince	sagorsarker/codeswitch-spaeng-sentiment-analysis-lince
lince	sagorsarker/codeswitch-spaeng-pos-lince
lince	sagorsarker/codeswitch-hineng-lid-lince
lince	AnkurIbySarkar/Code-Switching-project
lince	sagorsarker/codeswitch-hineng-pos-lince
lince	sagorsarker/codeswitch-spaeng-ner-lince
lince	sagorsarker/codeswitch-nepeng-lid-lince
# dataset: linnaeus --> 0 models
# dataset: liveqa --> 0 models
# dataset: lj_speech --> 0 models
# dataset: lm1b --> 0 models
# dataset: lst20 --> 0 models
# dataset: m_lama --> 0 models
# dataset: mac_morpho --> 0 models
# dataset: makhzan --> 0 models
# dataset: masakhaner --> 53 models
masakhaner	Davlan/xlm-roberta-large-masakhaner
masakhaner	mbeukman/xlm-roberta-base-finetuned-yoruba-finetuned-ner-yoruba
masakhaner	Davlan/bert-base-multilingual-cased-masakhaner
masakhaner	Davlan/distilbert-base-multilingual-cased-masakhaner
masakhaner	mbeukman/xlm-roberta-base-finetuned-kinyarwanda-finetuned-ner-kinyarwanda
masakhaner	mbeukman/xlm-roberta-base-finetuned-ner-igbo
masakhaner	mbeukman/xlm-roberta-base-finetuned-naija-finetuned-ner-swahili
masakhaner	mbeukman/xlm-roberta-base-finetuned-ner-swahili
masakhaner	mbeukman/xlm-roberta-base-finetuned-swahili-finetuned-ner-kinyarwanda
masakhaner	arnolfokam/mbert-base-uncased-pcm
masakhaner	mbeukman/xlm-roberta-base-finetuned-hausa-finetuned-ner-hausa
masakhaner	mbeukman/xlm-roberta-base-finetuned-kinyarwanda-finetuned-ner-swahili
masakhaner	mbeukman/xlm-roberta-base-finetuned-luo-finetuned-ner-luo
masakhaner	mbeukman/xlm-roberta-base-finetuned-ner-hausa
masakhaner	mbeukman/xlm-roberta-base-finetuned-ner-kinyarwanda
masakhaner	mbeukman/xlm-roberta-base-finetuned-swahili-finetuned-ner-hausa
masakhaner	mbeukman/xlm-roberta-base-finetuned-swahili-finetuned-ner-swahili
masakhaner	mbeukman/xlm-roberta-base-finetuned-yoruba-finetuned-ner-swahili
masakhaner	arnolfokam/mbert-base-uncased-ner-swa
masakhaner	mbeukman/xlm-roberta-base-finetuned-igbo-finetuned-ner-swahili
masakhaner	mbeukman/xlm-roberta-base-finetuned-luo-finetuned-ner-swahili
masakhaner	mbeukman/xlm-roberta-base-finetuned-swahili-finetuned-ner-wolof
masakhaner	arnolfokam/mbert-base-uncased-kin
masakhaner	arnolfokam/mbert-base-uncased-swa
masakhaner	mbeukman/xlm-roberta-base-finetuned-igbo-finetuned-ner-igbo
masakhaner	mbeukman/xlm-roberta-base-finetuned-ner-luo
masakhaner	mbeukman/xlm-roberta-base-finetuned-ner-naija
masakhaner	mbeukman/xlm-roberta-base-finetuned-ner-wolof
masakhaner	mbeukman/xlm-roberta-base-finetuned-ner-yoruba
masakhaner	mbeukman/xlm-roberta-base-finetuned-swahili-finetuned-ner-luganda
masakhaner	arnolfokam/bert-base-uncased-kin
masakhaner	arnolfokam/mbert-base-uncased-ner-pcm
masakhaner	arnolfokam/roberta-base-swa
masakhaner	mbeukman/xlm-roberta-base-finetuned-swahili-finetuned-ner-igbo
masakhaner	mbeukman/xlm-roberta-base-finetuned-swahili-finetuned-ner-yoruba
masakhaner	mbeukman/xlm-roberta-base-finetuned-wolof-finetuned-ner-wolof
masakhaner	arnolfokam/bert-base-uncased-pcm
masakhaner	arnolfokam/bert-base-uncased-swa
masakhaner	arnolfokam/mbert-base-uncased-ner-kin
masakhaner	arnolfokam/roberta-base-kin
masakhaner	arnolfokam/roberta-base-pcm
masakhaner	mbeukman/xlm-roberta-base-finetuned-hausa-finetuned-ner-swahili
masakhaner	mbeukman/xlm-roberta-base-finetuned-luganda-finetuned-ner-luganda
masakhaner	mbeukman/xlm-roberta-base-finetuned-naija-finetuned-ner-naija
masakhaner	mbeukman/xlm-roberta-base-finetuned-ner-luganda
masakhaner	mbeukman/xlm-roberta-base-finetuned-swahili-finetuned-ner-luo
masakhaner	mbeukman/xlm-roberta-base-finetuned-swahili-finetuned-ner-naija
masakhaner	mbeukman/xlm-roberta-base-finetuned-wolof-finetuned-ner-swahili
masakhaner	mbeukman/xlm-roberta-base-finetuned-luganda-finetuned-ner-swahili
masakhaner	mbeukman/xlm-roberta-base-finetuned-amharic-finetuned-ner-amharic
masakhaner	mbeukman/xlm-roberta-base-finetuned-amharic-finetuned-ner-swahili
masakhaner	mbeukman/xlm-roberta-base-finetuned-swahili-finetuned-ner-amharic
masakhaner	mbeukman/xlm-roberta-base-finetuned-ner-amharic
# dataset: math_dataset --> 0 models
# dataset: math_qa --> 0 models
# dataset: matinf --> 0 models
# dataset: mbpp --> 0 models
# dataset: mc4 --> 38 models
mc4	google/mt5-base
mc4	google/mt5-xl
mc4	google/byt5-small
mc4	google/mt5-small
mc4	google/mt5-large
mc4	google/byt5-xl
mc4	google/byt5-base
mc4	google/byt5-large
mc4	google/mt5-xxl
mc4	jonfd/electra-small-nordic
mc4	megagonlabs/t5-base-japanese-web
mc4	bakrianoo/t5-arabic-large
mc4	ufal/byt5-small-multilexnorm2021-en
mc4	birgermoell/roberta-swedish-scandi
mc4	flax-community/arabic-t5-small
mc4	flax-community/gpt2-bengali
mc4	bakrianoo/t5-arabic-small
mc4	flax-community/RoBERTa-large-finnish
mc4	baffo32/pyc2py_alpha2
mc4	ufal/byt5-small-multilexnorm2021-iden
mc4	ufal/byt5-small-multilexnorm2021-sl
mc4	google/byt5-xxl
mc4	megagonlabs/t5-base-japanese-web-8k
mc4	ufal/byt5-small-multilexnorm2021-da
mc4	ufal/byt5-small-multilexnorm2021-it
mc4	ufal/byt5-small-multilexnorm2021-de
mc4	ufal/byt5-small-multilexnorm2021-nl
mc4	bakrianoo/t5-arabic-base
mc4	jonfd/electra-small-is-no
mc4	ufal/byt5-small-multilexnorm2021-es
mc4	ufal/byt5-small-multilexnorm2021-trde
mc4	flax-community/Sinhala-gpt2
mc4	keshan/sinhala-gpt2
mc4	ufal/byt5-small-multilexnorm2021-sr
mc4	tftransformers/mt5-base
mc4	tftransformers/mt5-small
mc4	ufal/byt5-small-multilexnorm2021-hr
mc4	ufal/byt5-small-multilexnorm2021-tr
# dataset: mc_taco --> 0 models
# dataset: md_gender_bias --> 0 models
# dataset: mdd --> 0 models
# dataset: med_hop --> 0 models
# dataset: medal --> 0 models
# dataset: medical_dialog --> 0 models
# dataset: medical_questions_pairs --> 0 models
# dataset: menyo20k_mt --> 0 models
# dataset: meta_woz --> 0 models
# dataset: metooma --> 0 models
# dataset: metrec --> 0 models
# dataset: miam --> 0 models
# dataset: mkb --> 0 models
# dataset: mkqa --> 0 models
# dataset: mlqa --> 3 models
mlqa	Sahajtomar/German-question-answer-Electra
mlqa	Sahajtomar/GBERTQnA
mlqa	nbroad/mt5-small-qgen
# dataset: mlsum --> 13 models
mlsum	mrm8488/bert2bert_shared-german-finetuned-summarization
mlsum	ml6team/mt5-small-german-finetune-mlsum
mlsum	deutsche-telekom/mt5-small-sum-de-en-v1
mlsum	mrm8488/camembert2camembert_shared-finetuned-french-summarization
mlsum	mrm8488/bert2bert_shared-spanish-finetuned-summarization
mlsum	cointegrated/rut5-base-absum
mlsum	Narrativa/bsc_roberta2roberta_shared-spanish-finetuned-mlsum-summarization
mlsum	T-Systems-onsite/mt5-small-sum-de-en-v2
mlsum	Shahm/bart-german
mlsum	mrm8488/bert2bert_shared-turkish-summarization
mlsum	Shahm/t5-small-german
mlsum	Shahm/bert-german
mlsum	lewtun/mt5-small-finetuned-mlsum
# dataset: mnist --> 1 models
mnist	mindspore-ai/LeNet
# dataset: mocha --> 0 models
# dataset: moroco --> 0 models
# dataset: movie_rationales --> 0 models
# dataset: mrqa --> 0 models
# dataset: ms_marco --> 6 models
ms_marco	sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco
ms_marco	sebastian-hofstaetter/colbert-distilbert-margin_mse-T2-msmarco
ms_marco	sebastian-hofstaetter/distilbert-dot-margin_mse-T2-msmarco
ms_marco	sebastian-hofstaetter/distilbert-cat-margin_mse-T2-msmarco
ms_marco	sebastian-hofstaetter/idcm-distilbert-msmarco_doc
ms_marco	sebastian-hofstaetter/prettr-distilbert-split_at_3-margin_mse-T2-msmarco
# dataset: ms_terms --> 0 models
# dataset: msr_genomics_kbcomp --> 0 models
# dataset: msr_sqa --> 7 models
msr_sqa	google/tapas-tiny-finetuned-sqa
msr_sqa	google/tapas-base-finetuned-sqa
msr_sqa	google/tapas-large-finetuned-sqa
msr_sqa	google/tapas-small-finetuned-sqa
msr_sqa	google/tapas-medium-finetuned-sqa
msr_sqa	nielsr/tapex-large-finetuned-sqa
msr_sqa	google/tapas-mini-finetuned-sqa
# dataset: msr_text_compression --> 0 models
# dataset: msr_zhen_translation_parity --> 0 models
# dataset: msra_ner --> 0 models
# dataset: mt_eng_vietnamese --> 0 models
# dataset: muchocine --> 2 models
muchocine	mrm8488/electricidad-base-finetuned-muchocine
muchocine	mrm8488/electricidad-small-finetuned-muchocine
# dataset: multi_booked --> 0 models
# dataset: multi_eurlex --> 0 models
# dataset: multi_news --> 0 models
# dataset: multi_nli --> 29 models
multi_nli	facebook/bart-large-mnli
multi_nli	cross-encoder/nli-distilroberta-base
multi_nli	typeform/distilbert-base-uncased-mnli
multi_nli	joeddav/xlm-roberta-large-xnli
multi_nli	ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli
multi_nli	typeform/mobilebert-uncased-mnli
multi_nli	MoritzLaurer/mDeBERTa-v3-base-mnli-xnli
multi_nli	MoritzLaurer/xtremedistil-l6-h256-mnli-fever-anli-ling-binary
multi_nli	NbAiLab/nb-bert-base-mnli
multi_nli	alan-turing-institute/mt5-large-finetuned-mnli-xtreme-xnli
multi_nli	MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli
multi_nli	cross-encoder/nli-MiniLM2-L6-H768
multi_nli	cross-encoder/nli-deberta-base
multi_nli	cross-encoder/nli-roberta-base
multi_nli	cross-encoder/nli-deberta-v3-base
multi_nli	canwenxu/BERT-of-Theseus-MNLI
multi_nli	MoritzLaurer/DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary
multi_nli	cross-encoder/nli-deberta-v3-large
multi_nli	Jiva/xlm-roberta-large-it-mnli
multi_nli	oigele/Fb_improved_zeroshot
multi_nli	cross-encoder/nli-deberta-v3-xsmall
multi_nli	AdapterHub/bert-base-uncased-pf-mnli
multi_nli	navteca/bart-large-mnli
multi_nli	cross-encoder/nli-deberta-v3-small
multi_nli	usc-isi/sbert-roberta-large-anli-mnli-snli
multi_nli	lighteternal/nli-xlm-r-greek
multi_nli	AdapterHub/roberta-base-pf-mnli
multi_nli	ClaudeYang/awesome_fb_model
multi_nli	oigele/awesome_fb_model
# dataset: multi_nli_mismatch --> 1 models
multi_nli_mismatch	ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli
# dataset: multi_para_crawl --> 0 models
# dataset: multi_re_qa --> 0 models
# dataset: multi_woz_v22 --> 1 models
multi_woz_v22	tosin/dialogpt_mwoz
# dataset: multi_x_science_sum --> 0 models
# dataset: multidoc2dial --> 0 models
# dataset: multilingual_librispeech --> 16 models
multilingual_librispeech	facebook/wav2vec2-xls-r-300m
multilingual_librispeech	facebook/wav2vec2-xls-r-1b
multilingual_librispeech	facebook/wav2vec2-xls-r-1b-21-to-en
multilingual_librispeech	facebook/wav2vec2-xls-r-2b
multilingual_librispeech	facebook/wav2vec2-xls-r-1b-en-to-15
multilingual_librispeech	facebook/wav2vec2-xls-r-300m-21-to-en
multilingual_librispeech	FremyCompany/xls-r-nl-v1-cv8-lm
multilingual_librispeech	facebook/wav2vec2-xls-r-300m-en-to-15
multilingual_librispeech	facebook/wav2vec2-xls-r-2b-22-to-16
multilingual_librispeech	facebook/wav2vec2-xls-r-2b-21-to-en
multilingual_librispeech	patrickvonplaten/wav2vec2-300m-mls-german-ft
multilingual_librispeech	facebook/wav2vec2-xls-r-2b-en-to-15
multilingual_librispeech	patrickvonplaten/phoneme_test_5_sv
multilingual_librispeech	patrickvonplaten/wav2vec2-xlsr-53-300m-mls-german-ft
multilingual_librispeech	patrickvonplaten/wav2vec2-100m-mls-german-ft-2
multilingual_librispeech	patrickvonplaten/wav2vec2-100m-mls-german-ft
# dataset: mutual_friends --> 0 models
# dataset: mwsc --> 0 models
# dataset: myanmar_news --> 0 models
# dataset: narrativeqa --> 1 models
narrativeqa	AdapterHub/narrativeqa
# dataset: narrativeqa_manual --> 0 models
# dataset: natural_questions --> 14 models
natural_questions	vasudevgupta/bigbird-roberta-natural-questions
natural_questions	google/t5-large-ssm-nq
natural_questions	google/t5-small-ssm-nq
natural_questions	ankur310794/bert-large-uncased-nq-small-answer
natural_questions	nlpconnect/roberta-base-squad2-nq
natural_questions	google/t5-xl-ssm-nq
natural_questions	vasudevgupta/flax-bigbird-natural-questions
natural_questions	google/t5-xxl-ssm-nq
natural_questions	google/t5-3b-ssm-nqo
natural_questions	google/t5-11b-ssm-nq
natural_questions	google/t5-11b-ssm-nqo
natural_questions	google/t5-3b-ssm-nq
natural_questions	google/t5-large-ssm-nqo
natural_questions	google/t5-xxl-ssm-nqo
# dataset: ncbi_disease --> 1 models
ncbi_disease	raynardj/ner-disease-ncbi-bionlp-bc5cdr-pubmed
# dataset: nchlt --> 0 models
# dataset: ncslgr --> 0 models
# dataset: nell --> 0 models
# dataset: neural_code_search --> 0 models
# dataset: news_commentary --> 0 models
# dataset: newsgroup --> 0 models
# dataset: newsph --> 0 models
# dataset: newsph_nli --> 0 models
# dataset: newspop --> 0 models
# dataset: newsqa --> 2 models
newsqa	AdapterHub/bert-base-uncased-pf-newsqa
newsqa	AdapterHub/roberta-base-pf-newsqa
# dataset: newsroom --> 0 models
# dataset: nkjp-ner --> 0 models
# dataset: nli_tr --> 13 models
nli_tr	emrecan/bert-base-turkish-cased-mean-nli-stsb-tr
nli_tr	emrecan/bert-base-multilingual-cased-allnli_tr
nli_tr	emrecan/bert-base-multilingual-cased-multinli_tr
nli_tr	emrecan/bert-base-multilingual-cased-snli_tr
nli_tr	emrecan/bert-base-turkish-cased-multinli_tr
nli_tr	emrecan/distilbert-base-turkish-cased-snli_tr
nli_tr	emrecan/bert-base-turkish-cased-allnli_tr
nli_tr	emrecan/convbert-base-turkish-mc4-cased-allnli_tr
nli_tr	emrecan/bert-base-turkish-cased-snli_tr
nli_tr	emrecan/distilbert-base-turkish-cased-allnli_tr
nli_tr	emrecan/distilbert-base-turkish-cased-multinli_tr
nli_tr	emrecan/convbert-base-turkish-mc4-cased-multinli_tr
nli_tr	emrecan/convbert-base-turkish-mc4-cased-snli_tr
# dataset: nlu_evaluation_data --> 0 models
# dataset: norec --> 0 models
# dataset: norne --> 1 models
norne	saattrupdan/nbailab-base-ner-scandi
# dataset: norwegian_ner --> 0 models
# dataset: nq_open --> 0 models
# dataset: nsmc --> 2 models
nsmc	daekeun-ml/koelectra-small-v3-nsmc
nsmc	jaesun/kcbert-base-finetuned-nsmc
# dataset: numer_sense --> 0 models
# dataset: numeric_fused_head --> 0 models
# dataset: oclar --> 0 models
# dataset: offcombr --> 0 models
# dataset: offenseval2020_tr --> 0 models
# dataset: offenseval_dravidian --> 0 models
# dataset: ofis_publik --> 0 models
# dataset: ohsumed --> 0 models
# dataset: ollie --> 0 models
# dataset: omp --> 0 models
# dataset: onestop_english --> 0 models
# dataset: onestop_qa --> 0 models
# dataset: open_subtitles --> 8 models
open_subtitles	qarib/bert-base-qarib
open_subtitles	qarib/bert-base-qarib60_860k
open_subtitles	qarib/bert-base-qarib60_1970k
open_subtitles	qarib/bert-base-qarib60_1790k
open_subtitles	qarib/bert-base-qarib_far_6500k
open_subtitles	qarib/bert-base-qarib_far_8280k
open_subtitles	qarib/bert-base-qarib_far_9920k
open_subtitles	qarib/bert-base-qarib_far
# dataset: openai_humaneval --> 0 models
# dataset: openbookqa --> 4 models
openbookqa	LIAMF-USP/aristo-roberta
openbookqa	persiannlp/mt5-base-parsinlu-arc-comqa-obqa-multiple-choice
openbookqa	persiannlp/mt5-large-parsinlu-arc-comqa-obqa-multiple-choice
openbookqa	persiannlp/mt5-small-parsinlu-arc-comqa-obqa-multiple-choice
# dataset: openslr --> 20 models
openslr	prajin/wav2vec2-large-xlsr-300m-nepali
openslr	Tahsin-Mayeesha/wav2vec2-bn-300m
openslr	indonesian-nlp/wav2vec2-indonesian-javanese-sundanese
openslr	arijitx/wav2vec2-xls-r-300m-bengali
openslr	Mahalakshmi/wav2vec2-large-xlsr-53-demo-colab
openslr	sumedh/wav2vec2-large-xlsr-marathi
openslr	chmanoj/xls-r-300m-te
openslr	smangrul/xls-r-mr-model
openslr	anuragshas/wav2vec2-large-xlsr-53-telugu
openslr	tanmaylaud/wav2vec2-large-xlsr-hindi-marathi
openslr	chmanoj/xls-r-1B-te
openslr	prajin/wav2vec2-large-xlsr-53-nepali-test
openslr	vitouphy/wav2vec2-xls-r-1b-khmer
openslr	chmanoj/xls-r-2B-te
openslr	cahya/wav2vec2-large-xlsr-sundanese
openslr	gchhablani/wav2vec2-large-xlsr-mr
openslr	gchhablani/wav2vec2-large-xlsr-gu
openslr	amoghsgopadi/wav2vec2-large-xlsr-kn
openslr	cahya/wav2vec2-large-xlsr-javanese
openslr	gchhablani/wav2vec2-large-xlsr-mr-3
# dataset: openwebtext --> 9 models
openwebtext	distilgpt2
openwebtext	distilroberta-base
openwebtext	imvladikon/general_character_bert
openwebtext	typeform/distilroberta-base-v2
openwebtext	junnyu/electra_small_generator
openwebtext	typeform/distilroberta-base
openwebtext	junnyu/roformer_small_generator
openwebtext	junnyu/roformer_small_discriminator
openwebtext	junnyu/electra_small_discriminator
# dataset: opinosis --> 0 models
# dataset: opus100 --> 6 models
opus100	smangrul/xls-r-mr-model
opus100	mrm8488/mbart-large-finetuned-opus-en-es-translation
opus100	mrm8488/mbart-large-finetuned-opus-es-en-translation
opus100	Narrativa/mbart-large-50-finetuned-opus-pt-en-translation
opus100	Narrativa/mbart-large-50-finetuned-opus-en-pt-translation
opus100	mrm8488/mbart-large-finetuned-opus-it-en-translation
# dataset: opus_books --> 1 models
opus_books	rossanez/opus-mt-finetuned-en-es
# dataset: opus_dgt --> 0 models
# dataset: opus_dogc --> 0 models
# dataset: opus_elhuyar --> 0 models
# dataset: opus_euconst --> 0 models
# dataset: opus_finlex --> 0 models
# dataset: opus_fiskmo --> 0 models
# dataset: opus_gnome --> 0 models
# dataset: opus_infopankki --> 0 models
# dataset: opus_memat --> 0 models
# dataset: opus_montenegrinsubs --> 0 models
# dataset: opus_openoffice --> 0 models
# dataset: opus_paracrawl --> 0 models
# dataset: opus_rf --> 0 models
# dataset: opus_tedtalks --> 0 models
# dataset: opus_ubuntu --> 0 models
# dataset: opus_wikipedia --> 1 models
opus_wikipedia	MaryaAI/opus-mt-ar-en-finetuned-ar-to-en
# dataset: opus_xhosanavy --> 0 models
# dataset: orange_sum --> 0 models
# dataset: oscar --> 73 models
oscar	camembert-base
oscar	cmarkea/distilcamembert-base
oscar	asafaya/bert-base-arabic
oscar	onlplab/alephbert-base
oscar	sonoisa/t5-base-japanese
oscar	pdelobelle/robbert-v2-dutch-base
oscar	deepset/gbert-large
oscar	deepset/gelectra-large
oscar	racai/distilbert-base-romanian-uncased
oscar	lanwuwei/GigaBERT-v3-Arabic-and-English
oscar	asafaya/bert-large-arabic
oscar	gerulata/slovakbert
oscar	sagorsarker/bangla-bert-base
oscar	yongzx/gpt2-finetuned-oscar-ko
oscar	abinayam/gpt-2-tamil
oscar	asafaya/bert-mini-arabic
oscar	sonoisa/byt5-small-japanese
oscar	Recognai/selectra_small
oscar	tau/tavbert-he
oscar	ibraheemmoosa/xlmindic-base-uniscript
oscar	Recognai/selectra_medium
oscar	asafaya/bert-medium-arabic
oscar	racai/distilbert-base-romanian-cased
oscar	deepset/gelectra-large-generator
oscar	flax-community/gpt2-base-thai
oscar	yongzx/gpt2-finetuned-oscar-fr-ori-tok
oscar	yellowback/gpt-neo-japanese-1.3B
oscar	yongzx/gpt2-finetuned-oscar-fr
oscar	yongzx/gpt2-finetuned-oscar-de
oscar	flax-community/arabic-t5-small
oscar	jhu-clsp/roberta-large-eng-ara-128k
oscar	sonoisa/vl-t5-base-japanese
oscar	biu-nlp/alephbert-base
oscar	ChristopherA08/IndoELECTRA
oscar	flax-community/gpt-2-spanish
oscar	DTAI-KULeuven/robbertje-1-gb-bort
oscar	DTAI-KULeuven/robbertje-1-gb-shuffled
oscar	flax-community/gpt-2-tamil
oscar	flax-community/indonesian-roberta-large
oscar	neurocode/IsRoBERTa
oscar	keshan/SinhalaBERTo
oscar	Andrija/SRoBERTa-F
oscar	ibraheemmoosa/xlmindic-base-multiscript-soham
oscar	Andrija/SRoBERTa-base
oscar	keshan/sinhala-roberta-oscar
oscar	DataikuNLP/camembert-base
oscar	Andrija/SRoBERTa-L
oscar	ibraheemmoosa/xlmindic-base-multiscript
oscar	birgermoell/t5-base-swedish
oscar	flax-community/indonesian-roberta-base
oscar	pere/nb-nn-translation
oscar	DTAI-KULeuven/robbertje-1-gb-non-shuffled
oscar	jirmauritz/robbert-v2-dutch-base
oscar	Andrija/SRoBERTa-XL
oscar	pere/nb-nn-dev
oscar	w11wo/malaysian-distilbert-small
oscar	sarahlintang/IndoBERT
oscar	sgugger/esberto-small
oscar	asafaya/albert-base-arabic
oscar	asafaya/albert-xlarge-arabic
oscar	ibraheemmoosa/xlmindic-base-uniscript-soham
oscar	DTAI-KULeuven/robbertje-1-gb-merged
oscar	pere/nb-nn-dev2
oscar	flax-community/mongolian-gpt2
oscar	gsarti/it5-base-oscar
oscar	pere/norwegian-t5
oscar	SebastianS/dummy-model
oscar	asafaya/albert-large-arabic
oscar	StevenLimcorn/MelayuBERT
oscar	racai/distilbert-multi-base-romanian-cased
oscar	SaulLu/albert-bn-dev
oscar	edugp/kenlm
oscar	pere/norwegian-gpt2
# dataset: para_crawl --> 0 models
# dataset: para_pat --> 0 models
# dataset: parsinlu_reading_comprehension --> 1 models
parsinlu_reading_comprehension	m3hrdadfi/gpt2-persian-qa
# dataset: pass --> 0 models
# dataset: paws-x --> 0 models
# dataset: paws --> 1 models
paws	eugenesiow/bart-paraphrase
# dataset: pec --> 0 models
# dataset: peer_read --> 0 models
# dataset: peoples_daily_ner --> 0 models
# dataset: per_sent --> 0 models
# dataset: persian_ner --> 0 models
# dataset: pg19 --> 0 models
# dataset: php --> 0 models
# dataset: piaf --> 6 models
piaf	etalab-ia/camembert-base-squadFR-fquad-piaf
piaf	etalab-ia/dpr-question_encoder-fr_qa-camembert
piaf	etalab-ia/dpr-ctx_encoder-fr_qa-camembert
piaf	JDBN/t5-base-fr-qg-fquad
piaf	lincoln/barthez-squadFR-fquad-piaf-question-generation
piaf	lincoln/camembert-squadFR-fquad-piaf-answer-extraction
# dataset: pib --> 3 models
pib	vasudevgupta/mbart-iitb-hin-eng
pib	vasudevgupta/mbart-bhasha-guj-eng
pib	vasudevgupta/mbart-bhasha-hin-eng
# dataset: piqa --> 0 models
# dataset: pn_summary --> 0 models
# dataset: poem_sentiment --> 0 models
# dataset: polemo2 --> 0 models
# dataset: poleval2019_cyberbullying --> 0 models
# dataset: poleval2019_mt --> 0 models
# dataset: polsum --> 0 models
# dataset: polyglot_ner --> 0 models
# dataset: prachathai67k --> 0 models
# dataset: pragmeval --> 0 models
# dataset: proto_qa --> 0 models
# dataset: psc --> 0 models
# dataset: ptb_text_only --> 0 models
# dataset: pubmed --> 5 models
pubmed	bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12
pubmed	jakelever/coronabert
pubmed	raynardj/roberta-pubmed
pubmed	fbaigt/procbert
pubmed	fbaigt/proc_roberta
# dataset: pubmed_qa --> 0 models
# dataset: py_ast --> 0 models
# dataset: qa4mre --> 0 models
# dataset: qa_srl --> 0 models
# dataset: qa_zre --> 0 models
# dataset: qangaroo --> 0 models
# dataset: qanta --> 0 models
# dataset: qasc --> 1 models
qasc	mrm8488/t5-base-finetuned-qasc
# dataset: qasper --> 0 models
# dataset: qed --> 0 models
# dataset: qed_amara --> 0 models
# dataset: quac --> 0 models
# dataset: quail --> 2 models
quail	AdapterHub/bert-base-uncased-pf-quail
quail	AdapterHub/roberta-base-pf-quail
# dataset: quarel --> 1 models
quarel	mrm8488/t5-base-finetuned-quarel
# dataset: quartz --> 3 models
quartz	AdapterHub/bert-base-uncased-pf-quartz
quartz	mrm8488/t5-base-finetuned-quartz
quartz	AdapterHub/roberta-base-pf-quartz
# dataset: quora --> 5 models
quora	mrm8488/t5-small-finetuned-quora-for-paraphrasing
quora	eugenesiow/bart-paraphrase
quora	navteca/quora-roberta-base
quora	hetpandya/t5-small-quora
quora	navteca/quora-roberta-large
# dataset: quoref --> 6 models
quoref	AdapterHub/bert-base-uncased-pf-quoref
quoref	nielsr/coref-bert-base
quoref	nielsr/coref-bert-large
quoref	AdapterHub/roberta-base-pf-quoref
quoref	nielsr/coref-roberta-large
quoref	nielsr/coref-roberta-base
# dataset: race --> 11 models
race	LIAMF-USP/roberta-large-finetuned-race
race	voidful/bart-distractor-generation-pm
race	LIAMF-USP/aristo-roberta
race	voidful/bart-distractor-generation-both
race	voidful/bart-distractor-generation
race	AdapterHub/bert-base-uncased-pf-race
race	russab0/distilbert-qa
race	mamlong34/t5_large_race_cosmos_qa
race	SvPolina/bert-base-uncased-finetuned-arc
race	AdapterHub/roberta-base-pf-race
race	mamlong34/t5_base_race_cosmos_qa
# dataset: re_dial --> 0 models
# dataset: reasoning_bg --> 0 models
# dataset: recipe_nlg --> 0 models
# dataset: reclor --> 0 models
# dataset: red_caps --> 0 models
# dataset: reddit --> 0 models
# dataset: reddit_tifu --> 0 models
# dataset: refresd --> 0 models
# dataset: reuters21578 --> 0 models
# dataset: riddle_sense --> 0 models
# dataset: ro_sent --> 0 models
# dataset: ro_sts --> 0 models
# dataset: ro_sts_parallel --> 0 models
# dataset: roman_urdu --> 0 models
# dataset: ronec --> 1 models
ronec	dumitrescustefan/bert-base-romanian-ner
# dataset: ropes --> 0 models
# dataset: rotten_tomatoes --> 2 models
rotten_tomatoes	AdapterHub/bert-base-uncased-pf-rotten_tomatoes
rotten_tomatoes	AdapterHub/roberta-base-pf-rotten_tomatoes
# dataset: russian_super_glue --> 0 models
# dataset: s2orc --> 1 models
s2orc	malteos/scincl
# dataset: samsum --> 20 models
samsum	philschmid/bart-large-cnn-samsum
samsum	lidiya/bart-large-xsum-samsum
samsum	philschmid/distilbart-cnn-12-6-samsum
samsum	philschmid/bart-base-samsum
samsum	linydub/bart-large-samsum
samsum	lidiya/bart-base-samsum
samsum	slauw87/bart_summarisation
samsum	knkarthick/bart-large-xsum-samsum
samsum	Kirili4ik/mbart_ruDialogSum
samsum	knkarthick/meeting-summary-samsum
samsum	henryu-lin/t5-large-samsum-deepspeed
samsum	lvwerra/pegasus-samsum
samsum	transformersbook/pegasus-samsum
samsum	jpcorb20/pegasus-large-reddit_tifu-samsum-256
samsum	henryu-lin/t5-3b-samsum-deepspeed
samsum	jpcorb20/pegasus-large-reddit_tifu-samsum-512
samsum	Mapcar/pegasus-samsum
samsum	carlosaguayo/pegasus-samsum
samsum	abdelkader/pegasus-samsum
samsum	jackieliu930/bart-large-cnn-samsum
# dataset: sanskrit_classic --> 0 models
# dataset: saudinewsnet --> 0 models
# dataset: sberquad --> 1 models
sberquad	AndrewChar/model-QA-5-epoch-RU
# dataset: scan --> 0 models
# dataset: scb_mt_enth_2020 --> 0 models
# dataset: scene_parse_150 --> 7 models
scene_parse_150	microsoft/beit-base-finetuned-ade-640-640
scene_parse_150	nvidia/segformer-b0-finetuned-ade-512-512
scene_parse_150	nvidia/segformer-b5-finetuned-ade-640-640
scene_parse_150	nvidia/segformer-b1-finetuned-ade-512-512
scene_parse_150	microsoft/beit-large-finetuned-ade-640-640
scene_parse_150	nvidia/segformer-b2-finetuned-ade-512-512
scene_parse_150	nvidia/segformer-b4-finetuned-ade-512-512
# dataset: schema_guided_dstc8 --> 0 models
# dataset: scicite --> 2 models
scicite	AdapterHub/bert-base-uncased-pf-scicite
scicite	AdapterHub/roberta-base-pf-scicite
# dataset: scielo --> 0 models
# dataset: scientific_papers --> 6 models
scientific_papers	google/bigbird-pegasus-large-arxiv
scientific_papers	google/bigbird-pegasus-large-pubmed
scientific_papers	allenai/led-large-16384-arxiv
scientific_papers	patrickvonplaten/led-large-16384-pubmed
scientific_papers	mse30/bart-base-finetuned-pubmed
scientific_papers	mse30/bart-base-finetuned-arxiv
# dataset: scifact --> 0 models
# dataset: sciq --> 0 models
# dataset: scitail --> 2 models
scitail	AdapterHub/bert-base-uncased-pf-scitail
scitail	AdapterHub/roberta-base-pf-scitail
# dataset: scitldr --> 1 models
scitldr	lrakotoson/scitldr-catts-xsum-ao
# dataset: search_qa --> 0 models
# dataset: sede --> 0 models
# dataset: selqa --> 0 models
# dataset: sem_eval_2010_task_8 --> 0 models
# dataset: sem_eval_2014_task_1 --> 0 models
# dataset: sem_eval_2018_task_1 --> 0 models
# dataset: sem_eval_2020_task_11 --> 0 models
# dataset: sent_comp --> 0 models
# dataset: senti_lex --> 0 models
# dataset: senti_ws --> 0 models
# dataset: sentiment140 --> 0 models
# dataset: sepedi_ner --> 0 models
# dataset: sesotho_ner_corpus --> 0 models
# dataset: setimes --> 1 models
setimes	julien-c/fasttext-language-id
# dataset: setswana_ner_corpus --> 0 models
# dataset: sharc --> 0 models
# dataset: sharc_modified --> 0 models
# dataset: sick --> 2 models
sick	AdapterHub/bert-base-uncased-pf-sick
sick	AdapterHub/roberta-base-pf-sick
# dataset: silicone --> 0 models
# dataset: simple_questions_v2 --> 0 models
# dataset: siswati_ner_corpus --> 0 models
# dataset: smartdata --> 0 models
# dataset: sms_spam --> 2 models
sms_spam	mrm8488/bert-tiny-finetuned-sms-spam-detection
sms_spam	mariagrandury/roberta-base-finetuned-sms-spam-detection
# dataset: snips_built_in_intents --> 0 models
# dataset: snli --> 16 models
snli	cross-encoder/nli-distilroberta-base
snli	ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli
snli	cross-encoder/nli-MiniLM2-L6-H768
snli	cross-encoder/nli-deberta-base
snli	cross-encoder/nli-roberta-base
snli	cross-encoder/nli-deberta-v3-base
snli	cross-encoder/nli-deberta-v3-large
snli	cross-encoder/nli-deberta-v3-xsmall
snli	cross-encoder/nli-deberta-v3-small
snli	AdapterHub/bert-base-uncased-pf-snli
snli	usc-isi/sbert-roberta-large-anli-mnli-snli
snli	AdapterHub/roberta-base-pf-snli
snli	lighteternal/nli-xlm-r-greek
snli	persiannlp/mt5-base-parsinlu-snli-entailment
snli	persiannlp/mt5-small-parsinlu-snli-entailment
snli	persiannlp/mt5-large-parsinlu-snli-entailment
# dataset: snow_simplified_japanese_corpus --> 0 models
# dataset: so_stacksample --> 0 models
# dataset: social_bias_frames --> 0 models
# dataset: social_i_qa --> 2 models
social_i_qa	AdapterHub/bert-base-uncased-pf-social_i_qa
social_i_qa	AdapterHub/roberta-base-pf-social_i_qa
# dataset: sofc_materials_articles --> 0 models
# dataset: sogou_news --> 0 models
# dataset: spanish_billion_words --> 0 models
# dataset: spc --> 0 models
# dataset: species_800 --> 0 models
# dataset: speech_commands --> 0 models
# dataset: spider --> 6 models
spider	tscholak/3vnuv1vf
spider	tscholak/cxmefzzi
spider	tscholak/1wnr382e
spider	tscholak/1zha5ono
spider	tscholak/2e826ioa
spider	tscholak/2jrayxos
# dataset: squad --> 178 models
squad	distilbert-base-uncased-distilled-squad
squad	distilbert-base-cased-distilled-squad
squad	nguyenvulebinh/vi-mrc-base
squad	valhalla/t5-base-qa-qg-hl
squad	valhalla/t5-small-qg-hl
squad	pierreguillou/bert-base-cased-squad-v1.1-portuguese
squad	valhalla/t5-small-qa-qg-hl
squad	valhalla/t5-small-e2e-qg
squad	valhalla/t5-base-e2e-qg
squad	mrm8488/t5-base-finetuned-question-generation-ap
squad	valhalla/bart-large-finetuned-squadv1
squad	thatdramebaazguy/roberta-base-squad
squad	csarron/bert-base-uncased-squad-v1
squad	valhalla/t5-base-qg-hl
squad	valhalla/distilt5-qa-qg-hl-12-6
squad	csarron/roberta-base-squad-v1
squad	pierreguillou/bert-large-cased-squad-v1.1-portuguese
squad	ThomasNLG/t5-qg_squad1-en
squad	salti/bert-base-multilingual-cased-finetuned-squad
squad	fgaim/t5-small-squad-v2
squad	microsoft/prophetnet-large-uncased-squad-qg
squad	ThomasNLG/t5-weighter_cnndm-en
squad	valhalla/distilt5-qg-hl-6-4
squad	madlag/bert-base-uncased-squadv1-x2.44-f87.7-d26-hybrid-filled-v1
squad	pierreguillou/t5-base-qa-squad-v1.1-portuguese
squad	keras-io/transformers-qa
squad	ThomasSimonini/t5-end2end-question-generation
squad	MarcBrun/ixambert-finetuned-squad
squad	csarron/mobilebert-uncased-squad-v1
squad	huggingface-course/bert-finetuned-squad
squad	asahi417/lmqg-t5-small-squad-multitask
squad	Palak/microsoft_deberta-base_squad
squad	madlag/bert-base-uncased-squadv1-x1.96-f88.3-d27-hybrid-filled-opt-v1
squad	fadhilarkan/t5-small-finetuned-xsum-2
squad	p208p2002/bart-squad-qg-hl
squad	p208p2002/gpt2-squad-nqg-hl
squad	AdapterHub/bert-base-uncased-pf-squad
squad	persiannlp/mt5-base-parsinlu-squad-reading-comprehension
squad	p208p2002/gpt2-squad-qg-hl
squad	nguyenvulebinh/vi-mrc-large
squad	anas-awadalla/bert-small-finetuned-squad
squad	madlag/bert-base-uncased-squadv1-x1.84-f88.7-d36-hybrid-filled-v1
squad	anukaver/xlm-roberta-est-qa
squad	persiannlp/mt5-small-parsinlu-squad-reading-comprehension
squad	philschmid/distilbert-onnx
squad	madlag/bert-base-uncased-squadv1-x2.32-f86.6-d15-hybrid-v1
squad	Firat/distilbert-base-uncased-finetuned-squad
squad	valhalla/distilt5-qa-qg-hl-6-4
squad	gpssohi/distilbart-qgen-6-6
squad	jgammack/distilbert-base-uncased-squad
squad	anas-awadalla/bert-tiny-finetuned-squad
squad	Firat/roberta-base-finetuned-squad
squad	Firat/albert-base-v2-finetuned-squad
squad	MaggieXM/distilbert-base-uncased-finetuned-squad
squad	Palak/microsoft_deberta-large_squad
squad	asahi417/lmqg-t5-small-squad
squad	m3hrdadfi/gpt2-QA
squad	jgammack/MTL-distilbert-base-uncased-squad
squad	madlag/bert-base-uncased-squadv1-x2.01-f89.2-d30-hybrid-rewind-opt-v1
squad	gokulkarthik/xlm-roberta-qa-chaii
squad	jgammack/SAE-distilbert-base-uncased-squad
squad	hark99/distilbert-base-uncased-finetuned-squad
squad	lewtun/bert-finetuned-squad
squad	madlag/bert-base-uncased-squad1.1-block-sparse-0.20-v1
squad	p208p2002/bart-squad-nqg-hl
squad	anas-awadalla/roberta-base-few-shot-k-1024-finetuned-squad-seed-42
squad	husnu/electra-small-turkish-uncased-discriminator
squad	anas-awadalla/bert-medium-pretrained-finetuned-squad
squad	jgammack/roberta-base-squad
squad	Palak/albert-large-v2_squad
squad	ZhangCheng/T5-Base-Fine-Tuned-for-Question-Generation
squad	kamilali/distilbert-base-uncased-finetuned-squad
squad	Palak/albert-base-v2_squad
squad	emre/distilbert-base-uncased-finetuned-squad
squad	Palak/distilroberta-base_squad
squad	Palak/xlm-roberta-base_squad
squad	mrm8488/mobilebert-uncased-finetuned-squadv1
squad	persiannlp/mt5-large-parsinlu-squad-reading-comprehension
squad	Palak/google_electra-small-discriminator_squad
squad	Palak/xlm-roberta-large_squad
squad	anas-awadalla/roberta-base-few-shot-k-128-finetuned-squad-seed-42
squad	anas-awadalla/roberta-base-few-shot-k-16-finetuned-squad-seed-42
squad	anas-awadalla/spanbert-base-cased-few-shot-k-1024-finetuned-squad-seed-42
squad	anas-awadalla/spanbert-base-cased-few-shot-k-128-finetuned-squad-seed-42
squad	madlag/bert-base-uncased-squadv1-x1.16-f88.1-d8-unstruct-v1
squad	madlag/bert-base-uncased-squad1.1-block-sparse-0.13-v1
squad	mrp/bert-finetuned-squad
squad	pierreguillou/byt5-small-qa-squad-v1.1-portuguese
squad	sunitha/Trial_3_Results
squad	valhalla/distilt5-qg-hl-12-6
squad	madlag/bert-base-uncased-squad1.1-block-sparse-0.07-v1
squad	mrm8488/RuPERTa-base-finetuned-squadv1
squad	ncduy/distilbert-base-cased-distilled-squad-finetuned-squad-small
squad	sontn122/xlm-roberta-large-finetuned-squad
squad	victoraavila/bert-base-uncased-finetuned-squad
squad	Palak/google_electra-base-discriminator_squad
squad	gpssohi/distilbart-qgen-3-3
squad	hankzhong/electra-small-discriminator-finetuned-squad
squad	jgammack/MTL-bert-base-uncased-ww-squad
squad	BatuhanYilmaz/distilbert-base-uncased-finetuned-squad-d5716d28
squad	MaggieXM/deberta-base-finetuned-squad
squad	SEISHIN/distilbert-base-uncased-finetuned-squad
squad	Sonny/distilbert-base-uncased-finetuned-squad-d5716d28
squad	anas-awadalla/spanbert-base-cased-few-shot-k-16-finetuned-squad-seed-42
squad	jgammack/SAE-roberta-base-squad
squad	kaporter/bert-base-uncased-finetuned-squad
squad	mbateman/distilbert-base-uncased-finetuned-squad-d5716d28
squad	AdapterHub/roberta-base-pf-squad
squad	AyushPJ/test-squad-trained-finetuned-squad
squad	SupriyaArun/distilbert-base-uncased-finetuned-squad
squad	ZhangCheng/T5v1.1-Base-Fine-Tuned-for-Question-Generation
squad	anas-awadalla/bert-base-uncased-few-shot-k-1024-finetuned-squad-seed-42
squad	anas-awadalla/bert-base-uncased-few-shot-k-128-finetuned-squad-seed-42
squad	anas-awadalla/bert-base-uncased-few-shot-k-16-finetuned-squad-seed-42
squad	anas-awadalla/bert-small-pretrained-finetuned-squad
squad	andi611/distilbert-base-uncased-squad
squad	ericRosello/bert-base-uncased-finetuned-squad-frozen-v2
squad	ericRosello/distilbert-base-uncased-finetuned-squad-frozen-v1
squad	husnu/electra-small-turkish-uncased-discriminator-finetuned_lr-2e-05_epochs-3
squad	husnu/xtremedistil-l6-h256-uncased-finetuned_lr-2e-05_epochs-3
squad	jatinshah/bert-finetuned-squad
squad	kaggleodin/distilbert-base-uncased-finetuned-squad
squad	knlu1016/albert-base-v2-finetuned-squad
squad	madlag/bert-base-uncased-squad-v1-sparse0.25
squad	madlag/bert-base-uncased-squad1.1-block-sparse-0.32-v1
squad	mrm8488/squeezebert-finetuned-squadv1
squad	p208p2002/t5-squad-qg-hl
squad	pixyz/distilbert-base-uncased-finetuned-squad
squad	ptnv-s/biobert_squad2_cased-finetuned-squad
squad	rpv/distilbert-base-uncased-finetuned-squad
squad	sunitha/distilbert-base-uncased-3feb-2022-finetuned-squad
squad	Hoang/distilbert-base-uncased-finetuned-squad
squad	Seongkyu/bert-base-cased-finetuned-squad
squad	Sourabh714/distilbert-base-uncased-finetuned-squad
squad	SupriyaArun/bert-base-uncased-finetuned-squad
squad	SupriyaArun/squeezebert-uncased-finetuned-squad-finetuned-squad
squad	anas-awadalla/bert-medium-pretrained-on-squad
squad	anas-awadalla/bert-small-pretrained-on-squad
squad	ericRosello/distilbert-base-uncased-finetuned-squad-frozen-v2
squad	fadhilarkan/distilbert-base-uncased-finetuned-squad
squad	fadhilarkan/t5-small-finetuned-xsum
squad	gokulkarthik/distilbert-base-uncased-finetuned-squad
squad	lewtun/distilbert-base-uncased-finetuned-squad-d5716d28
squad	lucasresck/distilbert-base-uncased-finetuned-squad
squad	marioarteaga/distilbert-base-uncased-finetuned-squad
squad	mrm8488/t5-small-finetuned-squadv1
squad	oo/distilbert-base-uncased-finetuned-squad
squad	p208p2002/t5-squad-nqg-hl
squad	tabo/checkpoint-500-finetuned-squad
squad	tiennvcs/distilbert-base-uncased-finetuned-squad
squad	vitusya/distilbert-base-uncased-finetuned-squad
squad	MYX4567/distilbert-base-uncased-finetuned-squad
squad	Rachneet/t5-base-qg-hl-squadv2
squad	SupriyaArun/squeezebert-uncased-finetuned-squad
squad	Thitaree/distilbert-base-uncased-finetuned-squad
squad	V3RX2000/distilbert-base-uncased-finetuned-squad
squad	avioo1/distilbert-base-uncased-finetuned-squad
squad	aychang/bert-large-cased-whole-word-masking-finetuned-squad
squad	aychang/distilbert-squad
squad	bhan/distilbert-base-uncased-finetuned-squad
squad	en/distilbert-base-uncased-finetuned-squad
squad	ericRosello/bert-base-uncased-finetuned-squad-frozen-v1
squad	hiiii23/distilbert-base-uncased-finetuned-squad
squad	husnu/bert-base-turkish-128k-cased-finetuned_lr-2e-05_epochs-3
squad	husnu/bert-base-turkish-128k-cased-finetuned_lr-2e-05_epochs-3TQUAD2-finetuned_lr-2e-05_epochs-1
squad	husnu/xtremedistil-l6-h256-uncased-TQUAD-finetuned_lr-2e-05_epochs-3
squad	husnu/xtremedistil-l6-h256-uncased-TQUAD-finetuned_lr-2e-05_epochs-6
squad	husnu/xtremedistil-l6-h256-uncased-TQUAD-finetuned_lr-2e-05_epochs-9
squad	husnu/xtremedistil-l6-h256-uncased-finetuned_lr-2e-05_epochs-6
squad	kenlevine/distilbert-base-uncased-finetuned-squad
squad	nehamj/distilbert-base-uncased-finetuned-squad
squad	nikcook/distilbert-base-uncased-finetuned-squad
squad	shivkumarganesh/distilbert-base-uncased-finetuned-squad
squad	superb-test-user/distilbert-base-uncased-finetuned-squad-d5716d28
squad	suzuki/distilbert-base-uncased-finetuned-squad
squad	tabo/distilbert-base-uncased-finetuned-squad2
squad	tucan9389/distilbert-base-uncased-finetuned-squad
squad	youngjae/bert-finetuned-squad
# dataset: squad_adversarial --> 0 models
# dataset: squad_es --> 6 models
squad_es	jamarju/roberta-large-bne-squad-2.0-es
squad_es	jamarju/roberta-base-bne-squad-2.0-es
squad_es	MMG/bert-base-spanish-wwm-cased-finetuned-sqac-finetuned-squad
squad_es	MMG/bert-base-spanish-wwm-cased-finetuned-squad2-es
squad_es	mrm8488/t5-small-spanish-finetuned-squadv1
squad_es	MMG/bert-base-spanish-wwm-cased-finetuned-sqac-finetuned-squad2-es
# dataset: squad_it --> 0 models
# dataset: squad_kor_v1 --> 2 models
squad_kor_v1	arogyaGurkha/kobert-finetuned-squad_kor_v1
squad_kor_v1	arogyaGurkha/koelectra-base-discriminator-finetuned-squad_kor_v1
# dataset: squad_kor_v2 --> 0 models
# dataset: squad_v1_pt --> 4 models
squad_v1_pt	pierreguillou/bert-base-cased-squad-v1.1-portuguese
squad_v1_pt	pierreguillou/bert-large-cased-squad-v1.1-portuguese
squad_v1_pt	pierreguillou/t5-base-qa-squad-v1.1-portuguese
squad_v1_pt	mrm8488/bert-base-portuguese-cased-finetuned-squad-v1-pt
# dataset: squad_v2 --> 60 models
squad_v2	deepset/roberta-base-squad2
squad_v2	deepset/minilm-uncased-squad2
squad_v2	deepset/xlm-roberta-large-squad2
squad_v2	deepset/electra-base-squad2
squad_v2	deepset/xlm-roberta-base-squad2
squad_v2	mrm8488/longformer-base-4096-finetuned-squadv2
squad_v2	ThomasNLG/t5-qa_squad2neg-en
squad_v2	deepset/bert-base-uncased-squad2
squad_v2	mrm8488/t5-base-finetuned-squadv2
squad_v2	deepset/roberta-base-squad2-distilled
squad_v2	navteca/roberta-base-squad2
squad_v2	kiri-ai/t5-base-qa-summary-emotion
squad_v2	navteca/roberta-large-squad2
squad_v2	mrm8488/t5-small-finetuned-squadv2
squad_v2	deepset/tinyroberta-squad2
squad_v2	deepset/tinybert-6l-768d-squad2
squad_v2	deepset/bert-medium-squad2-distilled
squad_v2	mvonwyl/distilbert-base-uncased-finetuned-squad2
squad_v2	hogger32/xlmRoberta-for-VietnameseQA
squad_v2	nlpconnect/roberta-base-squad2-nq
squad_v2	nbroad/mt5-small-qgen
squad_v2	csarron/mobilebert-uncased-squad-v2
squad_v2	AdapterHub/bert-base-uncased-pf-squad_v2
squad_v2	madlag/bert-large-uncased-wwm-squadv2-x2.63-f82.6-d16-hybrid-v1
squad_v2	AdapterHub/roberta-base-pf-squad_v2
squad_v2	a-ware/xlmroberta-squadv2
squad_v2	madlag/bert-large-uncased-wwm-squadv2-x2.15-f83.2-d25-hybrid-v1
squad_v2	a-ware/roberta-large-squad-classification
squad_v2	abhilash1910/albert-squad-v2
squad_v2	a-ware/bart-squadv2
squad_v2	nbroad/deberta-v3-xsmall-squad2
squad_v2	gerardozq/biobert_v1.1_pubmed-finetuned-squad
squad_v2	bigwiz83/sapbert-from-pubmedbert-squad2
squad_v2	mrm8488/mobilebert-uncased-finetuned-squadv2
squad_v2	aodiniz/bert_uncased_L-10_H-512_A-8_cord19-200616_squad2
squad_v2	ThomasNLG/t5-qg_webnlg_synth-en
squad_v2	mrm8488/RuPERTa-base-finetuned-squadv2
squad_v2	navteca/electra-base-squad2
squad_v2	deepset/xlm-roberta-base-squad2-distilled
squad_v2	ThomasNLG/t5-qa_webnlg_synth-en
squad_v2	sontn122/xlm-roberta-large-finetuned-squad-v2_15102021
squad_v2	andi611/bert-large-uncased-whole-word-masking-squad2-with-ner-conll2003-with-neg-with-repeat
squad_v2	andi611/bert-large-uncased-whole-word-masking-squad2-with-ner-Pwhatisthe-conll2003-with-neg-with-repeat
squad_v2	andi611/bert-large-uncased-whole-word-masking-squad2-with-ner-mit-restaurant-with-neg-with-repeat
squad_v2	PremalMatalia/roberta-base-best-squad2
squad_v2	hogger32/distilbert-base-uncased-finetuned-squad
squad_v2	Plimpton/distilbert-base-uncased-finetuned-squad
squad_v2	PremalMatalia/albert-base-best-squad2
squad_v2	PremalMatalia/electra-base-best-squad2
squad_v2	Raphaelg9/distilbert-base-uncased-finetuned-squad
squad_v2	andi611/bert-large-uncased-whole-word-masking-squad2-with-ner-mit-movie-with-neg-with-repeat
squad_v2	mvonwyl/roberta-base-finetuned-squad2
squad_v2	sontn122/xlm-roberta-large-finetuned-squad-v2
squad_v2	Akari/albert-base-v2-finetuned-squad
squad_v2	andi611/distilbert-base-uncased-squad2-with-ner-mit-restaurant-with-neg-with-repeat
squad_v2	princebansal42/distilbert-base-uncased-finetuned-squad
squad_v2	andi611/bert-large-uncased-whole-word-masking-squad2-with-ner-Pistherea-conll2003-with-neg-with-repeat
squad_v2	bengul/bert-base-uncased-finetuned-squad
squad_v2	bgfruna/double-bart-ensemble-squad2
squad_v2	mrm8488/squeezebert-finetuned-squadv2
# dataset: squadshifts --> 0 models
# dataset: srwac --> 3 models
srwac	Andrija/SRoBERTa-F
srwac	Andrija/SRoBERTa-L
srwac	Andrija/SRoBERTa-XL
# dataset: sst --> 0 models
# dataset: stereoset --> 0 models
# dataset: story_cloze --> 0 models
# dataset: stsb_mt_sv --> 0 models
# dataset: stsb_multi_mt --> 9 models
stsb_multi_mt	hugorosen/flaubert_base_uncased-xnli-sts
stsb_multi_mt	eduardofv/stsb-m-mt-es-distiluse-base-multilingual-cased-v1
stsb_multi_mt	mrm8488/distiluse-base-multilingual-cased-v2-finetuned-stsb_multi_mt-es
stsb_multi_mt	dangvantuan/sentence-camembert-large
stsb_multi_mt	eduardofv/stsb-m-mt-es-distilbert-base-uncased
stsb_multi_mt	T-Systems-onsite/cross-en-fr-roberta-sentence-transformer
stsb_multi_mt	inokufu/flaubert-base-uncased-xnli-sts
stsb_multi_mt	inokufu/bertheo
stsb_multi_mt	T-Systems-onsite/cross-de-fr-roberta-sentence-transformer
# dataset: style_change_detection --> 0 models
# dataset: subjqa --> 0 models
# dataset: super_glue --> 1 models
super_glue	msintaha/bert-base-uncased-finetuned-copa-data-new
# dataset: superb --> 34 models
superb	superb/hubert-large-superb-er
superb	anton-l/wav2vec2-base-ft-keyword-spotting
superb	superb/wav2vec2-base-superb-ks
superb	superb/hubert-base-superb-ks
superb	superb/wav2vec2-base-superb-sid
superb	superb/wav2vec2-base-superb-er
superb	superb/hubert-base-superb-er
superb	superb/wav2vec2-base-superb-ic
superb	superb/wav2vec2-large-superb-er
superb	superb/hubert-base-superb-ic
superb	superb/hubert-large-superb-sid
superb	superb/hubert-base-superb-sid
superb	superb/wav2vec2-large-superb-ic
superb	anton-l/sew-mid-100k-ft-keyword-spotting
superb	superb/wav2vec2-large-superb-ks
superb	superb/wav2vec2-large-superb-sid
superb	superb/hubert-large-superb-ks
superb	anton-l/wav2vec2-base-keyword-spotting
superb	superb/hubert-large-superb-ic
superb	NhatPham/wav2vec2-base-finetuned-ks
superb	addy88/wav2vec2-base-finetuned-ks
superb	anton-l/hubert-base-ft-keyword-spotting
superb	anton-l/wav2vec2-base-finetuned-ks
superb	anton-l/distilhubert-ft-keyword-spotting
superb	leo19941227/superb-s3prl-osanseviero__hubert_base-asr-c61a5cff
superb	lewtun/superb-s3prl-osanseviero__hubert_base-asr-50f7ee76
superb	lewtun/superb-s3prl-osanseviero__hubert_base-asr-ca6de67e
superb	lewtun/superb-s3prl-osanseviero__hubert_base-asr-cbcd177a
superb	lewtun/superb-s3prl-osanseviero__hubert_base-diarization-7f28b8b5
superb	lewtun/superb-s3prl-superb-test-org__test-submission-with-weights-asr-ceaac01d
superb	mishig/test_regex_searchreplace
superb	superb/hubert__508944ac
superb	superb/superb-test-org__test-submission-with-example-expert__d609b3c32044e50e3d5e9067bd97af1b42f04b0e
superb	superb/superb-test-org__test-submission-with-weights__2323d47e588aa02648ac1770568eeaa203431535
# dataset: svhn --> 0 models
# dataset: swag --> 6 models
swag	AdapterHub/bert-base-uncased-pf-swag
swag	AdapterHub/roberta-base-pf-swag
swag	domdomreloaded/bert-base-uncased-finetuned-swag
swag	thyagosme/bert-base-uncased-finetuned-swag
swag	JazibEijaz/bert-base-uncased-finetuned-swag-e1-b16-l5e5
swag	ncduy/bert-base-uncased-finetuned-swag
# dataset: swahili --> 0 models
# dataset: swahili_news --> 0 models
# dataset: swda --> 0 models
# dataset: swedish_medical_ner --> 0 models
# dataset: swedish_ner_corpus --> 0 models
# dataset: swedish_reviews --> 0 models
# dataset: swiss_judgment_prediction --> 0 models
# dataset: tab_fact --> 7 models
tab_fact	google/tapas-base-finetuned-tabfact
tab_fact	google/tapas-large-finetuned-tabfact
tab_fact	nielsr/tapex-large-finetuned-tabfact
tab_fact	google/tapas-mini-finetuned-tabfact
tab_fact	google/tapas-medium-finetuned-tabfact
tab_fact	google/tapas-small-finetuned-tabfact
tab_fact	google/tapas-tiny-finetuned-tabfact
# dataset: tamilmixsentiment --> 2 models
tamilmixsentiment	DeadBeast/emoBERTTamil
tamilmixsentiment	Vasanth/tamil-sentiment-distilbert
# dataset: tanzil --> 0 models
# dataset: tapaco --> 4 models
tapaco	hetpandya/t5-base-tapaco
tapaco	hetpandya/t5-small-tapaco
tapaco	erfan226/persian-t5-paraphraser
tapaco	smangrul/xls-r-mr-model
# dataset: tashkeela --> 0 models
# dataset: taskmaster1 --> 0 models
# dataset: taskmaster2 --> 0 models
# dataset: taskmaster3 --> 0 models
# dataset: tatoeba --> 2 models
tatoeba	smangrul/xls-r-mr-model
tatoeba	julien-c/fasttext-language-id
# dataset: ted_hrlr --> 0 models
# dataset: ted_iwlst2013 --> 0 models
# dataset: ted_multi --> 0 models
# dataset: ted_talks_iwslt --> 0 models
# dataset: telugu_books --> 0 models
# dataset: telugu_news --> 0 models
# dataset: tep_en_fa_para --> 0 models
# dataset: text2log --> 0 models
# dataset: thai_toxicity_tweet --> 0 models
# dataset: thainer --> 0 models
# dataset: thaiqa_squad --> 1 models
thaiqa_squad	Sirinya/wangchanberta-th-squad_test1
# dataset: thaisum --> 0 models
# dataset: the_pile --> 1 models
the_pile	EleutherAI/gpt-neo-1.3B
# dataset: the_pile_books3 --> 0 models
# dataset: the_pile_openwebtext2 --> 0 models
# dataset: the_pile_stack_exchange --> 0 models
# dataset: tilde_model --> 0 models
# dataset: time_dial --> 0 models
# dataset: times_of_india_news_headlines --> 0 models
# dataset: timit_asr --> 17 models
timit_asr	elgeish/wav2vec2-large-lv60-timit-asr
timit_asr	patrickvonplaten/unispeech-large-1500h-cv-timit
timit_asr	patrickvonplaten/wav2vec2-base-timit-fine-tuned
timit_asr	elgeish/wav2vec2-base-timit-asr
timit_asr	patrickvonplaten/distilhubert-timit
timit_asr	patrickvonplaten/sew-small-100k-timit
timit_asr	patrickvonplaten/wav2vec2-random
timit_asr	patrickvonplaten/sew-d-small-100k-ft-timit
timit_asr	patrickvonplaten/sew-d-small-100k-timit
timit_asr	patrickvonplaten/sat-base
timit_asr	patrickvonplaten/wav2vec2-base-repro-timit
timit_asr	denden/new_iloko
timit_asr	patrickvonplaten/unispeech-sat-base-plus-timit-ft
timit_asr	patrickvonplaten/unispeech-sat-large-timit-ft
timit_asr	harshit345/wav2vec2-large-lv60-timit
timit_asr	patrickvonplaten/sew-d-small-100k-ft-timit-2
timit_asr	patrickvonplaten/unispeech-sat-base-timit-ft
# dataset: tiny_shakespeare --> 0 models
# dataset: tlc --> 0 models
# dataset: tmu_gfm_dataset --> 0 models
# dataset: told-br --> 0 models
# dataset: totto --> 0 models
# dataset: trec --> 4 models
trec	AdapterHub/bert-base-uncased-pf-trec
trec	aychang/bert-base-cased-trec-coarse
trec	aychang/distilbert-base-cased-trec-coarse
trec	AdapterHub/roberta-base-pf-trec
# dataset: trivia_qa --> 5 models
trivia_qa	google/bigbird-base-trivia-itc
trivia_qa	google/t5-11b-ssm-tqa
trivia_qa	google/t5-xxl-ssm-tqa
trivia_qa	google/t5-xxl-ssm-tqao
trivia_qa	google/t5-11b-ssm-tqao
# dataset: tsac --> 0 models
# dataset: ttc4900 --> 0 models
# dataset: tunizi --> 0 models
# dataset: tuple_ie --> 0 models
# dataset: turk --> 0 models
# dataset: turkic_xwmt --> 0 models
# dataset: turkish_movie_sentiment --> 0 models
# dataset: turkish_ner --> 0 models
# dataset: turkish_product_reviews --> 0 models
# dataset: turkish_shrinked_ner --> 0 models
# dataset: turku_ner_corpus --> 0 models
# dataset: tweet_eval --> 63 models
tweet_eval	elozano/tweet_sentiment_eval
tweet_eval	elozano/tweet_emotion_eval
tweet_eval	elozano/tweet_offensive_eval
tweet_eval	aXhyra/emotion_trained_1234567
tweet_eval	aXhyra/test_hate_trained_test
tweet_eval	AlekseyDorkin/xlm-roberta-en-ru-emoji
tweet_eval	aXhyra/demo_hate_42
tweet_eval	philschmid/BERT-tweet-eval-emotion
tweet_eval	aXhyra/presentation_sentiment_1234567
tweet_eval	aXhyra/irony_trained_final
tweet_eval	marcolatella/hate_trained
tweet_eval	aXhyra/emotion_trained_31415
tweet_eval	aXhyra/presentation_hate_42
tweet_eval	aXhyra/presentation_irony_42
tweet_eval	marcolatella/tweet_eval_bench
tweet_eval	aXhyra/demo_emotion_42
tweet_eval	aXhyra/demo_hate_31415
tweet_eval	aXhyra/demo_irony_1234567
tweet_eval	aXhyra/demo_sentiment_31415
tweet_eval	aXhyra/hate_trained_1234567
tweet_eval	aXhyra/irony_trained_1234567
tweet_eval	aXhyra/irony_trained_31415
tweet_eval	aXhyra/irony_trained_42
tweet_eval	aXhyra/presentation_emotion_31415
tweet_eval	aXhyra/test_irony_trained_test
tweet_eval	aXhyra/demo_hate_1234567
tweet_eval	aXhyra/demo_irony_31415
tweet_eval	aXhyra/demo_irony_42
tweet_eval	aXhyra/emotion_trained_final
tweet_eval	aXhyra/hate_trained_final
tweet_eval	aXhyra/presentation_emotion_1234567
tweet_eval	aXhyra/presentation_hate_31415
tweet_eval	aXhyra/presentation_sentiment_42
tweet_eval	pietrotrope/hate_trained
tweet_eval	aXhyra/demo_emotion_1234567
tweet_eval	aXhyra/demo_emotion_31415
tweet_eval	aXhyra/demo_sentiment_42
tweet_eval	aXhyra/hate_trained_42
tweet_eval	aXhyra/presentation_emotion_42
tweet_eval	aXhyra/presentation_hate_1234567
tweet_eval	aXhyra/presentation_irony_1234567
tweet_eval	aXhyra/presentation_irony_31415
tweet_eval	aXhyra/presentation_sentiment_31415
tweet_eval	aXhyra/sentiment_trained
tweet_eval	aXhyra/sentiment_trained_42
tweet_eval	aXhyra/test_emotion_trained_test
tweet_eval	marcolatella/hate_trained_1234567
tweet_eval	aXhyra/demo_sentiment_1234567
tweet_eval	aXhyra/irony_trained
tweet_eval	aXhyra/sentiment_trained_1234567
tweet_eval	aXhyra/emotion_trained_42
tweet_eval	aXhyra/hate_trained_31415
tweet_eval	aXhyra/sentiment_trained_31415
tweet_eval	marcolatella/Hps_seed1
tweet_eval	marcolatella/emotion_trained_1234567
tweet_eval	marcolatella/irony_trained
tweet_eval	marcolatella/emotion_trained
tweet_eval	marcolatella/emotion_trained_31415
tweet_eval	marcolatella/emotion_trained_42
tweet_eval	marcolatella/hate_trained_31415
tweet_eval	marcolatella/prova_Classi2
tweet_eval	philschmid/DistilBERT-tweet-eval-emotion
tweet_eval	marcolatella/hate_trained_42
# dataset: tweet_qa --> 1 models
tweet_qa	Narrativa/byt5-base-finetuned-tweet-qa
# dataset: tweets_ar_en_parallel --> 0 models
# dataset: tweets_hate_speech_detection --> 2 models
tweets_hate_speech_detection	Narrativa/byt5-base-tweet-hate-detection
tweets_hate_speech_detection	mrm8488/distilroberta-finetuned-tweets-hate-speech
# dataset: twi_text_c3 --> 0 models
# dataset: twi_wordsim353 --> 0 models
# dataset: tydiqa --> 7 models
tydiqa	wissamantoun/araelectra-base-artydiqa
tydiqa	mrm8488/mT5-small-finetuned-tydiqa-for-xqa
tydiqa	nbroad/mt5-small-qgen
tydiqa	sagorsarker/mbert-bengali-tydiqa-qa
tydiqa	Narrativa/mT5-base-finetuned-tydiQA-xqa
tydiqa	cjrowe/afriberta_base-finetuned-tydiqa
tydiqa	Narrativa/mT5-base-finetuned-tydiQA-question-generation
# dataset: ubuntu_dialogs_corpus --> 0 models
# dataset: udhr --> 0 models
# dataset: um005 --> 0 models
# dataset: un_ga --> 0 models
# dataset: un_multi --> 0 models
# dataset: un_pc --> 0 models
# dataset: universal_dependencies --> 33 models
universal_dependencies	KoichiYasuoka/bert-base-japanese-upos
universal_dependencies	KoichiYasuoka/bert-base-japanese-unidic-luw-upos
universal_dependencies	AdapterHub/bert-base-uncased-pf-ud_deprel
universal_dependencies	AdapterHub/bert-base-uncased-pf-ud_pos
universal_dependencies	KoichiYasuoka/roberta-base-japanese-luw-upos
universal_dependencies	AdapterHub/bert-base-uncased-pf-ud_en_ewt
universal_dependencies	KoichiYasuoka/bert-large-japanese-luw-upos
universal_dependencies	KoichiYasuoka/roberta-base-thai-syllable-upos
universal_dependencies	KoichiYasuoka/bert-base-japanese-luw-upos
universal_dependencies	AdapterHub/roberta-base-pf-ud_en_ewt
universal_dependencies	AdapterHub/roberta-base-pf-ud_deprel
universal_dependencies	KoichiYasuoka/roberta-classical-chinese-base-upos
universal_dependencies	KoichiYasuoka/chinese-bert-wwm-ext-upos
universal_dependencies	KoichiYasuoka/chinese-roberta-base-upos
universal_dependencies	KoichiYasuoka/bert-large-japanese-upos
universal_dependencies	KoichiYasuoka/bert-base-thai-upos
universal_dependencies	KoichiYasuoka/roberta-base-english-upos
universal_dependencies	KoichiYasuoka/roberta-large-japanese-luw-upos
universal_dependencies	KoichiYasuoka/roberta-base-japanese-char-luw-upos
universal_dependencies	KoichiYasuoka/roberta-small-japanese-char-luw-upos
universal_dependencies	KoichiYasuoka/bert-large-japanese-unidic-luw-upos
universal_dependencies	KoichiYasuoka/chinese-roberta-large-upos
universal_dependencies	KoichiYasuoka/roberta-base-thai-spm-upos
universal_dependencies	KoichiYasuoka/xlm-roberta-base-english-upos
universal_dependencies	projecte-aina/roberta-base-ca-cased-pos
universal_dependencies	KoichiYasuoka/roberta-small-japanese-luw-upos
universal_dependencies	KoichiYasuoka/SuPar-Kanbun
universal_dependencies	KoichiYasuoka/roberta-large-japanese-char-luw-upos
universal_dependencies	KoichiYasuoka/roberta-classical-chinese-large-upos
universal_dependencies	KoichiYasuoka/roberta-base-thai-char-upos
universal_dependencies	KoichiYasuoka/roberta-large-english-upos
universal_dependencies	kinit/slovakbert-pos
universal_dependencies	AdapterHub/roberta-base-pf-ud_pos
# dataset: universal_morphologies --> 0 models
# dataset: urdu_fake_news --> 0 models
# dataset: urdu_sentiment_corpus --> 0 models
# dataset: vctk --> 25 models
vctk	espnet/kan-bayashi_vctk_tts_train_full_band_multi_spk_vits_raw_phn_tacotron_g2p_en_no_space_train.total_count.ave
vctk	espnet/kan-bayashi_vctk_gst_fastspeech2
vctk	espnet/kan-bayashi_vctk_full_band_multi_spk_vits
vctk	espnet/kan-bayashi_vctk_tts_train_xvector_tacotron2_raw_phn_tacotron_g2p_en_no_space_train.loss.ave
vctk	espnet/kan-bayashi_vctk_gst_tacotron2
vctk	espnet/kan-bayashi_vctk_gst_xvector_tacotron2
vctk	espnet/kan-bayashi_vctk_tts_train_gst_fastspeech_raw_phn_tacotron_g2p_en_no_space_train.loss.best
vctk	espnet/kan-bayashi_vctk_tts_train_gst_xvector_tacotron2_raw_phn_tacotron_g2p_en_no_space_train.loss.ave
vctk	espnet/kan-bayashi_vctk_multi_spk_vits
vctk	espnet/kan-bayashi_vctk_gst_conformer_fastspeech2
vctk	espnet/kan-bayashi_vctk_gst_fastspeech
vctk	espnet/kan-bayashi_vctk_tts_train_gst_conformer_fastspeech2_raw_phn_tacotron_g2p_en_no_space_train.loss.ave
vctk	espnet/kan-bayashi_vctk_tts_train_xvector_conformer_fastspeech2_transformer_teacher_raw_phn_tacotron_g2p_en_no_space_train.loss.ave
vctk	espnet/kan-bayashi_vctk_gst_transformer
vctk	espnet/kan-bayashi_vctk_gst_xvector_conformer_fastspeech2
vctk	espnet/kan-bayashi_vctk_tts_train_gst_tacotron2_raw_phn_tacotron_g2p_en_no_space_train.loss.best
vctk	espnet/kan-bayashi_vctk_tts_train_xvector_transformer_raw_phn_tacotron_g2p_en_no_space_train.loss.ave
vctk	espnet/kan-bayashi_vctk_gst_xvector_transformer
vctk	espnet/kan-bayashi_vctk_tts_train_gst_fastspeech2_raw_phn_tacotron_g2p_en_no_space_train.loss.ave
vctk	espnet/kan-bayashi_vctk_tts_train_gst_transformer_raw_phn_tacotron_g2p_en_no_space_train.loss.ave
vctk	espnet/kan-bayashi_vctk_tts_train_gst_xvector_conformer_fastspeech2_transformer_teacher_raw_phn_tacotron_g2p_en_no_space_train.loss.ave
vctk	espnet/kan-bayashi_vctk_tts_train_multi_spk_vits_raw_phn_tacotron_g2p_en_no_space_train.total_count.ave
vctk	espnet/kan-bayashi_vctk_xvector_conformer_fastspeech2
vctk	espnet/kan-bayashi_vctk_xvector_tacotron2
vctk	espnet/kan-bayashi_vctk_xvector_transformer
# dataset: vivos --> 4 models
vivos	nguyenvulebinh/wav2vec2-base-vietnamese-250h
vivos	dragonSwing/wav2vec2-base-vn-270h
vivos	dragonSwing/digits-recognizer
vivos	not-tanh/wav2vec2-large-xlsr-53-vietnamese
# dataset: web_nlg --> 0 models
# dataset: web_of_science --> 0 models
# dataset: web_questions --> 4 models
web_questions	google/t5-11b-ssm-wq
web_questions	google/t5-xxl-ssm-wq
web_questions	google/t5-xxl-ssm-wqo
web_questions	google/t5-11b-ssm-wqo
# dataset: weibo_ner --> 0 models
# dataset: wi_locness --> 0 models
# dataset: wider_face --> 0 models
# dataset: wiki40b --> 2 models
wiki40b	megagonlabs/t5-base-japanese-web
wiki40b	megagonlabs/t5-base-japanese-web-8k
# dataset: wiki_asp --> 0 models
# dataset: wiki_atomic_edits --> 0 models
# dataset: wiki_auto --> 0 models
# dataset: wiki_bio --> 0 models
# dataset: wiki_dpr --> 3 models
wiki_dpr	facebook/rag-token-nq
wiki_dpr	facebook/rag-token-base
wiki_dpr	facebook/rag-sequence-nq
# dataset: wiki_hop --> 0 models
# dataset: wiki_lingua --> 2 models
wiki_lingua	deutsche-telekom/mt5-small-sum-de-en-v1
wiki_lingua	cointegrated/rut5-base-absum
# dataset: wiki_movies --> 0 models
# dataset: wiki_qa --> 0 models
# dataset: wiki_qa_ar --> 0 models
# dataset: wiki_snippets --> 0 models
# dataset: wiki_source --> 0 models
# dataset: wiki_split --> 3 models
wiki_split	flax-community/t5-large-wikisplit
wiki_split	flax-community/t5-v1_1-base-wikisplit
wiki_split	flax-community/byt5-base-wikisplit
# dataset: wiki_summary --> 0 models
# dataset: wikiann --> 20 models
wikiann	saattrupdan/nbailab-base-ner-scandi
wikiann	sagorsarker/mbert-bengali-ner
wikiann	crabz/slovakbert-ner
wikiann	vitvit/xlm-roberta-base-finetuned-heb_HebrewSentiment
wikiann	durgaamma2005/indic-transformers-te-distilbert
wikiann	Suchandra/bengali_language_NER
wikiann	birgermoell/ner-swedish-wikiann
wikiann	crabz/bertoslav-limited-ner
wikiann	jimregan/bert-base-irish-cased-v1-finetuned-ner
wikiann	philschmid/distilroberta-base-ner-wikiann
wikiann	transformersbook/xlm-roberta-base-finetuned-panx-all
wikiann	Aleksandar/electra-srb-ner
wikiann	jimregan/BERTreach-finetuned-ner
wikiann	Aleksandar/bert-srb-ner
wikiann	crabz/FERNET-CC_sk-ner
wikiann	Aleksandar/distilbert-srb-ner
wikiann	dbsamu/distilbert-base-uncased-finetuned-ner
wikiann	dbsamu/electra-small-discriminator-finetuned-ner
wikiann	jimregan/electra-base-irish-cased-discriminator-v1-finetuned-ner
wikiann	BillelBenoudjit/jplu-wikiann
# dataset: wikicorpus --> 0 models
# dataset: wikihow --> 0 models
# dataset: wikipedia --> 534 models
wikipedia	bert-base-uncased
wikipedia	distilbert-base-uncased
wikipedia	cl-tohoku/bert-base-japanese-char
wikipedia	roberta-base
wikipedia	bert-base-cased
wikipedia	cl-tohoku/bert-base-japanese-whole-word-masking
wikipedia	cl-tohoku/bert-base-japanese
wikipedia	roberta-large
wikipedia	albert-base-v2
wikipedia	bert-base-multilingual-cased
wikipedia	distilbert-base-cased
wikipedia	bert-large-uncased-whole-word-masking-finetuned-squad
wikipedia	bert-large-uncased
wikipedia	bert-base-multilingual-uncased
wikipedia	xlnet-base-cased
wikipedia	distilbert-base-multilingual-cased
wikipedia	google/bigbird-roberta-base
wikipedia	bert-large-cased
wikipedia	albert-base-v1
wikipedia	bert-large-uncased-whole-word-masking
wikipedia	funnel-transformer/small
wikipedia	aubmindlab/aragpt2-base
wikipedia	aubmindlab/aragpt2-medium
wikipedia	aubmindlab/aragpt2-large
wikipedia	aubmindlab/aragpt2-mega
wikipedia	albert-xxlarge-v2
wikipedia	cl-tohoku/bert-base-japanese-v2
wikipedia	funnel-transformer/medium
wikipedia	dbmdz/bert-base-italian-xxl-cased
wikipedia	deepset/gbert-base
wikipedia	bert-large-cased-whole-word-masking-finetuned-squad
wikipedia	albert-large-v2
wikipedia	asafaya/bert-base-arabic
wikipedia	onlplab/alephbert-base
wikipedia	google/canine-s
wikipedia	dbmdz/bert-base-italian-uncased
wikipedia	xlnet-large-cased
wikipedia	rinna/japanese-roberta-base
wikipedia	facebook/muppet-roberta-base
wikipedia	google/bigbird-roberta-large
wikipedia	Maltehb/danish-bert-botxo
wikipedia	albert-xxlarge-v1
wikipedia	cl-tohoku/bert-base-japanese-char-v2
wikipedia	facebook/muppet-roberta-large
wikipedia	SZTAKI-HLT/hubert-base-cc
wikipedia	sonoisa/t5-base-japanese
wikipedia	cl-tohoku/bert-large-japanese
wikipedia	nlp-waseda/roberta-base-japanese
wikipedia	aubmindlab/bert-base-arabertv02
wikipedia	deepset/gbert-large
wikipedia	rinna/japanese-gpt2-medium
wikipedia	aubmindlab/bert-base-arabert
wikipedia	rinna/japanese-gpt-1b
wikipedia	albert-xlarge-v2
wikipedia	deepmind/language-perceiver
wikipedia	aubmindlab/bert-base-arabertv2
wikipedia	bert-large-cased-whole-word-masking
wikipedia	rinna/japanese-gpt2-xsmall
wikipedia	dbmdz/bert-base-italian-cased
wikipedia	aubmindlab/bert-base-arabertv01
wikipedia	dbmdz/bert-base-italian-xxl-uncased
wikipedia	cl-tohoku/bert-base-japanese-char-whole-word-masking
wikipedia	Geotrend/bert-base-th-cased
wikipedia	deepset/gelectra-base
wikipedia	pierreguillou/gpt2-small-portuguese
wikipedia	aubmindlab/bert-large-arabertv02
wikipedia	google/canine-c
wikipedia	izumi-lab/bert-small-japanese
wikipedia	deepset/gelectra-large
wikipedia	cahya/bert-base-indonesian-522M
wikipedia	dbmdz/electra-base-italian-xxl-cased-discriminator
wikipedia	aubmindlab/bert-base-arabertv02-twitter
wikipedia	allegro/plt5-small
wikipedia	izumi-lab/electra-base-japanese-discriminator
wikipedia	rinna/japanese-gpt2-small
wikipedia	google/rembert
wikipedia	funnel-transformer/intermediate
wikipedia	google/t5-large-ssm
wikipedia	racai/distilbert-base-romanian-uncased
wikipedia	aubmindlab/araelectra-base-discriminator
wikipedia	lanwuwei/GigaBERT-v3-Arabic-and-English
wikipedia	nlp-waseda/gpt2-small-japanese-wikipedia
wikipedia	dbmdz/electra-base-italian-xxl-cased-generator
wikipedia	albert-large-v1
wikipedia	allegro/plt5-base
wikipedia	asafaya/bert-large-arabic
wikipedia	google/t5-large-ssm-nq
wikipedia	gerulata/slovakbert
wikipedia	sagorsarker/bangla-bert-base
wikipedia	aubmindlab/bert-large-arabertv2
wikipedia	Geotrend/bert-base-es-cased
wikipedia	asafaya/bert-mini-arabic
wikipedia	Maltehb/danish-bert-botxo-ner-dane
wikipedia	izumi-lab/electra-small-paper-japanese-fin-discriminator
wikipedia	albert-xlarge-v1
wikipedia	funnel-transformer/small-base
wikipedia	google/t5-small-ssm-nq
wikipedia	Geotrend/bert-base-en-fr-cased
wikipedia	sonoisa/byt5-small-japanese
wikipedia	datificate/gpt2-small-spanish
wikipedia	funnel-transformer/large
wikipedia	izumi-lab/electra-small-paper-japanese-discriminator
wikipedia	amine/bert-base-5lang-cased
wikipedia	qwant/fralbert-base
wikipedia	colorfulscoop/gpt2-small-ja
wikipedia	funnel-transformer/xlarge
wikipedia	Geotrend/distilbert-base-ru-cased
wikipedia	aubmindlab/araelectra-base-generator
wikipedia	izumi-lab/bert-small-japanese-fin
wikipedia	allegro/plt5-large
wikipedia	Geotrend/bert-base-ru-cased
wikipedia	Recognai/distilbert-base-es-multilingual-cased
wikipedia	cahya/bert-base-indonesian-1.5G
wikipedia	asafaya/bert-medium-arabic
wikipedia	funnel-transformer/medium-base
wikipedia	aubmindlab/bert-large-arabertv02-twitter
wikipedia	racai/distilbert-base-romanian-cased
wikipedia	deepset/gelectra-large-generator
wikipedia	Intel/bert-base-uncased-sparse-90-unstructured-pruneofa
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-0k
wikipedia	cahya/distilbert-base-indonesian
wikipedia	Geotrend/distilbert-base-da-cased
wikipedia	jacobshein/danish-bert-botxo-qa-squad
wikipedia	Geotrend/bert-base-lt-cased
wikipedia	deepset/gelectra-base-generator
wikipedia	yellowback/gpt-neo-japanese-1.3B
wikipedia	cl-tohoku/bert-large-japanese-char
wikipedia	sonoisa/t5-base-japanese-mC4-Wikipedia
wikipedia	Finnish-NLP/gpt2-finnish
wikipedia	Geotrend/distilbert-base-es-cased
wikipedia	google/t5-xl-ssm-nq
wikipedia	ufal/byt5-small-multilexnorm2021-en
wikipedia	google/t5-small-ssm
wikipedia	Geotrend/distilbert-base-th-cased
wikipedia	Geotrend/distilbert-base-it-cased
wikipedia	Geotrend/distilbert-base-de-cased
wikipedia	Finnish-NLP/gpt2-medium-finnish
wikipedia	imvladikon/general_character_bert
wikipedia	funnel-transformer/large-base
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-20k
wikipedia	Geotrend/distilbert-base-en-fr-cased
wikipedia	Geotrend/bert-base-fr-cased
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-140k
wikipedia	Geotrend/bert-base-en-de-cased
wikipedia	Intel/bert-large-uncased-sparse-90-unstructured-pruneofa
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-40k
wikipedia	jhu-clsp/roberta-large-eng-ara-128k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-120k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-160k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-100k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-200k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-180k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-300k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-60k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-80k
wikipedia	nielsr/coref-bert-base
wikipedia	sonoisa/vl-t5-base-japanese
wikipedia	Geotrend/distilbert-base-uk-cased
wikipedia	biu-nlp/alephbert-base
wikipedia	mlcorelib/deberta-base-uncased
wikipedia	Geotrend/distilbert-base-fr-cased
wikipedia	Geotrend/distilbert-base-zh-cased
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-400k
wikipedia	izumi-lab/electra-small-japanese-generator
wikipedia	Geotrend/bert-base-it-cased
wikipedia	Geotrend/distilbert-base-nl-cased
wikipedia	mlcorelib/debertav2-base-uncased
wikipedia	Geotrend/distilbert-base-pt-cased
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-700k
wikipedia	Finnish-NLP/roberta-large-finnish-v2
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-600k
wikipedia	nielsr/coref-bert-large
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-500k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-900k
wikipedia	funnel-transformer/intermediate-base
wikipedia	Geotrend/bert-base-ur-cased
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-800k
wikipedia	w11wo/indo-roberta-small
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-1000k
wikipedia	izumi-lab/electra-small-japanese-fin-discriminator
wikipedia	colorfulscoop/bert-base-ja
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-1100k
wikipedia	Geotrend/bert-base-en-cased
wikipedia	Geotrend/bert-base-pt-cased
wikipedia	Intel/bert-base-uncased-sparse-85-unstructured-pruneofa
wikipedia	Geotrend/bert-base-en-zh-cased
wikipedia	Geotrend/distilbert-base-bg-cased
wikipedia	Geotrend/distilbert-base-pl-cased
wikipedia	Geotrend/bert-base-pl-cased
wikipedia	Geotrend/bert-base-uk-cased
wikipedia	Geotrend/distilbert-base-en-fr-de-cased
wikipedia	Geotrend/distilbert-base-en-fr-es-pt-it-cased
wikipedia	Geotrend/bert-base-en-th-cased
wikipedia	Geotrend/bert-base-en-da-cased
wikipedia	Geotrend/bert-base-en-ro-cased
wikipedia	hiroshi-matsuda-rit/bert-base-japanese-basic-char-v2
wikipedia	Geotrend/bert-base-ja-cased
wikipedia	byeongal/bert-base-uncased
wikipedia	imvladikon/charbert-bert-wiki
wikipedia	Geotrend/bert-base-da-cased
wikipedia	Geotrend/distilbert-base-en-fr-de-no-da-cased
wikipedia	izumi-lab/electra-small-japanese-fin-generator
wikipedia	Ferch423/gpt2-small-portuguese-wikipediabio
wikipedia	Geotrend/distilbert-base-ar-cased
wikipedia	Geotrend/distilbert-base-en-fr-it-cased
wikipedia	ysakuramoto/mobilebert-ja
wikipedia	Geotrend/bert-base-sw-cased
wikipedia	Geotrend/distilbert-base-en-ur-cased
wikipedia	Geotrend/distilbert-base-en-zh-cased
wikipedia	Geotrend/distilbert-base-ur-cased
wikipedia	google/t5-11b-ssm-wq
wikipedia	google/t5-xxl-ssm-nq
wikipedia	ufal/byt5-small-multilexnorm2021-iden
wikipedia	yohida/yoshida_gpt
wikipedia	Geotrend/bert-base-de-cased
wikipedia	Geotrend/bert-base-el-cased
wikipedia	Geotrend/bert-base-en-el-cased
wikipedia	Geotrend/bert-base-en-fr-de-no-da-cased
wikipedia	Geotrend/bert-base-tr-cased
wikipedia	Geotrend/distilbert-base-en-no-cased
wikipedia	Geotrend/distilbert-base-vi-cased
wikipedia	ufal/byt5-small-multilexnorm2021-sl
wikipedia	Geotrend/bert-base-25lang-cased
wikipedia	Geotrend/bert-base-en-pl-cased
wikipedia	Geotrend/distilbert-base-el-cased
wikipedia	Geotrend/distilbert-base-en-da-cased
wikipedia	Geotrend/distilbert-base-en-ro-cased
wikipedia	Geotrend/distilbert-base-en-ru-cased
wikipedia	google/t5-3b-ssm-nqo
wikipedia	Barytes/hellohf
wikipedia	Geotrend/bert-base-en-es-it-cased
wikipedia	Geotrend/bert-base-en-es-pt-cased
wikipedia	Geotrend/bert-base-en-vi-cased
wikipedia	Geotrend/bert-base-hi-cased
wikipedia	Geotrend/distilbert-base-25lang-cased
wikipedia	Geotrend/distilbert-base-en-cased
wikipedia	Geotrend/distilbert-base-en-hi-cased
wikipedia	Geotrend/distilbert-base-en-ja-cased
wikipedia	Geotrend/distilbert-base-lt-cased
wikipedia	benyong/testmodel
wikipedia	funnel-transformer/xlarge-base
wikipedia	google/t5-3b-ssm
wikipedia	jirmauritz/bert-multilingual-emoji
wikipedia	ufal/byt5-small-multilexnorm2021-da
wikipedia	Finnish-NLP/roberta-large-finnish
wikipedia	Finnish-NLP/roberta-large-wechsel-finnish
wikipedia	Geotrend/bert-base-bg-cased
wikipedia	Geotrend/bert-base-en-fr-it-cased
wikipedia	Geotrend/bert-base-en-sw-cased
wikipedia	Geotrend/bert-base-en-uk-cased
wikipedia	Geotrend/bert-base-en-zh-hi-cased
wikipedia	Geotrend/bert-base-no-cased
wikipedia	Geotrend/distilbert-base-en-ar-cased
wikipedia	Geotrend/distilbert-base-en-fr-ar-cased
wikipedia	Geotrend/distilbert-base-en-it-cased
wikipedia	google/t5-11b-ssm-tqa
wikipedia	izumi-lab/electra-base-japanese-generator
wikipedia	Geotrend/bert-base-15lang-cased
wikipedia	Geotrend/bert-base-ar-cased
wikipedia	Geotrend/bert-base-en-ar-cased
wikipedia	Geotrend/bert-base-en-el-ru-cased
wikipedia	Geotrend/bert-base-en-fr-uk-el-ro-cased
wikipedia	Geotrend/bert-base-en-fr-zh-cased
wikipedia	Geotrend/bert-base-en-fr-zh-ja-vi-cased
wikipedia	Geotrend/bert-base-en-hi-cased
wikipedia	Geotrend/bert-base-en-ur-cased
wikipedia	Geotrend/bert-base-nl-cased
wikipedia	Geotrend/bert-base-zh-cased
wikipedia	Geotrend/distilbert-base-en-th-cased
wikipedia	Geotrend/distilbert-base-en-zh-hi-cased
wikipedia	Geotrend/distilbert-base-tr-cased
wikipedia	asafaya/albert-base-arabic
wikipedia	izumi-lab/electra-small-paper-japanese-fin-generator
wikipedia	ufal/byt5-small-multilexnorm2021-it
wikipedia	Geotrend/bert-base-en-bg-cased
wikipedia	Geotrend/bert-base-en-fr-ar-cased
wikipedia	Geotrend/bert-base-en-fr-es-de-zh-cased
wikipedia	Geotrend/bert-base-en-no-cased
wikipedia	Geotrend/bert-base-en-tr-cased
wikipedia	Geotrend/bert-base-vi-cased
wikipedia	Geotrend/distilbert-base-en-de-cased
wikipedia	Geotrend/distilbert-base-en-el-ru-cased
wikipedia	Geotrend/distilbert-base-en-es-pt-cased
wikipedia	Geotrend/distilbert-base-en-fr-da-ja-vi-cased
wikipedia	Geotrend/distilbert-base-en-fr-es-cased
wikipedia	Geotrend/distilbert-base-en-fr-es-de-zh-cased
wikipedia	Geotrend/distilbert-base-en-fr-zh-ja-vi-cased
wikipedia	Geotrend/distilbert-base-sw-cased
wikipedia	asafaya/albert-xlarge-arabic
wikipedia	google/t5-11b-ssm-nq
wikipedia	ufal/byt5-small-multilexnorm2021-de
wikipedia	w11wo/indo-gpt2-small
wikipedia	w11wo/javanese-bert-small
wikipedia	Geotrend/bert-base-en-fr-da-ja-vi-cased
wikipedia	Geotrend/bert-base-en-fr-de-cased
wikipedia	Geotrend/bert-base-en-pt-cased
wikipedia	Geotrend/bert-base-ro-cased
wikipedia	Geotrend/distilbert-base-en-bg-cased
wikipedia	Geotrend/distilbert-base-en-pt-cased
wikipedia	Geotrend/distilbert-base-en-tr-cased
wikipedia	Geotrend/distilbert-base-en-uk-cased
wikipedia	Geotrend/distilbert-base-ja-cased
wikipedia	ufal/byt5-small-multilexnorm2021-nl
wikipedia	w11wo/javanese-gpt2-small
wikipedia	w11wo/javanese-roberta-small
wikipedia	DJSammy/bert-base-danish-uncased_BotXO-ai
wikipedia	Geotrend/bert-base-en-es-cased
wikipedia	Geotrend/bert-base-en-fr-es-pt-it-cased
wikipedia	Geotrend/bert-base-en-fr-lt-no-pl-cased
wikipedia	Geotrend/bert-base-en-ja-cased
wikipedia	Geotrend/bert-base-en-nl-cased
wikipedia	Geotrend/distilbert-base-en-es-it-cased
wikipedia	Geotrend/distilbert-base-en-es-zh-cased
wikipedia	Geotrend/distilbert-base-en-fr-zh-cased
wikipedia	Geotrend/distilbert-base-en-nl-cased
wikipedia	Geotrend/distilbert-base-hi-cased
wikipedia	Mary222/made-ai-dungeon
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-1400k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-600k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-120k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-400k
wikipedia	ayansinha/false-positives-scancode-bert-base-uncased-L8-1
wikipedia	google/t5-11b-ssm
wikipedia	izumi-lab/electra-small-japanese-discriminator
wikipedia	izumi-lab/electra-small-paper-japanese-generator
wikipedia	tau/t5-v1_1-large-rss
wikipedia	tftransformers/albert-base-v2
wikipedia	tftransformers/bert-base-cased
wikipedia	tftransformers/bert-large-cased
wikipedia	Geotrend/bert-base-en-fr-nl-ru-ar-cased
wikipedia	Geotrend/bert-base-en-lt-cased
wikipedia	Geotrend/distilbert-base-en-fr-lt-no-pl-cased
wikipedia	Geotrend/distilbert-base-en-fr-nl-ru-ar-cased
wikipedia	Geotrend/distilbert-base-en-lt-cased
wikipedia	Geotrend/distilbert-base-no-cased
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-1300k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-1500k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-1600k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-1100k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-1600k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-300k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-200k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-80k
wikipedia	akahana/roberta-base-indonesia
wikipedia	ayansinha/lic-class-scancode-bert-base-cased-L32-1
wikipedia	google/t5-11b-ssm-nqo
wikipedia	google/t5-3b-ssm-nq
wikipedia	google/t5-xxl-ssm-tqa
wikipedia	ufal/byt5-small-multilexnorm2021-es
wikipedia	ufal/byt5-small-multilexnorm2021-trde
wikipedia	Geotrend/distilbert-base-en-pl-cased
wikipedia	Geotrend/distilbert-base-en-sw-cased
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-1600k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-160k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-1700k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-300k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-400k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-100k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-1100k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-1200k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-1800k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-1300k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-1400k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-180k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-100k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-1700k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-2000k
wikipedia	google/t5-xxl-ssm-wq
wikipedia	google/t5-xxl-ssm-wqo
wikipedia	imvladikon/charbert-roberta-wiki
wikipedia	sramasamy8/testModel
wikipedia	tftransformers/albert-base-v1
wikipedia	w11wo/javanese-distilbert-small
wikipedia	Geotrend/bert-base-10lang-cased
wikipedia	Geotrend/bert-base-en-es-zh-cased
wikipedia	Geotrend/bert-base-en-fr-es-cased
wikipedia	Geotrend/distilbert-base-en-el-cased
wikipedia	Geotrend/distilbert-base-en-es-cased
wikipedia	Geotrend/distilbert-base-en-vi-cased
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-1200k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-1700k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-1900k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-1000k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-1100k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-1300k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-2000k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-200k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1
wikipedia	MultiBertGunjanPatrick/multiberts-seed-11
wikipedia	MultiBertGunjanPatrick/multiberts-seed-17
wikipedia	MultiBertGunjanPatrick/multiberts-seed-19
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-0k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-1400k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-140k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-160k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-1900k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-400k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-40k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-600k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-60k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-800k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-900k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-120k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-1900k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-2000k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-200k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-40k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-800k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-80k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-900k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-1000k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-1200k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-140k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-160k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-1800k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-20k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-40k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-700k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-800k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4
wikipedia	MultiBertGunjanPatrick/multiberts-seed-8
wikipedia	asafaya/albert-large-arabic
wikipedia	google/t5-large-ssm-nqo
wikipedia	google/t5-xxl-ssm-tqao
wikipedia	nielsr/coref-roberta-large
wikipedia	tftransformers/bert-base-uncased
wikipedia	tftransformers/bert-large-uncased-whole-word-masking
wikipedia	ufal/byt5-small-multilexnorm2021-sr
wikipedia	Geotrend/distilbert-base-ro-cased
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-1800k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-2000k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-100k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-1200k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-120k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-140k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-1500k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-1800k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-180k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-500k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-700k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-10
wikipedia	MultiBertGunjanPatrick/multiberts-seed-12
wikipedia	MultiBertGunjanPatrick/multiberts-seed-14
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-1000k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-1500k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-1700k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-2000k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-300k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-500k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-80k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2
wikipedia	MultiBertGunjanPatrick/multiberts-seed-20
wikipedia	MultiBertGunjanPatrick/multiberts-seed-21
wikipedia	MultiBertGunjanPatrick/multiberts-seed-23
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-1000k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-100k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-400k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-700k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-0k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-1300k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-1400k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-1500k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-1600k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-300k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-500k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-600k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-60k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-6
wikipedia	MultiBertGunjanPatrick/multiberts-seed-7
wikipedia	akahana/tiny-roberta-indonesia
wikipedia	flax-community/bigband
wikipedia	google/t5-xxl-ssm-nqo
wikipedia	google/t5-xxl-ssm
wikipedia	nielsr/coref-roberta-base
wikipedia	racai/distilbert-multi-base-romanian-cased
wikipedia	tftransformers/albert-xlarge-v1
wikipedia	tftransformers/albert-xlarge-v2
wikipedia	tftransformers/albert-xxlarge-v1
wikipedia	tftransformers/bert-large-cased-whole-word-masking
wikipedia	tftransformers/bert-large-uncased
wikipedia	Geotrend/bert-base-en-it-cased
wikipedia	Geotrend/bert-base-en-ru-cased
wikipedia	Geotrend/distilbert-base-en-fr-uk-el-ro-cased
wikipedia	MultiBertGunjanPatrick/multiberts-seed-0-1400k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-0k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-1900k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-20k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-40k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-600k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-60k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-800k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-80k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-1-900k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-13
wikipedia	MultiBertGunjanPatrick/multiberts-seed-15
wikipedia	MultiBertGunjanPatrick/multiberts-seed-16
wikipedia	MultiBertGunjanPatrick/multiberts-seed-18
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-120k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-1300k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-1600k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-180k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-200k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-20k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-2-700k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-22
wikipedia	MultiBertGunjanPatrick/multiberts-seed-24
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-0k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-1200k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-140k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-1500k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-160k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-1700k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-1800k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-20k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-500k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-3-60k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-1100k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-180k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-1900k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-4-900k
wikipedia	MultiBertGunjanPatrick/multiberts-seed-5
wikipedia	MultiBertGunjanPatrick/multiberts-seed-9
wikipedia	SaulLu/albert-bn-dev
wikipedia	edugp/kenlm
wikipedia	google/t5-11b-ssm-tqao
wikipedia	google/t5-11b-ssm-wqo
wikipedia	julien-c/fasttext-language-id
wikipedia	kjackson/distilbert-base-uncased-finetuned-emotion
wikipedia	matrix/test
wikipedia	tftransformers/albert-xxlarge-v2
wikipedia	ufal/byt5-small-multilexnorm2021-hr
wikipedia	ufal/byt5-small-multilexnorm2021-tr
# dataset: wikisql --> 11 models
wikisql	mrm8488/t5-base-finetuned-wikiSQL
wikisql	google/tapas-base-finetuned-wikisql-supervised
wikisql	mrm8488/t5-small-finetuned-wikiSQL
wikisql	google/tapas-medium-finetuned-wikisql-supervised
wikisql	google/tapas-large-finetuned-wikisql-supervised
wikisql	dbernsohn/t5_wikisql_en2SQL
wikisql	google/tapas-small-finetuned-wikisql-supervised
wikisql	dbernsohn/t5_wikisql_SQL2en
wikisql	navteca/tapas-large-finetuned-wtq
wikisql	mrm8488/t5-base-finetuned-wikiSQL-sql-to-en
wikisql	nielsr/tapex-large-finetuned-wikisql
# dataset: wikitext --> 1 models
wikitext	mikaelsouza/msft-regular-model
# dataset: wikitext_tl39 --> 0 models
# dataset: wili_2018 --> 2 models
wili_2018	m3hrdadfi/zabanshenas-roberta-base-mix
wili_2018	m3hrdadfi/wili2018-roberta-base
# dataset: wino_bias --> 0 models
# dataset: winograd_wsc --> 4 models
winograd_wsc	nielsr/coref-bert-base
winograd_wsc	nielsr/coref-bert-large
winograd_wsc	nielsr/coref-roberta-large
winograd_wsc	nielsr/coref-roberta-base
# dataset: winogrande --> 3 models
winogrande	AdapterHub/bert-base-uncased-pf-winogrande
winogrande	DeepPavlov/roberta-large-winogrande
winogrande	AdapterHub/roberta-base-pf-winogrande
# dataset: wiqa --> 0 models
# dataset: wisesight1000 --> 0 models
# dataset: wisesight_sentiment --> 1 models
wisesight_sentiment	poom-sci/WangchanBERTa-finetuned-sentiment
# dataset: wmt14 --> 15 models
wmt14	google/bert2bert_L-24_wmt_de_en
wmt14	google/bert2bert_L-24_wmt_en_de
wmt14	rossanez/t5-base-finetuned-de-en
wmt14	rossanez/t5-small-finetuned-de-en-64
wmt14	rossanez/t5-small-finetuned-de-en-batch8
wmt14	rossanez/t5-small-finetuned-de-en-lr2e-4
wmt14	rossanez/t5-small-finetuned-de-en-nofp16
wmt14	rossanez/t5-small-finetuned-de-en-wd-01
wmt14	rossanez/t5-small-finetuned-de-en-256-lr2e-4
wmt14	rossanez/t5-small-finetuned-de-en-256
wmt14	rossanez/t5-small-finetuned-de-en-256-epochs2
wmt14	rossanez/t5-small-finetuned-de-en-256-nofp16
wmt14	rossanez/t5-small-finetuned-de-en-256-wd-01
wmt14	rossanez/t5-small-finetuned-de-en-epochs5
wmt14	rossanez/t5-small-finetuned-de-en-final
# dataset: wmt15 --> 0 models
# dataset: wmt16 --> 39 models
wmt16	allenai/wmt16-en-de-dist-12-1
wmt16	wandemberg-eld/opus-mt-en-de-finetuned-en-to-de
wmt16	allenai/wmt16-en-de-12-1
wmt16	allenai/wmt16-en-de-dist-6-1
wmt16	svsokol/opus-mt-ru-en-finetuned-en-to-ru
wmt16	DiegoAlysson/opus-mt-en-ro-finetuned-en-to-ro
wmt16	alexrfelicio/t5-small-finetuned32-en-to-de
wmt16	eliotm/t5-small-finetuned-en-to-ro-fp16_off
wmt16	fabiogr/opus-mt-en-de-finetuned-en-to-de-wd01-fp16false
wmt16	felipetanios/opus-mt-de-en-finetuned-de-to-en-second
wmt16	marciovbarbosa/t5-small-finetuned-de-to-en-lr3e-4
wmt16	tiagohatta/opus-mt-de-en-finetuned-de-to-en-first
wmt16	alexrfelicio/t5-small-finetuned8-en-to-de
wmt16	marciovbarbosa/t5-small-finetuned-de-to-en-swd
wmt16	MaryaAI/opus-mt-en-ro-finetuned-en-to-ro
wmt16	afreireosorio/opus-mt-en-de-finetuned-en-to-de
wmt16	alexrfelicio/t5-small-finetuned-en-to-de
wmt16	alexrfelicio/t5-small-finetuned128-en-to-de
wmt16	alexrfelicio/t5-small-finetuned16-en-to-de
wmt16	alexrfelicio/t5-small-finetuned300-en-to-de
wmt16	aretw0/t5-small-finetuned-en-to-ro-dataset_20
wmt16	aretw0/t5-small-finetuned-en-to-ro-epoch.04375
wmt16	danhsf/t5-small-finetuned-en-to-ro-lr_2e-3-fp_false
wmt16	marciovbarbosa/t5-small-finetuned-de-to-en-fp16
wmt16	marciovbarbosa/t5-small-finetuned-de-to-en-lr1e-4
wmt16	marciovbarbosa/t5-small-finetuned-de-to-en
wmt16	marcosscarpim/t5-small-finetuned-en-to-ro
wmt16	rtoguchi/t5-small-finetuned-en-to-ro-fp16_off
wmt16	Edomonndo/opus-mt-en-ro-finetuned-en-to-ro
wmt16	Mirelle/t5-small-finetuned-ro-to-en
wmt16	aretw0/t5-small-finetuned-en-to-ro-dataset_20-input_64
wmt16	eliotm/t5-small-finetuned-en-to-ro-LR_1e-3
wmt16	eliotm/t5-small-finetuned-en-to-ro-lr0.001
wmt16	eliotm/t5-small-finetuned-en-to-ro-lr_2e-6
wmt16	ncduy/opus-mt-en-ro-finetuned-en-to-ro
wmt16	rtoguchi/t5-small-finetuned-en-to-ro-fp16_off-lr_2e-7-weight_decay_0.001
wmt16	rtoguchi/t5-small-finetuned-en-to-ro-weight_decay_0.001
wmt16	tiagohatta/opus-mt-de-en-finetuned-de-to-en-second
wmt16	wandemberg-eld/opus-mt-en-de-finetuned-en-to-de-model-2
# dataset: wmt17 --> 0 models
# dataset: wmt18 --> 0 models
# dataset: wmt19 --> 14 models
wmt19	facebook/wmt19-ru-en
wmt19	facebook/wmt19-en-de
wmt19	facebook/wmt19-de-en
wmt19	facebook/wmt19-en-ru
wmt19	allenai/wmt19-de-en-6-6-base
wmt19	stas/tiny-wmt19-en-ru
wmt19	stas/tiny-wmt19-en-de
wmt19	allenai/wmt19-de-en-6-6-big
wmt19	Tanhim/translation-En2De
wmt19	Sancha/t5-small-finetuned-fi-to-en
wmt19	pitehu/T5_NER_CONLL_LIST
wmt19	ingridnc/t5-small-finetuned-fi-to-en
wmt19	danielbispov/t5-small-finetuned-fi-to-en
wmt19	xiaj/test
# dataset: wmt20_mlqe_task1 --> 0 models
# dataset: wmt20_mlqe_task2 --> 0 models
# dataset: wmt20_mlqe_task3 --> 0 models
# dataset: wmt_t2t --> 0 models
# dataset: wnut_17 --> 10 models
wnut_17	sberbank-ai/bert-base-NER-reptile-5-datasets
wnut_17	AdapterHub/bert-base-uncased-pf-wnut_17
wnut_17	AdapterHub/roberta-base-pf-wnut_17
wnut_17	prashanth/new-indic-bert
wnut_17	prashanth/bert-base-multilingual-cased-ner
wnut_17	prashanth/bn-indic-bert-ner
wnut_17	prashanth/hi-bn-indic-bert-ner
wnut_17	prashanth/xlm-roberta-base-ner
wnut_17	prashanth/hi-indic-bert-ner
wnut_17	prashanth/hi-roberta
# dataset: wongnai_reviews --> 1 models
wongnai_reviews	poom-sci/WangchanBERTa-finetuned-sentiment
# dataset: woz_dialogue --> 0 models
# dataset: wrbsc --> 0 models
# dataset: x_stance --> 0 models
# dataset: xcopa --> 0 models
# dataset: xcsr --> 0 models
# dataset: xed_en_fi --> 0 models
# dataset: xglue --> 0 models
# dataset: xnli --> 16 models
xnli	BaptisteDoyen/camembert-base-xnli
xnli	Sahajtomar/German_Zeroshot
xnli	joeddav/xlm-roberta-large-xnli
xnli	vicgalle/xlm-roberta-large-xnli-anli
xnli	MoritzLaurer/mDeBERTa-v3-base-mnli-xnli
xnli	Recognai/bert-base-spanish-wwm-cased-xnli
xnli	NbAiLab/nb-bert-base-mnli
xnli	alan-turing-institute/mt5-large-finetuned-mnli-xtreme-xnli
xnli	Recognai/zeroshot_selectra_medium
xnli	hugorosen/flaubert_base_uncased-xnli-sts
xnli	mrm8488/electricidad-small-finetuned-xnli-es
xnli	Recognai/zeroshot_selectra_small
xnli	salesken/xlm-roberta-base-finetuned-mnli-cross-lingual-transfer
xnli	inokufu/flaubert-base-uncased-xnli-sts
xnli	inokufu/bertheo
xnli	KheireddineDaouadi/zero-shot-araelctra
# dataset: xor_tydi_qa --> 0 models
# dataset: xquad --> 11 models
xquad	salti/bert-base-multilingual-cased-finetuned-squad
xquad	nbroad/mt5-small-qgen
xquad	alon-albalak/xlm-roberta-large-xquad
xquad	alon-albalak/bert-base-multilingual-xquad
xquad	alon-albalak/xlm-roberta-base-xquad
xquad	obss/mt5-base-3task-highlight-combined3
xquad	obss/mt5-small-3task-prepend-tquad2
xquad	obss/mt5-base-3task-highlight-tquad2
xquad	obss/mt5-small-3task-both-tquad2
xquad	obss/mt5-small-3task-highlight-combined3
xquad	obss/mt5-small-3task-highlight-tquad2
# dataset: xquad_r --> 0 models
# dataset: xsum --> 37 models
xsum	sshleifer/distilbart-cnn-6-6
xsum	sshleifer/distilbart-cnn-12-6
xsum	sshleifer/distilbart-xsum-12-1
xsum	human-centered-summarization/financial-summarization-pegasus
xsum	sshleifer/distilbart-xsum-1-1
xsum	sshleifer/distilbart-xsum-12-6
xsum	sshleifer/distilbart-xsum-12-3
xsum	google/roberta2roberta_L-24_bbc
xsum	sshleifer/distilbart-cnn-12-3
xsum	deutsche-telekom/mt5-small-sum-de-en-v1
xsum	aseda/t5-small-finetuned-xsum
xsum	bhuvaneswari/t5-small-text_summarization
xsum	bochaowei/t5-small-finetuned-xsum-wei1
xsum	philschmid/tf-distilbart-cnn-12-6
xsum	pki/t5-small-finetuned_xsum
xsum	gniemiec/t5-small-finetuned-xsum
xsum	sshleifer/distilbart-xsum-6-6
xsum	bochaowei/t5-small-finetuned-xsum-wei0
xsum	T-Systems-onsite/mt5-small-sum-de-en-v2
xsum	lrakotoson/scitldr-catts-xsum-ao
xsum	CogComp/bart-faithful-summary-detector
xsum	RenZHU/t5-small-finetuned-xsum-original
xsum	Doogie/Waynehills_NLP_muti
xsum	sshleifer/distilbart-xsum-9-6
xsum	Doogie/Wayne_NLP_mT5
xsum	patrickvonplaten/roberta_shared_bbc_xsum
xsum	mrm8488/roberta-med-small_shared-finetuned-bbc_xsum-summarization
xsum	flax-community/t5-base-dutch-demo
xsum	Ayham/bert_gpt2_summarization_xsum
xsum	gniemiec/mt5-small-finetuned-xsum
xsum	andrejmiscic/simcls-scorer-xsum
xsum	furyhawk/t5-small-finetuned-xsum
xsum	bdwjaya/t5-small-finetuned-xsum
xsum	bochaowei/t5-small-finetuned-xsum-wei2
xsum	aozorahime/my-new-model
xsum	TheLongSentance/t5-small-finetuned-xsum
xsum	XSY/t5-small-finetuned-xsum
# dataset: xsum_factuality --> 0 models
# dataset: xtreme --> 25 models
xtreme	sachaarbonel/bert-italian-cased-finetuned-pos
xtreme	sagorsarker/mbert-bengali-ner
xtreme	bullmount/xlm-roberta-base-finetuned-panx-it
xtreme	neuropark/sahajBERT-NER
xtreme	mrm8488/bert-base-german-dbmdz-cased-finetuned-pawsx-de
xtreme	mrm8488/camembert-base-finetuned-pawsx-fr
xtreme	SaulLu/recreate-history
xtreme	mrm8488/RuPERTa-base-finetuned-pawsx-es
xtreme	mrm8488/electricidad-base-finetuned-pawsx-es
xtreme	victen/xlm-roberta-base-finetuned-panx-de
xtreme	robkayinto/xlm-roberta-base-finetuned-panx-de
xtreme	transformersbook/xlm-roberta-base-finetuned-panx-fr
xtreme	coldfir3/xlm-roberta-base-finetuned-panx-en
xtreme	hadxu/xlm-roberta-base-finetuned-panx-de
xtreme	hugsao123/xlm-roberta-base-finetuned-panx-de
xtreme	transformersbook/xlm-roberta-base-finetuned-panx-en
xtreme	transformersbook/xlm-roberta-base-finetuned-panx-it
xtreme	coldfir3/xlm-roberta-base-finetuned-panx-it
xtreme	MhF/xlm-roberta-base-finetuned-panx-de
xtreme	MhF/xlm-roberta-base-finetuned-panx-en
xtreme	MhF/xlm-roberta-base-finetuned-panx-fr
xtreme	MhF/xlm-roberta-base-finetuned-panx-it
xtreme	coldfir3/xlm-roberta-base-finetuned-panx-fr
xtreme	hugsao123/XLM-R-fine-tuned-for-ner
xtreme	transformersbook/xlm-roberta-base-finetuned-panx-de
# dataset: yahoo_answers_qa --> 0 models
# dataset: yahoo_answers_topics --> 1 models
yahoo_answers_topics	fabriceyhc/bert-base-uncased-yahoo_answers_topics
# dataset: yelp_polarity --> 6 models
yelp_polarity	felflare/bert-restore-punctuation
yelp_polarity	VictorSanh/roberta-base-finetuned-yelp-polarity
yelp_polarity	AdapterHub/bert-base-uncased-pf-yelp_polarity
yelp_polarity	st1992/bert-restore-punctuation
yelp_polarity	fabriceyhc/bert-base-uncased-yelp_polarity
yelp_polarity	AdapterHub/roberta-base-pf-yelp_polarity
# dataset: yelp_review_full --> 0 models
# dataset: yoruba_bbc_topics --> 0 models
# dataset: yoruba_gv_ner --> 0 models
# dataset: yoruba_text_c3 --> 0 models
# dataset: yoruba_wordsim353 --> 0 models
# dataset: youtube_caption_corrections --> 0 models
# dataset: zest --> 0 models
# dataset: 0n1xus/codexglue --> 0 models
# dataset: 0n1xus/pytorrent-standalone --> 0 models
# dataset: AConsApart/anime_subtitles_DialoGPT --> 0 models
# dataset: AHussain0418/day2_data --> 0 models
# dataset: AHussain0418/day4data --> 0 models
# dataset: AHussain0418/demo_data --> 0 models
# dataset: AI-Sweden/SuperLim --> 0 models
# dataset: AI-it/khs_service_test --> 0 models
# dataset: AI-it/korean-hate-speech --> 0 models
# dataset: ARKseal/YFCC14M_subset_webdataset --> 0 models
# dataset: ARTeLab/fanpage --> 0 models
# dataset: ARTeLab/ilpost --> 0 models
# dataset: ARTeLab/mlsum-it --> 0 models
# dataset: ASCCCCCCCC/amazon_zh --> 0 models
# dataset: Abdo1Kamr/Arabic_Hadith --> 0 models
# dataset: Abirate/code_net_dataset --> 0 models
# dataset: Abirate/code_net_dev_dataset --> 0 models
# dataset: Abirate/code_net_test_final_dataset --> 0 models
# dataset: Abirate/english_quotes --> 0 models
# dataset: Abirate/french_book_reviews --> 0 models
# dataset: AdWeeb/DravidianMT --> 0 models
# dataset: Adnan/Urdu_News_Headlines --> 0 models
# dataset: AhmadSawal/qa --> 0 models
# dataset: AhmedSSoliman/CoNaLa --> 0 models
# dataset: Aisha/BAAD16 --> 0 models
# dataset: Aisha/BAAD6 --> 0 models
# dataset: Akila/ForgottenRealmsWikiDataset --> 0 models
# dataset: Akshith/aa --> 0 models
# dataset: Akshith/g_rock --> 0 models
# dataset: Akshith/test --> 0 models
# dataset: Alegzandra/test --> 0 models
# dataset: AlekseyDorkin/extended_tweet_emojis --> 0 models
# dataset: AlekseyKorshuk/comedy-scripts --> 0 models
# dataset: AlekseyKorshuk/horror-scripts --> 0 models
# dataset: AlexMaclean/all-deletion-compressions --> 0 models
# dataset: AlexMaclean/wikipedia-deletion-compressions --> 0 models
# dataset: AlexZapolskii/zapolskii-amazon --> 0 models
# dataset: AlgoveraAI/CryptoPunks --> 0 models
# dataset: Aliseyfi/event_token_type --> 0 models
# dataset: Alvenir/nst-da-16khz --> 0 models
# dataset: AndrewMcDowell/de_corpora_parliament_processed --> 0 models
# dataset: Annabelleabbott/real-fake-news-workshop --> 0 models
# dataset: Annielytics/DoctorsNotes --> 0 models
# dataset: Anurag-Singh-creator/task --> 0 models
# dataset: Anurag-Singh-creator/tasks --> 0 models
# dataset: ApiInferenceTest/asr_dummy --> 0 models
# dataset: Arnold/hausa_common_voice --> 0 models
# dataset: AryanLala/autonlp-data-Scientific_Title_Generator --> 0 models
# dataset: Avishekavi/Avi --> 0 models
# dataset: Ayou/mobile_bert_datas --> 0 models
# dataset: BSC-TeMU/SQAC --> 0 models
# dataset: BSC-TeMU/ancora-ca-ner --> 0 models
# dataset: BSC-TeMU/sts-ca --> 0 models
# dataset: BSC-TeMU/tecla --> 0 models
# dataset: BSC-TeMU/viquiquad --> 0 models
# dataset: BSC-TeMU/xquad-ca --> 0 models
# dataset: Babelscape/rebel-dataset --> 0 models
# dataset: Babelscape/wikineural --> 0 models
# dataset: BatuhanYilmaz/github-issues --> 0 models
# dataset: Baybars/parla_text_corpus --> 0 models
# dataset: BeIR/beir-corpus --> 0 models
# dataset: BeIR/beir --> 0 models
# dataset: Binbin/my_dataset --> 0 models
# dataset: BlakesOrb6/Fred-Flintstone --> 0 models
# dataset: Bosio/pacman --> 0 models
# dataset: Bosio/pacman_descriptions --> 0 models
# dataset: BritishLibraryLabs/EThOS-PhD-metadata --> 0 models
# dataset: CAGER/rick --> 0 models
# dataset: CALM/arwiki --> 0 models
# dataset: CAiRE/ASCEND --> 0 models
# dataset: CShorten/KerasBERT --> 0 models
# dataset: CShorten/ZillowPrize --> 0 models
# dataset: ChadxxxxHall/Inter-vision --> 0 models
# dataset: Champion/vpc2020_clear_anon_speech --> 0 models
# dataset: Check/a_re_gi --> 0 models
# dataset: Check/region_1 --> 0 models
# dataset: Check/region_2 --> 0 models
# dataset: Check/region_3 --> 0 models
# dataset: Check/region_4 --> 0 models
# dataset: Check/region_5 --> 0 models
# dataset: Check/region_6 --> 0 models
# dataset: Check/region_7 --> 0 models
# dataset: Check/region_8 --> 0 models
# dataset: Check/region_9 --> 0 models
# dataset: Check/regions --> 0 models
# dataset: Check/vverify --> 0 models
# dataset: Cheranga/test --> 0 models
# dataset: ChristophSchuhmann/MS_COCO_2017_URL_TEXT --> 0 models
# dataset: Chun/dataset --> 0 models
# dataset: Chuu/Vhh --> 0 models
# dataset: CodedotAI/code-clippy-tfrecords --> 0 models
# dataset: CodedotAI/code_clippy --> 0 models
# dataset: Cropinky/flatearther --> 0 models
# dataset: Cropinky/rap_lyrics_english --> 0 models
# dataset: Cropinky/wow_fishing_bobber --> 0 models
# dataset: Cyberfish/pos_tagger --> 0 models
# dataset: Cyberfish/text_error_correction --> 0 models
# dataset: DDSC/angry-tweets --> 0 models
# dataset: DDSC/dkhate --> 0 models
# dataset: DDSC/europarl --> 0 models
# dataset: DDSC/lcc --> 0 models
# dataset: DDSC/partial-danish-gigaword-no-twitter --> 0 models
# dataset: DDSC/reddit-da --> 0 models
# dataset: DDSC/squad-da --> 0 models
# dataset: DDSC/twitter-sent --> 0 models
# dataset: DELith/github-issues --> 0 models
# dataset: DSCI511G1/COP26_Energy_Transition_Tweets --> 0 models
# dataset: DanL/scientific-challenges-and-directions-dataset --> 0 models
# dataset: Daniele/dante-corpus --> 0 models
# dataset: Darren/data --> 0 models
# dataset: Datatang/accented_english --> 0 models
# dataset: Datatang/accented_mandarin --> 0 models
# dataset: Datatang/chinese_dialect --> 0 models
# dataset: Datatang/mandarin_chinese --> 0 models
# dataset: Datatang/mixed_speech_chinese_english --> 0 models
# dataset: Datatang/multi_language --> 0 models
# dataset: Datatang/multi_language_conversation --> 0 models
# dataset: Davlan/conll2003_de_noMISC --> 0 models
# dataset: Davlan/conll2003_noMISC --> 0 models
# dataset: Davlan/masakhanerV1 --> 0 models
# dataset: DelgadoPanadero/Pokemon --> 0 models
# dataset: DeskDown/ALTDataset --> 0 models
# dataset: DeskDown/ALTDataset_en-to-fil-vi-id-ms-ja-khm --> 0 models
# dataset: DiFronzo/Human_Activity_Recognition --> 0 models
# dataset: Dmitriy612/1 --> 0 models
# dataset: DoctorSlimm/yipee --> 0 models
# dataset: Doohae/klue-mrc-bm25 --> 0 models
# dataset: Doohae/modern_music_re --> 0 models
# dataset: DoyyingFace/github-embeddings-doy --> 0 models
# dataset: DoyyingFace/github-issues-doy --> 0 models
# dataset: DrishtiSharma/_CV8_processed --> 0 models
# dataset: DrishtiSharma/as_opus100_processed --> 0 models
# dataset: DrishtiSharma/bg_opus100_processed --> 0 models
# dataset: DrishtiSharma/br_opus100_processed --> 0 models
# dataset: DrishtiSharma/hi_opus100_processed --> 0 models
# dataset: DrishtiSharma/kk_opus100_processed --> 0 models
# dataset: DrishtiSharma/mr_opus100_processed --> 0 models
# dataset: DrishtiSharma/or_opus100_processed --> 0 models
# dataset: DrishtiSharma/sl_opus100_processed --> 0 models
# dataset: DrishtiSharma/sr_opus100_processed --> 0 models
# dataset: Dumiiii/common-voice-romaniarss --> 0 models
# dataset: EMBO/biolang --> 0 models
# dataset: EMBO/sd-nlp --> 0 models
# dataset: ESZER/H --> 0 models
# dataset: Emanuel/UD_Portuguese-Bosque --> 0 models
# dataset: Emma121/testtest --> 0 models
# dataset: Emon/sobuj --> 0 models
# dataset: Enes3774/data --> 0 models
# dataset: Exr0n/wiki-entity-similarity --> 0 models
# dataset: Eymen3455/xsum_tr --> 0 models
# dataset: FIG-Loneliness/FIG-Loneliness --> 0 models
# dataset: FL33TW00D/test-dataset --> 0 models
# dataset: FRTNX/cosuju --> 0 models
# dataset: FRTNX/worldbank-projects --> 0 models
# dataset: Felix-ML/quoteli3 --> 0 models
# dataset: Fhrozen/JTubeSpeech --> 0 models
# dataset: Finnish-NLP/mc4_fi_cleaned --> 0 models
# dataset: Firoj/CrisisBench --> 0 models
# dataset: Francois/futures_es --> 0 models
# dataset: Fraser/mnist-text-default --> 0 models
# dataset: Fraser/mnist-text-no-spaces --> 0 models
# dataset: Fraser/mnist-text-small --> 0 models
# dataset: Fraser/news-category-dataset --> 0 models
# dataset: Fraser/program-synthesis --> 0 models
# dataset: Fraser/python-lines --> 0 models
# dataset: Fraser/python-state-changes --> 0 models
# dataset: Fraser/short-jokes --> 0 models
# dataset: Fraser/wiki_sentences --> 0 models
# dataset: GEM/ART --> 0 models
# dataset: GEM/BiSECT --> 0 models
# dataset: GEM/CrossWOZ --> 0 models
# dataset: GEM/OrangeSum --> 0 models
# dataset: GEM/RiSAWOZ --> 0 models
# dataset: GEM/RotoWire_English-German --> 0 models
# dataset: GEM/SIMPITIKI --> 0 models
# dataset: GEM/SciDuet --> 0 models
# dataset: GEM/Taskmaster --> 0 models
# dataset: GEM/cochrane-simplification --> 0 models
# dataset: GEM/common_gen --> 0 models
# dataset: GEM/conversational_weather --> 0 models
# dataset: GEM/cs_restaurants --> 0 models
# dataset: GEM/dart --> 0 models
# dataset: GEM/dstc10_track2_task2 --> 0 models
# dataset: GEM/e2e_nlg --> 0 models
# dataset: GEM/indonlg --> 0 models
# dataset: GEM/mlb_data_to_text --> 0 models
# dataset: GEM/mlsum --> 0 models
# dataset: GEM/opusparcus --> 0 models
# dataset: GEM/references --> 0 models
# dataset: GEM/schema_guided_dialog --> 0 models
# dataset: GEM/sportsett_basketball --> 0 models
# dataset: GEM/squad_v2 --> 0 models
# dataset: GEM/surface_realisation_st_2020 --> 0 models
# dataset: GEM/totto --> 0 models
# dataset: GEM/turku_hockey_data2text --> 0 models
# dataset: GEM/turku_paraphrase_corpus --> 0 models
# dataset: GEM/viggo --> 0 models
# dataset: GEM/web_nlg --> 0 models
# dataset: GEM/wiki_auto_asset_turk --> 0 models
# dataset: GEM/wiki_cat_sum --> 0 models
# dataset: GEM/wiki_lingua --> 0 models
# dataset: GEM/xlsum --> 0 models
# dataset: GEM/xsum --> 0 models
# dataset: GEM-submissions/submission-scores --> 0 models
# dataset: GV05/shlomit_speech --> 0 models
# dataset: Gabriel/quora_swe --> 0 models
# dataset: Gabriel/squad_v2_sv --> 0 models
# dataset: GalacticAI/Noirset --> 0 models
# dataset: Gauravadlakha1509/new_one --> 0 models
# dataset: GeoffVdr/cv8_trainval_processed --> 0 models
# dataset: GonzaloA/fake_news --> 0 models
# dataset: Graphcore/gqa-lxmert --> 0 models
# dataset: Graphcore/gqa --> 0 models
# dataset: Graphcore/vqa-lxmert --> 0 models
# dataset: Graphcore/vqa --> 0 models
# dataset: Graphcore/wikipedia-bert-128 --> 0 models
# dataset: Graphcore/wikipedia-bert-512 --> 0 models
# dataset: GroNLP/ik-nlp-22_pestyle --> 0 models
# dataset: GroNLP/ik-nlp-22_slp --> 0 models
# dataset: GroNLP/ik-nlp-22_transqe --> 0 models
# dataset: GroNLP/ik-nlp-22_winemag --> 0 models
# dataset: Gwangho/NCBI-Sars-Cov-2 --> 0 models
# dataset: HHousen/ParaSCI --> 0 models
# dataset: HHousen/msrp --> 0 models
# dataset: HHousen/quora --> 0 models
# dataset: Halilyesilceng/autonlp-data-nameEntityRecognition --> 0 models
# dataset: HarleyQ/WitcherDialogue --> 0 models
# dataset: HarrisDePerceptron/sv_corpora_parliament_processed --> 0 models
# dataset: HarrisDePerceptron/ur_corpora_pib --> 0 models
# dataset: Harveenchadha/bol-models --> 0 models
# dataset: HarveyBWest/mybot --> 0 models
# dataset: Hellisotherpeople/DebateSum --> 0 models
# dataset: Helsinki-NLP/tatoeba_mt --> 0 models
# dataset: HenryAI/KerasAPIReference.txt --> 0 models
# dataset: HenryAI/KerasBERTv1-Data --> 0 models
# dataset: HenryAI/KerasCodeExamples.txt --> 0 models
# dataset: HenryAI/KerasDeveloperGuides.txt --> 0 models
# dataset: Husain/intent-classification-en-fr --> 0 models
# dataset: IFSTalfredoswald/MBTI --> 0 models
# dataset: IGESML/pubmed_neg --> 0 models
# dataset: Iftoo95/Arabic_Sentiment_and_Topics --> 0 models
# dataset: IlyaGusev/gazeta --> 0 models
# dataset: IlyaGusev/headline_cause --> 0 models
# dataset: Intel/WEC-Eng --> 0 models
# dataset: Ishwar/Senti --> 0 models
# dataset: Iskaj/dutch_corpora_parliament_processed --> 0 models
# dataset: JIWON/nil_dataset --> 0 models
# dataset: JIsanan/war-ceb-wikipedia --> 0 models
# dataset: Jack0508/TED2020_kor --> 0 models
# dataset: Jack0508/TED2020_vi --> 0 models
# dataset: Jack0508/TED2020vi_kor --> 0 models
# dataset: Jack0508/demo --> 0 models
# dataset: Jack0508/eng_vi_demo --> 0 models
# dataset: Jack0508/test --> 0 models
# dataset: Jack0508/vi-ko-TED-txt --> 0 models
# dataset: Jean-Baptiste/wikiner_fr --> 0 models
# dataset: Jeska/autonlp-data-vaccinfaq --> 0 models
# dataset: Jeska/vaccinchat --> 0 models
# dataset: JesseParvess/book_snippets_asr --> 0 models
# dataset: Jikiwa/demo1 --> 0 models
# dataset: Jikiwa/demo2 --> 0 models
# dataset: Jikiwa/demo3 --> 0 models
# dataset: Jikiwa/demo4 --> 0 models
# dataset: Jikiwa/glue-mnli-train --> 0 models
# dataset: Jikiwa/push-to-hub --> 0 models
# dataset: Jikiwa/pushe-to-hub --> 0 models
# dataset: Jikiwa/pushed-to-hub --> 0 models
# dataset: Jikiwa/pushedd-to-hub --> 0 models
# dataset: Jikiwa/random_repo --> 0 models
# dataset: Jikiwa/stargazers --> 0 models
# dataset: Jikiwa/temp-repo-valid --> 0 models
# dataset: Jikiwa/test-16336477963335 --> 0 models
# dataset: Jikiwa/test-16336478042515 --> 0 models
# dataset: Jikiwa/test-16336479967338 --> 0 models
# dataset: Jikiwa/test-16336480189315 --> 0 models
# dataset: Jikiwa/test-16336486877862 --> 0 models
# dataset: Jikiwa/test-16340052901609 --> 0 models
# dataset: Jikiwa/test-16340052972855 --> 0 models
# dataset: Jikiwa/test-16344347220590 --> 0 models
# dataset: Jikiwa/test-16344347234752 --> 0 models
# dataset: Jikiwa/test-16344349332219 --> 0 models
# dataset: Jikiwa/test-16344349440339 --> 0 models
# dataset: Jikiwa/test-16344351925697 --> 0 models
# dataset: Jikiwa/test-16344360501144 --> 0 models
# dataset: Jikiwa/test-16344361893586 --> 0 models
# dataset: Jikiwa/test-16344362261113 --> 0 models
# dataset: Jikiwa/test-16344362895458 --> 0 models
# dataset: Jikiwa/test-16344364230608 --> 0 models
# dataset: Jikiwa/test-16344364547167 --> 0 models
# dataset: Jikiwa/test-16344367190179 --> 0 models
# dataset: Jikiwa/test-16344368182003 --> 0 models
# dataset: JonathanSum/github-issues --> 0 models
# dataset: JonathanSum/sv_corpora_parliament_processed --> 0 models
# dataset: JustinE/Test --> 0 models
# dataset: KBLab/overlim --> 0 models
# dataset: KBLab/sucx3_ner --> 0 models
# dataset: KETI-AIR/aihub --> 0 models
# dataset: KETI-AIR/klue --> 0 models
# dataset: KETI-AIR/kor_corpora --> 0 models
# dataset: KETI-AIR/korquad --> 0 models
# dataset: KETI-AIR/nikl --> 0 models
# dataset: KTH/martin --> 0 models
# dataset: KTH/nst --> 0 models
# dataset: KTH/speechdat --> 0 models
# dataset: KTH/waxholm --> 0 models
# dataset: Karavet/ARPA-Armenian-Paraphrase-Corpus --> 0 models
# dataset: Karavet/ILUR-news-text-classification-corpus --> 0 models
# dataset: Karavet/pioNER-Armenian-Named-Entity --> 0 models
# dataset: Khanoooo/autonlp-data-Corona --> 0 models
# dataset: Khondoker/SentNoB --> 0 models
# dataset: Kili/plastic_in_river --> 0 models
# dataset: Kira-Asimov/gender_clinical_trial --> 0 models
# dataset: LIAMF-USP/arc-retrieval-c4 --> 0 models
# dataset: Langame/waiting-messages --> 0 models
# dataset: Language/Fren --> 0 models
# dataset: Language/trans --> 0 models
# dataset: Lenn/github-issues --> 0 models
# dataset: LeoCordoba/CC-NEWS-ES-titles --> 0 models
# dataset: LeoCordoba/CC-NEWS-ES --> 0 models
# dataset: LeverageX/book-summarization --> 0 models
# dataset: LeverageX/klue-mrc --> 0 models
# dataset: LeverageX/klue-re --> 0 models
# dataset: Linda/test1111 --> 0 models
# dataset: Llamacha/Monolingual-cha --> 0 models
# dataset: Llamacha/monolingual-quechua-iic --> 0 models
# dataset: LoganKells/amazon_product_reviews_video_games --> 0 models
# dataset: Lucylulu/amazon --> 0 models
# dataset: Lucylulu/imdb --> 0 models
# dataset: LuisG07/es_corpora_parliament_processed --> 0 models
# dataset: Lumos/yahoo_hga --> 0 models
# dataset: MBAH/MOVIESON --> 0 models
# dataset: MKK/Dhivehi-English --> 0 models
# dataset: MLCommons/multilingual-spoken-words --> 0 models
# dataset: Mahalakshmi/ta_lm_processed --> 0 models
# dataset: Mansooreh/sharif-emotional-speech-dataset --> 0 models
# dataset: MarcBrun/squad-eu --> 0 models
# dataset: MarianaSahagun/test --> 0 models
# dataset: MarkusDressel/cord --> 0 models
# dataset: Marzipan/QA4PC --> 0 models
# dataset: Mateo/test_dataset --> 0 models
# dataset: Mateo/testdataset --> 0 models
# dataset: McGill-NLP/mlquestions --> 0 models
# dataset: Mcy/random_uselesstestsequence --> 0 models
# dataset: Melinoe/TheLabTexts --> 0 models
# dataset: MickyMike/large_c_corpus --> 0 models
# dataset: Motahar/github-issues --> 0 models
# dataset: Mrleo1nid/Test_ru_dataset --> 0 models
# dataset: Mulin/my_second_dataset --> 0 models
# dataset: Mulin/my_third_dataset --> 0 models
# dataset: NLPC-UOM/English-Tamil-Parallel-Corpus --> 0 models
# dataset: NLPC-UOM/Sinhala-POS-Data --> 0 models
# dataset: NTUYG/RAGTest --> 0 models
# dataset: NYTK/HuCOLA --> 0 models
# dataset: NYTK/HuCoPA --> 0 models
# dataset: NYTK/HuRC --> 0 models
# dataset: NYTK/HuSST --> 0 models
# dataset: NYTK/HuWSC --> 0 models
# dataset: NahedAbdelgaber/evaluating-student-writing --> 0 models
# dataset: Narsil/asr_dummy --> 0 models
# dataset: Narsil/conversational_dummy --> 0 models
# dataset: Narsil/image_dummy --> 0 models
# dataset: Narsil/test_data --> 0 models
# dataset: Nathanael/NPS --> 0 models
# dataset: Navigator/dodydard-marty --> 0 models
# dataset: NbAiLab/NCC --> 0 models
# dataset: NbAiLab/NCC_small_100 --> 0 models
# dataset: NbAiLab/NCC_small_divided --> 0 models
# dataset: NbAiLab/NPSC --> 0 models
# dataset: NbAiLab/NPSC_test --> 0 models
# dataset: NbAiLab/NPSC_test2 --> 0 models
# dataset: NbAiLab/bokmaal_admin --> 0 models
# dataset: NbAiLab/norec_agg --> 0 models
# dataset: NbAiLab/norne --> 0 models
# dataset: NbAiLab/norwegian_parliament --> 0 models
# dataset: NikolajW/NPS_nonNormalized-Cased --> 0 models
# dataset: NishinoTSK/leishmaniaV2 --> 0 models
# dataset: NishinoTSK/leishmaniav1 --> 0 models
# dataset: Ofrit/tmp --> 0 models
# dataset: Omar2027/caner_replicate --> 0 models
# dataset: OmarN121/train --> 0 models
# dataset: PDJ107/riot-data --> 0 models
# dataset: Paul/hatecheck --> 0 models
# dataset: PaulLerner/viquae_dataset --> 0 models
# dataset: PaulLerner/viquae_images --> 0 models
# dataset: PaulLerner/viquae_wikipedia --> 0 models
# dataset: Pengfei/asfwe --> 0 models
# dataset: Pengfei/test --> 0 models
# dataset: Pengfei/test1 --> 0 models
# dataset: PereLluis13/parla_text_corpus --> 0 models
# dataset: PereLluis13/spanish_speech_text --> 0 models
# dataset: Perkhad/corejur --> 0 models
# dataset: PlanTL-GOB-ES/SQAC --> 0 models
# dataset: Plim/common_voice_7_0_fr_processed --> 0 models
# dataset: Plim/fr_corpora_parliament_processed --> 0 models
# dataset: Plim/fr_wikipedia_processed --> 0 models
# dataset: Plim/language_model_fr --> 0 models
# dataset: Pongsaky/Wiki_SCG --> 0 models
# dataset: Pratik/Gujarati_OpenSLR --> 0 models
# dataset: Pyjay/emotion_nl --> 0 models
# dataset: Pyke/patent_abstract --> 0 models
# dataset: QA/abk-eng --> 0 models
# dataset: R0bk/XFUN --> 0 models
# dataset: RBG-AI/CoRePooL --> 0 models
# dataset: Recognai/ag_news_corrected_labels --> 0 models
# dataset: Recognai/corrected_labels_ag_news --> 0 models
# dataset: Recognai/gutenberg_spacy-ner --> 0 models
# dataset: Recognai/imdb_spacy-ner --> 0 models
# dataset: Recognai/news --> 0 models
# dataset: Recognai/sentiment-banking --> 0 models
# dataset: Recognai/veganuary --> 0 models
# dataset: Remesita/tagged_reviews --> 0 models
# dataset: Renukswamy/Patent_sentiment_analysis --> 0 models
# dataset: RohanAiLab/persian_blog --> 0 models
# dataset: RohanAiLab/persian_daily_news --> 0 models
# dataset: RohanAiLab/persian_news_dataset --> 0 models
# dataset: RollingMuffin/test_scripts --> 0 models
# dataset: Romrawin/mn-sim --> 0 models
# dataset: RuudVelo/commonvoice_mt_8_processed --> 0 models
# dataset: RuudVelo/commonvoice_nl_8_processed --> 0 models
# dataset: RuudVelo/nl_corpora_parliament_processed --> 0 models
# dataset: SCourthial/test --> 0 models
# dataset: Sabokou/qg_squad_modified --> 0 models
# dataset: Sabokou/qg_squad_modified_dev --> 0 models
# dataset: SajjadAyoubi/persian_qa --> 0 models
# dataset: Sam2021/Arguement_Mining_CL2017 --> 0 models
# dataset: Samip/func --> 0 models
# dataset: SaulLu/Natural_Questions_HTML --> 0 models
# dataset: SaulLu/Natural_Questions_HTML_Toy --> 0 models
# dataset: SaulLu/Natural_Questions_HTML_reduced_all --> 0 models
# dataset: SaulLu/test --> 0 models
# dataset: SaulLu/toy_struc_dataset --> 0 models
# dataset: SebastianS/github-issues --> 0 models
# dataset: SergeiGKS/wikiner_fr_job --> 0 models
# dataset: Serhii/Custom_SQuAD --> 0 models
# dataset: SetFit/20_newsgroups --> 0 models
# dataset: SetFit/TREC-QC --> 0 models
# dataset: SetFit/ag_news --> 0 models
# dataset: SetFit/amazon_counterfactual --> 0 models
# dataset: SetFit/amazon_counterfactual_en --> 0 models
# dataset: SetFit/amazon_polarity --> 0 models
# dataset: SetFit/bbc-news --> 0 models
# dataset: SetFit/emotion --> 0 models
# dataset: SetFit/enron_spam --> 0 models
# dataset: SetFit/ethos --> 0 models
# dataset: SetFit/ethos_binary --> 0 models
# dataset: SetFit/go_emotions --> 0 models
# dataset: SetFit/hate_speech18 --> 0 models
# dataset: SetFit/hate_speech_offensive --> 0 models
# dataset: SetFit/imdb --> 0 models
# dataset: SetFit/insincere-questions --> 0 models
# dataset: SetFit/sst2 --> 0 models
# dataset: SetFit/sst5 --> 0 models
# dataset: SetFit/student-question-categories --> 0 models
# dataset: SetFit/subj --> 0 models
# dataset: SetFit/toxic_conversations --> 0 models
# dataset: SetFit/tweet_eval_stance --> 0 models
# dataset: SetFit/tweet_sentiment_extraction --> 0 models
# dataset: SetFit/yelp_review_full --> 0 models
# dataset: Shanna/Jamaica --> 0 models
# dataset: ShinyQ/PPKM_Pemerintah --> 0 models
# dataset: Shushant/ContaminationQA --> 0 models
# dataset: Shushant/NepaliSentiment --> 0 models
# dataset: Shushant/nepali --> 0 models
# dataset: SkelterLabsInc/JaQuAD --> 0 models
# dataset: Smiling/webnovels-en --> 0 models
# dataset: SoLID/shellcode_i_a32 --> 0 models
# dataset: SocialGrep/one-million-reddit-confessions --> 0 models
# dataset: SocialGrep/one-million-reddit-jokes --> 0 models
# dataset: SocialGrep/one-million-reddit-questions --> 0 models
# dataset: SocialGrep/one-year-of-r-india --> 0 models
# dataset: SocialGrep/reddit-crypto-aug-2021 --> 0 models
# dataset: SocialGrep/reddit-nonewnormal-complete --> 0 models
# dataset: SocialGrep/reddit-wallstreetbets-aug-2021 --> 0 models
# dataset: SocialGrep/ten-million-reddit-answers --> 0 models
# dataset: SocialGrep/the-2022-trucker-strike-on-reddit --> 0 models
# dataset: SocialGrep/the-reddit-covid-dataset --> 0 models
# dataset: SophieTr/reddit_clean --> 0 models
# dataset: TRoboto/masc --> 0 models
# dataset: TRoboto/names --> 0 models
# dataset: TaahaKazi/FCE --> 0 models
# dataset: Taekyoon/test_none_state --> 0 models
# dataset: Tahsin-Mayeesha/Bengali-SQuAD --> 0 models
# dataset: Tatyana/ru_sentiment_dataset --> 0 models
# dataset: Terry0107/RiSAWOZ --> 0 models
# dataset: TestCher/Testi --> 0 models
# dataset: Tevatron/msmarco-passage-corpus --> 0 models
# dataset: Tevatron/msmarco-passage --> 0 models
# dataset: Tevatron/scifact-corpus --> 0 models
# dataset: Tevatron/scifact --> 0 models
# dataset: Tevatron/wikipedia-curated-corpus --> 0 models
# dataset: Tevatron/wikipedia-curated --> 0 models
# dataset: Tevatron/wikipedia-nq-corpus --> 0 models
# dataset: Tevatron/wikipedia-nq --> 0 models
# dataset: Tevatron/wikipedia-squad-corpus --> 0 models
# dataset: Tevatron/wikipedia-squad --> 0 models
# dataset: Tevatron/wikipedia-trivia-corpus --> 0 models
# dataset: Tevatron/wikipedia-trivia --> 0 models
# dataset: Tevatron/wikipedia-wq-corpus --> 0 models
# dataset: Tevatron/wikipedia-wq --> 0 models
# dataset: TheBlindBandit/SpongeNot --> 0 models
# dataset: TimTreasure4/Test --> 0 models
# dataset: Trainmaster9977/957 --> 0 models
# dataset: Trainmaster9977/zbakuman --> 0 models
# dataset: TristanBehrens/js-fakes-4bars --> 0 models
# dataset: TurkuNLP/register_mc4 --> 0 models
# dataset: TurkuNLP/register_oscar --> 0 models
# dataset: TurkuNLP/turku_hockey_data2text --> 0 models
# dataset: TurkuNLP/turku_paraphrase_corpus --> 0 models
# dataset: Tyler/wikimatrix_collapsed --> 0 models
# dataset: UMU/spanish-saticorpus-2021 --> 0 models
# dataset: Usin2705/test --> 0 models
# dataset: VJGamer/test --> 0 models
# dataset: VadorMazer/skyrimdialogstest --> 0 models
# dataset: Valahaar/wsdmt --> 0 models
# dataset: Vishnu393831/VICTORY_dataset --> 0 models
# dataset: Vishva/UniFAQ_DataSET --> 0 models
# dataset: Voxcroft/alffa_amharic --> 0 models
# dataset: Voxcroft/alffa_wolof --> 0 models
# dataset: Wiedy/be --> 0 models
# dataset: Wiedy/wav2vec2-large-xls-r-300m-tr-colab --> 0 models
# dataset: Wikidepia/IndoParaCrawl --> 0 models
# dataset: Wikidepia/IndoSQuAD --> 0 models
# dataset: Wikidepia/mc4-filter --> 0 models
# dataset: WillFerreiraSantos/halos --> 0 models
# dataset: Wuhu0/output --> 0 models
# dataset: WyrdCurt/AO4W --> 0 models
# dataset: Xenova/sponsorblock-768 --> 0 models
# dataset: Xenova/sponsorblock --> 0 models
# dataset: XiangPan/iflytek --> 0 models
# dataset: XiangPan/snli_break --> 0 models
# dataset: XiangXiang/clt --> 0 models
# dataset: Xinghua/test --> 0 models
# dataset: Yatoro/github-issues --> 0 models
# dataset: Yatoro/github_issues --> 0 models
# dataset: Yeva/arm-summary --> 0 models
# dataset: YuAnthony/tnews --> 0 models
# dataset: Yves/fhnw_swiss_parliament --> 0 models
# dataset: Zaid/coqa_expanded --> 0 models
# dataset: Zaid/quac_expanded --> 0 models
# dataset: Zoe10/ner_dataset --> 0 models
# dataset: abhishek/autonlp-data-imdb_eval --> 0 models
# dataset: abhishek/autonlp-data-prodigy-10 --> 0 models
# dataset: abidlabs/crowdsourced-notes --> 0 models
# dataset: abidlabs/crowdsourced-speech-demo --> 0 models
# dataset: abidlabs/crowdsourced-speech --> 0 models
# dataset: abidlabs/crowdsourced-speech2 --> 0 models
# dataset: abidlabs/crowdsourced-speech3 --> 0 models
# dataset: abidlabs/crowdsourced-speech4 --> 0 models
# dataset: abidlabs/crowdsourced-speech5 --> 0 models
# dataset: abidlabs/crowdsourced-speech6 --> 0 models
# dataset: abidlabs/crowdsourced-speech7 --> 0 models
# dataset: abidlabs/test-audio-1 --> 0 models
# dataset: abidlabs/test-audio-13 --> 0 models
# dataset: abidlabs/test-image-13 --> 0 models
# dataset: abidlabs/test-image-classifier-dataset --> 0 models
# dataset: abidlabs/test-translation-dataset --> 0 models
# dataset: abidlabs/voice-verification-adversarial-dataset --> 0 models
# dataset: abwicke/C-B-R --> 0 models
# dataset: abwicke/koplo --> 0 models
# dataset: adalbertojunior/MININER --> 0 models
# dataset: adalbertojunior/punctuation-ptbr-light --> 0 models
# dataset: adalbertojunior/punctuation-ptbr --> 0 models
# dataset: adamlin/FewShotWoz --> 0 models
# dataset: adamlin/companion --> 0 models
# dataset: adamlin/coqa_squad --> 0 models
# dataset: adamlin/daily_dialog --> 0 models
# dataset: adamlin/domain_classification --> 0 models
# dataset: adamlin/mail-classification --> 0 models
# dataset: adamlin/multiwoz_dst --> 0 models
# dataset: adamlin/qa_verification --> 0 models
# dataset: adamlin/roc_story --> 0 models
# dataset: adamlin/rs --> 0 models
# dataset: adamlin/weibo_ner --> 0 models
# dataset: addy88/nq-question-answeronly --> 0 models
# dataset: addy88/sanskrit-asr-84-eval --> 0 models
# dataset: addy88/sanskrit-asr-84 --> 0 models
# dataset: afasafen/mydataset --> 0 models
# dataset: afasafen/newDataSet --> 0 models
# dataset: ai4bharat/samanantar --> 0 models
# dataset: aidystark/Yt --> 0 models
# dataset: ajmbell/test-dataset --> 0 models
# dataset: akhaliq/test --> 0 models
# dataset: akumar33/manufacturing --> 0 models
# dataset: albertvillanova/carbon_24 --> 0 models
# dataset: albertvillanova/datasets-tests-compression --> 0 models
# dataset: albertvillanova/dummy_libri2mix --> 0 models
# dataset: albertvillanova/legal_contracts --> 0 models
# dataset: albertvillanova/lm_en_dummy0 --> 0 models
# dataset: albertvillanova/lm_en_dummy1 --> 0 models
# dataset: albertvillanova/lm_en_dummy2 --> 0 models
# dataset: albertvillanova/lm_en_dummy3 --> 0 models
# dataset: albertvillanova/lm_en_dummy4 --> 0 models
# dataset: albertvillanova/multilingual_spoken_words --> 0 models
# dataset: albertvillanova/pmc_open_access --> 0 models
# dataset: albertvillanova/sat --> 0 models
# dataset: albertvillanova/tests-public-raw-jsonl --> 0 models
# dataset: albertvillanova/tests-raw-jsonl --> 0 models
# dataset: albertvillanova/tmp-tests-zip --> 0 models
# dataset: albertvillanova/tmp-tests --> 0 models
# dataset: alexantonov/chuvash_parallel --> 0 models
# dataset: aliabd/crowdsourced-calculator-demo --> 0 models
# dataset: aliabd/crowdsourced-speech4 --> 0 models
# dataset: aliabd/hello-world --> 0 models
# dataset: alireza655/alireza655 --> 0 models
# dataset: alistvt/coqa-flat --> 0 models
# dataset: alistvt/coqa-stories --> 0 models
# dataset: alistvt/coqa --> 0 models
# dataset: alittleie/mis_238 --> 0 models
# dataset: allegro/klej-allegro-reviews --> 0 models
# dataset: allegro/klej-cbd --> 0 models
# dataset: allegro/klej-cdsc-e --> 0 models
# dataset: allegro/klej-cdsc-r --> 0 models
# dataset: allegro/klej-dyk --> 0 models
# dataset: allegro/klej-nkjp-ner --> 0 models
# dataset: allegro/klej-polemo2-in --> 0 models
# dataset: allegro/klej-polemo2-out --> 0 models
# dataset: allegro/klej-psc --> 0 models
# dataset: allegro/polish-question-passage-pairs --> 0 models
# dataset: allegro/summarization-allegro-articles --> 0 models
# dataset: allegro/summarization-polish-summaries-corpus --> 0 models
# dataset: allenai/c4 --> 0 models
# dataset: allenai/scico --> 0 models
# dataset: alperbayram/TwitterDuygu --> 0 models
# dataset: alperiox/autonlp-data-user-review-classification --> 0 models
# dataset: alvp/autonlp-data-alberti-stanza-names --> 0 models
# dataset: alvp/autonlp-data-alberti-stanzas-finetuning --> 0 models
# dataset: ami-wav2vec2/ami_multi_headset_segmented_and_chunked --> 0 models
# dataset: ami-wav2vec2/ami_multi_headset_segmented_and_chunked_and_concatenated --> 0 models
# dataset: ami-wav2vec2/ami_multi_headset_segmented_and_chunked_dummy --> 0 models
# dataset: ami-wav2vec2/ami_single_headset_segmented --> 0 models
# dataset: ami-wav2vec2/ami_single_headset_segmented_and_chunked --> 0 models
# dataset: ami-wav2vec2/ami_single_headset_segmented_and_chunked_and_concatenated --> 0 models
# dataset: ami-wav2vec2/ami_single_headset_segmented_and_chunked_dummy --> 0 models
# dataset: ami-wav2vec2/ami_single_headset_segmented_dummy --> 0 models
# dataset: aminedjebbie/Multi-Arabic-dialects --> 0 models
# dataset: andrepreira/outros2021 --> 0 models
# dataset: anechaev/med_history --> 0 models
# dataset: anechaev/ru_med_history --> 0 models
# dataset: animesh/autonlp-data-peptides --> 0 models
# dataset: antoinegk/HealthChallenge_dataset --> 0 models
# dataset: anton-l/common_language --> 0 models
# dataset: anton-l/common_voice_7_0_test --> 0 models
# dataset: anton-l/superb --> 0 models
# dataset: anton-l/superb_demo --> 0 models
# dataset: anton-l/superb_dummy --> 0 models
# dataset: anukaver/EstQA --> 0 models
# dataset: anuragshas/bg_opus100_processed --> 0 models
# dataset: anuragshas/ha_cc100_processed --> 0 models
# dataset: anuragshas/ha_opus100_processed --> 0 models
# dataset: anuragshas/hi_opus100_processed --> 0 models
# dataset: anuragshas/lv_opus100_processed --> 0 models
# dataset: anuragshas/mr_cc100_processed --> 0 models
# dataset: anuragshas/mt_opus100_processed --> 0 models
# dataset: anuragshas/pa_cc100_processed --> 0 models
# dataset: anuragshas/sk_opus100_processed --> 0 models
# dataset: anuragshas/sl_opus100_processed --> 0 models
# dataset: anuragshas/ur_opus100_processed --> 0 models
# dataset: anushakamath/sv_corpora_parliament_processed_v0 --> 0 models
# dataset: anzorq/kbd-ru-1.67M-temp --> 0 models
# dataset: anzorq/kbd-ru-jsonl-tmp --> 0 models
# dataset: anzorq/kbd-ru-temp --> 0 models
# dataset: arch-raven/MAMI --> 0 models
# dataset: arjunth2001/online_privacy_qna --> 0 models
# dataset: artemis13fowl/github-issues --> 0 models
# dataset: artyeth/Dorian --> 0 models
# dataset: aryanpatke/github-issues --> 0 models
# dataset: asahi417/qg_jaquad --> 0 models
# dataset: asahi417/qg_squad --> 0 models
# dataset: aseifert/merlin --> 0 models
# dataset: aseifert/pie-synthetic --> 0 models
# dataset: ashish-shrivastava/dont-know-dataset --> 0 models
# dataset: ashraq/dhivehi-corpus --> 0 models
# dataset: asi/wikitext_fr --> 0 models
# dataset: asoroa/bsbasque --> 0 models
# dataset: astarostap/antisemitic-tweets --> 0 models
# dataset: astarostap/antisemitic_tweets --> 0 models
# dataset: astarostap/autonlp-data-antisemitism-2 --> 0 models
# dataset: astremo/friendly_JA_corpus --> 0 models
# dataset: astrideducation/cefr-combined-no-cefr-test --> 0 models
# dataset: atelders/politweets --> 0 models
# dataset: athar/QA --> 0 models
# dataset: athivvat/thai-rap-lyrics --> 0 models
# dataset: ausgequetschtem/jtrddfhfgh --> 0 models
# dataset: austin/rheum_abstracts --> 0 models
# dataset: avadesian/dddd --> 0 models
# dataset: avanishcobaltest/datasetavanish --> 0 models
# dataset: averyanalex/panorama --> 0 models
# dataset: azuur/es_corpora_parliament_processed --> 0 models
# dataset: azuur/gn_wiki_cleaned --> 0 models
# dataset: badranx/opus_raw --> 0 models
# dataset: batelicm/feedback-prize-2021-qa-concluding-statement --> 0 models
# dataset: batelicm/feedback-prize-2021-qa-lead --> 0 models
# dataset: batelicm/feedback-prize-2021-qa-ner --> 0 models
# dataset: batelicm/feedback-prize-2021-qa-position --> 0 models
# dataset: batelicm/feedback-prize-2021-qa --> 0 models
# dataset: bavard/personachat_truecased --> 0 models
# dataset: beacon/test --> 0 models
# dataset: bemanningssitua/dplremjfjfj --> 0 models
# dataset: benjaminbeilharz/better_daily_dialog --> 0 models
# dataset: benjaminbeilharz/librivoxdeen --> 0 models
# dataset: bergoliveira/pl_corpus_teste --> 0 models
# dataset: berkergurcay/2020-10K-Reports --> 0 models
# dataset: bertin-project/mc4-es-sampled --> 0 models
# dataset: bertin-project/mc4-sampling --> 0 models
# dataset: bhadresh-savani/web_split --> 0 models
# dataset: bhavnicksm/sentihood --> 0 models
# dataset: bhigy/buckeye_asr --> 0 models
# dataset: bigscience/LanguageResourceCatalogue --> 0 models
# dataset: bigscience/P3 --> 13 models
bigscience/P3	bigscience/T0_3B
bigscience/P3	bigscience/T0pp
bigscience/P3	bigscience/T0
bigscience/P3	yuchenlin/BART0
bigscience/P3	yuchenlin/BART0pp
bigscience/P3	yuchenlin/BART0pp-base
bigscience/P3	bigscience/T0p
bigscience/P3	yuchenlin/BART0_CSR
bigscience/P3	gustavecortal/T0_3B-8bit
bigscience/P3	yuchenlin/BART0-base
bigscience/P3	bigscience/T0_original_task_only
bigscience/P3	saurkulsh/T0pp
bigscience/P3	bigscience/T0_single_prompt
# dataset: bigscience/mc4-sampled --> 0 models
# dataset: bigscience/open_subtitles_monolingual --> 0 models
# dataset: bigscience-catalogue-data-dev/lm_code_github-eval_subset --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ar_wikibooks --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ar_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ar_wikinews_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ar_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ar_wikisource --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ar_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ar_wikiversity_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ar_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ca_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ca_wikimedia_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ca_wikinews_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ca_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ca_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_ca_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_code_stackexchange --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_en_no_code_stackexchange --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_en_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_en_wikinews_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_en_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_en_wikiversity_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_en_wikivoyage_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_en_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_es_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_es_wikinews_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_es_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_es_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_es_wikiversity_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_es_wikivoyage_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_es_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_eu_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_eu_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_eu_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_eu_wiktionary --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_eu_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_fr_wikibooks --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_fr_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_fr_wikinews --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_fr_wikinews_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_fr_wikiquote --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_fr_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_fr_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_fr_wikiversity_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_fr_wikivoyage --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_fr_wikivoyage_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_fr_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_id_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_id_wikimedia_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_id_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_id_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_id_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-as_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-as_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-bn_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-bn_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-bn_wikivoyage_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-bn_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-gu_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-gu_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-gu_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-hi_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-hi_wikimedia_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-hi_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-hi_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-hi_wikiversity_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-hi_wikivoyage_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-hi_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-kn_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-kn_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-kn_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ml_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ml_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ml_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ml_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-mr_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-mr_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-mr_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-mr_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-or_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-or_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-pa_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-pa_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-pa_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ta_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ta_wikinews_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ta_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ta_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ta_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-te_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-te_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-te_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-te_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ur_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ur_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_indic-ur_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_nigercongo-bm_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_nigercongo-ln_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_nigercongo-rw_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_nigercongo-st_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_nigercongo-sw_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_nigercongo-sw_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_nigercongo-tn_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_nigercongo-ts_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_nigercongo-wo_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_nigercongo-wo_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_nigercongo-zu_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_pt_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_pt_wikimedia_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_pt_wikinews_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_pt_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_pt_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_pt_wikiversity_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_pt_wikivoyage_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_pt_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_vi_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_vi_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_vi_wikisource_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_vi_wikivoyage_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_vi_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_zh_wikibooks_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_zh_wikinews_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_zh_wikiquote_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_zh_wikiversity_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_zh_wikivoyage_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_zh_wiktionary_filtered --> 0 models
# dataset: bigscience-catalogue-lm-data/lm_zu_wiktionary --> 0 models
# dataset: bigscience-historical-texts/hipe2020 --> 0 models
# dataset: bingzhen/test2 --> 0 models
# dataset: birgermoell/sv_corpora_parliament_processed --> 0 models
# dataset: bitmorse/kickstarter_2022-2021 --> 0 models
# dataset: biu-nlp/qa_align --> 0 models
# dataset: biu-nlp/qa_discourse --> 0 models
# dataset: biu-nlp/qa_srl2018 --> 0 models
# dataset: biu-nlp/qa_srl2020 --> 0 models
# dataset: biu-nlp/qamr --> 0 models
# dataset: biu-nlp/qanom --> 0 models
# dataset: blinoff/medical_qa_ru_data --> 0 models
# dataset: bobbydylan/top2k --> 0 models
# dataset: bondarchukb/autonlp-data-iab_classification --> 0 models
# dataset: braincode/braincode --> 0 models
# dataset: brunodorneles/ner --> 0 models
# dataset: bryantpwhite/Medieval_Sermons_in_French --> 0 models
# dataset: bryantpwhite/Medieval_Texts_in_French --> 0 models
# dataset: bs-modeling-metadata/OSCAR_Entity_13_000 --> 0 models
# dataset: bs-modeling-metadata/c4_newslike_url_only --> 0 models
# dataset: bs-modeling-metadata/website_metadata_c4 --> 0 models
# dataset: bs-modeling-metadata/wiki_dump --> 0 models
# dataset: bsc/ancora-ca-ner --> 0 models
# dataset: bsc/sts-ca --> 0 models
# dataset: bsc/tecla --> 0 models
# dataset: bsc/viquiquad --> 0 models
# dataset: bsc/xquad-ca --> 0 models
# dataset: bstad/github-issues --> 0 models
# dataset: bwu2018/anime-tagging-dataset --> 0 models
# dataset: caca/zscczs --> 0 models
# dataset: cakiki/args_me --> 0 models
# dataset: cakiki/arxiv-metadata --> 0 models
# dataset: cakiki/en_wiki_quote --> 0 models
# dataset: cakiki/paperswithcode --> 0 models
# dataset: caltonji/harrypotter_squad_v2 --> 0 models
# dataset: caltonji/harrypotter_squad_v2_2 --> 0 models
# dataset: calvpang/github-issues --> 0 models
# dataset: cameronbc/synthtiger --> 0 models
# dataset: cankeles/eval-senh --> 0 models
# dataset: canwenxu/dogwhistle --> 0 models
# dataset: cassandra-themis/QR-AN --> 0 models
# dataset: castorini/afriberta-corpus --> 0 models
# dataset: castorini/mr-tydi-corpus --> 0 models
# dataset: castorini/mr-tydi --> 0 models
# dataset: castorini/msmarco_v1_doc_doc2query-t5_expansions --> 0 models
# dataset: castorini/msmarco_v1_doc_segmented_doc2query-t5_expansions --> 0 models
# dataset: castorini/msmarco_v1_passage_doc2query-t5_expansions --> 0 models
# dataset: castorini/msmarco_v2_doc_doc2query-t5_expansions --> 0 models
# dataset: castorini/msmarco_v2_doc_segmented_doc2query-t5_expansions --> 0 models
# dataset: castorini/msmarco_v2_passage_doc2query-t5_expansions --> 0 models
# dataset: castorini/nq_gar-t5_expansions --> 0 models
# dataset: castorini/triviaqa_gar_t5_expansions --> 0 models
# dataset: caythuoc/caoduoclieu --> 0 models
# dataset: cbrew475/hwu66 --> 0 models
# dataset: ccccccc/hdjw_94ejrjr --> 0 models
# dataset: ccdv/arxiv-classification --> 0 models
# dataset: ccdv/arxiv-summarization --> 0 models
# dataset: ccdv/cnn_dailymail --> 0 models
# dataset: ccdv/govreport-summarization --> 0 models
# dataset: ccdv/patent-classification --> 0 models
# dataset: ccdv/pubmed-summarization --> 0 models
# dataset: cdleong/piglatin-mt --> 0 models
# dataset: cdleong/temp_africaNLP_keyword_spotting_for_african_languages --> 0 models
# dataset: cdminix/iwslt2011 --> 0 models
# dataset: cdminix/mgb1 --> 0 models
# dataset: cem/dnm --> 0 models
# dataset: cem/film --> 0 models
# dataset: cemigo/taylor_vs_shakes --> 0 models
# dataset: cemigo/test-data --> 0 models
# dataset: cestwc/adapted-msrcomp --> 0 models
# dataset: cestwc/adapted-paranmt5m --> 0 models
# dataset: cestwc/adapted-sentcomp --> 0 models
# dataset: cestwc/adapted-synonym --> 0 models
# dataset: cestwc/adapted-wikismall --> 0 models
# dataset: cestwc/adapted-wordnet --> 0 models
# dataset: cestwc/asrc --> 0 models
# dataset: cestwc/cnn_dailymail-metaeval100 --> 0 models
# dataset: cestwc/cnn_dailymail-snippets --> 0 models
# dataset: cestwc/cnn_dailymail-test50 --> 0 models
# dataset: cestwc/conjnli --> 0 models
# dataset: cestwc/sac-approx-1 --> 0 models
# dataset: cestwc/sac-na --> 0 models
# dataset: cestwc/sac --> 0 models
# dataset: cfilt/iitb-english-hindi --> 0 models
# dataset: cgarciae/point-cloud-mnist --> 0 models
# dataset: cgarciae/point_cloud_mnist --> 0 models
# dataset: chau/ink_test01 --> 0 models
# dataset: chenghao/mc4_eu_dedup --> 0 models
# dataset: chenghao/mc4_sw_dedup --> 0 models
# dataset: chenghao/scielo_books --> 0 models
# dataset: chenyuxuan/wikigold --> 0 models
# dataset: cheulyop/dementiabank --> 0 models
# dataset: cheulyop/ksponspeech --> 0 models
# dataset: chitra/contradiction --> 0 models
# dataset: chitra/contradictionNLI --> 0 models
# dataset: chmanoj/ai4bharat__samanantar_processed_te --> 0 models
# dataset: chopey/dhivehi --> 0 models
# dataset: clarin-pl/aspectemo --> 0 models
# dataset: clarin-pl/cst-wikinews --> 0 models
# dataset: clarin-pl/kpwr-ner --> 0 models
# dataset: clarin-pl/multiwiki_90k --> 0 models
# dataset: clarin-pl/nkjp-pos --> 0 models
# dataset: clarin-pl/polemo2-official --> 0 models
# dataset: classla/FRENK-hate-en --> 0 models
# dataset: classla/FRENK-hate-hr --> 0 models
# dataset: classla/FRENK-hate-sl --> 0 models
# dataset: classla/copa_hr --> 0 models
# dataset: classla/hr500k --> 0 models
# dataset: classla/janes_tag --> 0 models
# dataset: classla/reldi_hr --> 0 models
# dataset: classla/reldi_sr --> 0 models
# dataset: classla/setimes_sr --> 0 models
# dataset: classla/ssj500k --> 0 models
# dataset: clem/autonlp-data-french_word_detection --> 0 models
# dataset: clips/mfaq --> 0 models
# dataset: clips/mqa --> 0 models
# dataset: cnrcastroli/aaaa --> 0 models
# dataset: coala/kkk --> 0 models
# dataset: codeceejay/ng_accent --> 0 models
# dataset: cointegrated/ru-paraphrase-NMT-Leipzig --> 0 models
# dataset: collectivat/tv3_parla --> 0 models
# dataset: comodoro/pscr --> 0 models
# dataset: comodoro/vystadial2016 --> 0 models
# dataset: congpt/dstc23_asr --> 0 models
# dataset: corypaik/coda --> 0 models
# dataset: corypaik/prost --> 0 models
# dataset: coyotte508/dataset --> 0 models
# dataset: craffel/openai_lambada --> 0 models
# dataset: crich/cider --> 0 models
# dataset: cristinakuo/latino40 --> 0 models
# dataset: crystina-z/inlang-mrtydi-corpus --> 0 models
# dataset: crystina-z/inlang-mrtydi --> 0 models
# dataset: crystina-z/mbert-mrtydi-corpus --> 0 models
# dataset: crystina-z/mbert-mrtydi --> 0 models
# dataset: csarron/image-captions --> 0 models
# dataset: csebuetnlp/xlsum --> 0 models
# dataset: csebuetnlp/xnli_bn --> 0 models
# dataset: csikasote/bemba_train_dev_sets_processed --> 0 models
# dataset: csikasote/bemba_trainset_processed --> 0 models
# dataset: csikasote/bembaspeech_plus_jw_processed --> 0 models
# dataset: csikasote/sv_corpora_parliament_processed --> 0 models
# dataset: cstrathe435/Task2Dial --> 0 models
# dataset: ctgowrie/chessgames --> 0 models
# dataset: ctl/ConceptualCaptions --> 0 models
# dataset: ctu-aic/ctkfacts_nli --> 0 models
# dataset: cyko/books --> 0 models
# dataset: cylee/github-issues --> 0 models
# dataset: dalle-mini/YFCC100M_OpenAI_subset --> 0 models
# dataset: dalle-mini/wit --> 0 models
# dataset: damlab/HIV_FLT --> 0 models
# dataset: damlab/HIV_PI --> 0 models
# dataset: damlab/HIV_V3_bodysite --> 0 models
# dataset: damlab/HIV_V3_coreceptor --> 0 models
# dataset: dansbecker/hackernews_hiring_posts --> 0 models
# dataset: darentang/generated --> 0 models
# dataset: darentang/sroie --> 0 models
# dataset: darkraipro/recipe-instructions --> 0 models
# dataset: dasago78/dasago78dataset --> 0 models
# dataset: dataset/wikipedia_bn --> 0 models
# dataset: davanstrien/19th-century-ads --> 0 models
# dataset: davanstrien/ads-im-test --> 0 models
# dataset: davanstrien/ads-test --> 0 models
# dataset: davanstrien/crowdsourced-keywords --> 0 models
# dataset: davanstrien/embellishments --> 0 models
# dataset: davanstrien/hipe2020 --> 0 models
# dataset: davanstrien/hmd_newspapers --> 0 models
# dataset: davanstrien/kitten --> 0 models
# dataset: davanstrien/manuscript_iiif_test --> 0 models
# dataset: davanstrien/snorkel_genre --> 0 models
# dataset: davanstrien/test_iiif --> 0 models
# dataset: davanstrien/test_push_to_hub_image --> 0 models
# dataset: davanstrien/testpush --> 0 models
# dataset: david-wb/zeshel --> 0 models
# dataset: davidwisdom/reddit-randomness --> 0 models
# dataset: dcfidalgo/test --> 0 models
# dataset: debajyotidatta/biosses --> 0 models
# dataset: debatelab/aaac --> 0 models
# dataset: deepset/germandpr --> 0 models
# dataset: deepset/germanquad --> 0 models
# dataset: dennlinger/klexikon --> 0 models
# dataset: deokgu/fooddetection --> 0 models
# dataset: dev/untitled_imgs --> 0 models
# dataset: dfgvhxfgv/fghghj --> 0 models
# dataset: dfki-nlp/few-nerd --> 0 models
# dataset: dfki-nlp/mobie --> 0 models
# dataset: dgao/librispeech_nc_test --> 0 models
# dataset: dgknrsln/Yorumsepeti --> 0 models
# dataset: diiogo/annotations --> 0 models
# dataset: diiogo/brwac-clean --> 0 models
# dataset: diiogo/harem-seletivo --> 0 models
# dataset: diiogo/harem-total --> 0 models
# dataset: diiogo/ocr-galdino --> 0 models
# dataset: diiogo/oscar --> 0 models
# dataset: dispenst/jhghdghfd --> 0 models
# dataset: dispix/test-dataset --> 0 models
# dataset: diwank/silicone-merged --> 0 models
# dataset: dk-crazydiv/huggingface-modelhub --> 0 models
# dataset: dlb/plue --> 0 models
# dataset: dog/friends-of-mine --> 0 models
# dataset: dog/punks --> 0 models
# dataset: dongpil/test --> 0 models
# dataset: dragosnicolae555/RoITD --> 0 models
# dataset: dram-conflict/horror-scripts --> 0 models
# dataset: dvilasuero/ag_news_error_analysis --> 0 models
# dataset: dvilasuero/ag_news_training_set_losses --> 0 models
# dataset: dvilasuero/test-dataset --> 0 models
# dataset: dweb/squad_with_cola_scores --> 0 models
# dataset: dynabench/dynasent --> 0 models
# dataset: dynabench/qa --> 0 models
# dataset: eason929/test --> 0 models
# dataset: ebrigham/asr_files --> 0 models
# dataset: ebrigham/autonlp-data-csat_classification_fr --> 0 models
# dataset: ebrigham/labels --> 0 models
# dataset: ebrigham/multi_sentiment --> 0 models
# dataset: echarlaix/gqa-lxmert --> 0 models
# dataset: echarlaix/gqa --> 0 models
# dataset: echarlaix/vqa-lxmert --> 0 models
# dataset: echarlaix/vqa --> 0 models
# dataset: edbeeching/decision_transformer_atari_dqn_replay --> 0 models
# dataset: edbeeching/decision_transformer_gym_replay --> 0 models
# dataset: edbeeching/github-issues --> 0 models
# dataset: edfews/szdfcszdf --> 0 models
# dataset: edge2992/github-issues --> 0 models
# dataset: edge2992/rri-short --> 0 models
# dataset: edge2992/rri_short --> 0 models
# dataset: edsas/fgrdtgrdtdr --> 0 models
# dataset: edsas/grttyi --> 0 models
# dataset: ehcalabres/ravdess_speech --> 0 models
# dataset: ejjaffe/onion_headlines_2_sources --> 0 models
# dataset: eliza-dukim/load_klue_re --> 0 models
# dataset: elonmuskceo/persistent-space-dataset --> 0 models
# dataset: elonmuskceo/wordle --> 0 models
# dataset: elricwan/bert_data --> 0 models
# dataset: emre/Open_SLR108_Turkish_10_hours --> 0 models
# dataset: emrecan/stsb-mt-turkish --> 0 models
# dataset: enelpol/czywiesz --> 0 models
# dataset: erikacardenas300/Zillow_Economics_Dataset --> 0 models
# dataset: ervis/aaa --> 0 models
# dataset: ervis/qqq --> 0 models
# dataset: erwanlc/cocktails_recipe --> 0 models
# dataset: erwanlc/cocktails_recipe_no_brand --> 0 models
# dataset: eugenesiow/BSD100 --> 0 models
# dataset: eugenesiow/Div2k --> 0 models
# dataset: eugenesiow/PIRM --> 0 models
# dataset: eugenesiow/Set14 --> 0 models
# dataset: eugenesiow/Set5 --> 0 models
# dataset: eugenesiow/Urban100 --> 0 models
# dataset: evageon/IADD --> 0 models
# dataset: ewdrtfwe/54refyghrtf --> 0 models
# dataset: facebook/multilingual_librispeech --> 0 models
# dataset: fatvvs/autonlp-data-entity_model_conll2003 --> 0 models
# dataset: fededeleon/CriteriosClasificacion --> 0 models
# dataset: fengzhang/fzTestDatasets --> 0 models
# dataset: fhamborg/news_sentiment_newsmtsc --> 0 models
# dataset: fighterhitx/test --> 0 models
# dataset: fihtrotuld/asu --> 0 models
# dataset: flax-community/code_clippy_data --> 0 models
# dataset: flax-community/conceptual-12m-mbart-50-multilingual --> 0 models
# dataset: flax-community/conceptual-12m-multilingual-marian-128 --> 0 models
# dataset: flax-community/conceptual-12m-multilingual-marian-es --> 0 models
# dataset: flax-community/conceptual-12m-multilingual-marian --> 0 models
# dataset: flax-community/conceptual-captions-12 --> 0 models
# dataset: flax-community/dummy-oscar-als-32 --> 0 models
# dataset: flax-community/german-common-voice-processed --> 0 models
# dataset: flax-community/german_common_crawl --> 0 models
# dataset: flax-community/multilingual-vqa --> 0 models
# dataset: flax-community/norwegian-clean-dummy --> 0 models
# dataset: flax-community/swahili-safi --> 0 models
# dataset: flax-sentence-embeddings/Gender_Bias_Evaluation_Set --> 0 models
# dataset: flax-sentence-embeddings/paws-jsonl --> 0 models
# dataset: flax-sentence-embeddings/stackexchange_math_jsonl --> 0 models
# dataset: flax-sentence-embeddings/stackexchange_title_best_voted_answer_jsonl --> 0 models
# dataset: flax-sentence-embeddings/stackexchange_title_body_jsonl --> 0 models
# dataset: flax-sentence-embeddings/stackexchange_titlebody_best_and_down_voted_answer_jsonl --> 0 models
# dataset: flax-sentence-embeddings/stackexchange_titlebody_best_voted_answer_jsonl --> 0 models
# dataset: flax-sentence-embeddings/stackexchange_xml --> 0 models
# dataset: flexthink/librig2p-nostress-space --> 0 models
# dataset: flexthink/librig2p-nostress --> 0 models
# dataset: flexthink/ljspeech --> 0 models
# dataset: flexudy/OMQD --> 0 models
# dataset: florianbussmann/FUNSD-vu2020revising --> 0 models
# dataset: florianbussmann/train_tickets-yu2020pick --> 0 models
# dataset: flxclxc/encoded_drug_reviews --> 0 models
# dataset: formermagic/github_python_1m --> 0 models
# dataset: formu/CVT --> 0 models
# dataset: fractalego/QA_to_statements --> 0 models
# dataset: frahman/github-issues --> 0 models
# dataset: frtna/all_about_that_base --> 0 models
# dataset: frtna/cukumicin --> 0 models
# dataset: frtna/deneme --> 0 models
# dataset: frtna/es_it_Results-base-OPUS_Tatoeba --> 0 models
# dataset: frtna/gezelimgorelim --> 0 models
# dataset: frtna/jwt300_mt --> 0 models
# dataset: frtna/opensubtitles_mt --> 0 models
# dataset: frtna/sabahaKKarsi --> 0 models
# dataset: frtna/ted_mt --> 0 models
# dataset: frtna/test --> 0 models
# dataset: frtna/test2 --> 0 models
# dataset: fulai/DuReader --> 0 models
# dataset: fuliucansheng/coco --> 0 models
# dataset: fuliucansheng/minicoco --> 0 models
# dataset: fuliucansheng/mininlp --> 0 models
# dataset: fuliucansheng/pascal_voc --> 0 models
# dataset: fuyun1107/clip-for-vlp --> 0 models
# dataset: fvillena/cantemist --> 0 models
# dataset: fvillena/spanish_diagnostics --> 0 models
# dataset: gabella/demo_data_raw --> 0 models
# dataset: gagan3012/fake-news --> 0 models
# dataset: gagan3012/grover-data --> 0 models
# dataset: gagan3012/vizwiz --> 0 models
# dataset: gar1t/test --> 0 models
# dataset: gayanin/pubmed-gastro-maskfilling --> 0 models
# dataset: gayanin/pubmed-gastro-paraphrasing --> 0 models
# dataset: gayanin/pubmed-gastro-summarisation --> 0 models
# dataset: gcaillaut/citeseer --> 0 models
# dataset: gcaillaut/cora --> 0 models
# dataset: gcaillaut/frwiki_good_pages_el --> 0 models
# dataset: gcaillaut/pubmed --> 0 models
# dataset: geekydevu/mlquestions --> 0 models
# dataset: geninhu/vi_opus100_processed --> 0 models
# dataset: geninhu/vi_vivos-cv-tts-fpt_processed --> 0 models
# dataset: german-nlp-group/german_common_crawl --> 0 models
# dataset: gfigueroa/wikitext_processed --> 0 models
# dataset: gfissore/arxiv-abstracts-2021 --> 0 models
# dataset: ghadeermobasher/BC5CDR-Chemical-Disease --> 0 models
# dataset: ghadeermobasher/CRAFT-Chem --> 0 models
# dataset: ghomasHudson/ao3_style_change --> 0 models
# dataset: ghomasHudson/character_id --> 0 models
# dataset: ghomasHudson/hotpotExtended --> 0 models
# dataset: ghomasHudson/long_contra_pro --> 0 models
# dataset: ghomasHudson/muld --> 0 models
# dataset: ghomasHudson/vlsp --> 0 models
# dataset: gigant/african_accented_french --> 0 models
# dataset: gigant/m-ailabs_speech_dataset_fr --> 0 models
# dataset: gigant/ro_corpora_parliament_processed --> 0 models
# dataset: gigant/romanian_speech_synthesis_0_8_1 --> 0 models
# dataset: gmnlp/tico19 --> 0 models
# dataset: gorkemgoknar/tr_ted_talk_translated --> 0 models
# dataset: gpt3mix/rt20 --> 0 models
# dataset: gpt3mix/sst2 --> 0 models
# dataset: gsarti/change_it --> 0 models
# dataset: gsarti/clean_mc4_it --> 0 models
# dataset: gsarti/flores_101 --> 0 models
# dataset: gsarti/itacola --> 0 models
# dataset: gsarti/wmt_vat --> 0 models
# dataset: guoqiang/cuge --> 0 models
# dataset: gusu/mymodel1 --> 0 models
# dataset: habu24/fdz --> 0 models
# dataset: happifyhealth/twitter_pnn --> 0 models
# dataset: hartzeer/kdfjdshfje --> 0 models
# dataset: henrychess/gutenberg-fulltext-dirty-locc --> 0 models
# dataset: herbievore/test --> 0 models
# dataset: hf-internal-testing/cats_vs_dogs_sample --> 0 models
# dataset: hf-internal-testing/fixtures_ade20k --> 0 models
# dataset: hf-internal-testing/fixtures_docvqa --> 0 models
# dataset: hf-internal-testing/fixtures_image_utils --> 0 models
# dataset: hf-internal-testing/fixtures_nlvr2 --> 0 models
# dataset: hf-internal-testing/fixtures_ocr --> 0 models
# dataset: hf-internal-testing/fixtures_sintel --> 0 models
# dataset: hf-internal-testing/librispeech_asr_demo --> 0 models
# dataset: hf-internal-testing/librispeech_asr_dummy --> 0 models
# dataset: hf-internal-testing/test-dataset --> 0 models
# dataset: hf-internal-testing/transformers-metadata --> 0 models
# dataset: hf-test/sv_corpora_parliament_processed --> 0 models
# dataset: hfface/poopi --> 0 models
# dataset: holodata/sensai --> 0 models
# dataset: holylovenia/recam --> 0 models
# dataset: hong/autonlp-data-zoo_test --> 0 models
# dataset: honghungle/dataset --> 0 models
# dataset: howardmiddleton382/esuyertusutr --> 0 models
# dataset: howardmiddleton382/wgweagwege --> 0 models
# dataset: huggingFaceUser02/air21_grp13_inference_results --> 0 models
# dataset: huggingFaceUser02/air21_grp13_tokenized_results --> 0 models
# dataset: huggingartists/100-gecs --> 0 models
# dataset: huggingartists/21-savage --> 0 models
# dataset: huggingartists/25-17 --> 0 models
# dataset: huggingartists/50-cent --> 0 models
# dataset: huggingartists/5nizza --> 0 models
# dataset: huggingartists/5opka --> 0 models
# dataset: huggingartists/6ix9ine --> 0 models
# dataset: huggingartists/aaron-watson --> 0 models
# dataset: huggingartists/abba --> 0 models
# dataset: huggingartists/adele --> 0 models
# dataset: huggingartists/agata-christie --> 0 models
# dataset: huggingartists/aikko --> 0 models
# dataset: huggingartists/aimer --> 0 models
# dataset: huggingartists/ajr --> 0 models
# dataset: huggingartists/alan-walker --> 0 models
# dataset: huggingartists/andre-3000 --> 0 models
# dataset: huggingartists/arash --> 0 models
# dataset: huggingartists/architects --> 0 models
# dataset: huggingartists/arctic-monkeys --> 0 models
# dataset: huggingartists/ariana-grande --> 0 models
# dataset: huggingartists/ariya --> 0 models
# dataset: huggingartists/armin-van-buuren --> 0 models
# dataset: huggingartists/as-i-lay-dying --> 0 models
# dataset: huggingartists/asdfgfa --> 0 models
# dataset: huggingartists/asper-x --> 0 models
# dataset: huggingartists/baklan --> 0 models
# dataset: huggingartists/big-baby-tape --> 0 models
# dataset: huggingartists/big-russian-boss --> 0 models
# dataset: huggingartists/bill-wurtz --> 0 models
# dataset: huggingartists/billie-eilish --> 0 models
# dataset: huggingartists/billy-talent --> 0 models
# dataset: huggingartists/bladee --> 0 models
# dataset: huggingartists/bob-dylan --> 0 models
# dataset: huggingartists/bones --> 0 models
# dataset: huggingartists/booker --> 0 models
# dataset: huggingartists/boris-grebenshikov --> 0 models
# dataset: huggingartists/braii --> 0 models
# dataset: huggingartists/bring-me-the-horizon --> 0 models
# dataset: huggingartists/bruce-springsteen --> 0 models
# dataset: huggingartists/bryan-adams --> 0 models
# dataset: huggingartists/burzum --> 0 models
# dataset: huggingartists/bushido-zho --> 0 models
# dataset: huggingartists/cardi-b --> 0 models
# dataset: huggingartists/chester-bennington --> 0 models
# dataset: huggingartists/chief-keef --> 0 models
# dataset: huggingartists/cocomelon --> 0 models
# dataset: huggingartists/coin --> 0 models
# dataset: huggingartists/coldplay --> 0 models
# dataset: huggingartists/dababy --> 0 models
# dataset: huggingartists/david-bowie --> 0 models
# dataset: huggingartists/ddt --> 0 models
# dataset: huggingartists/death-grips --> 0 models
# dataset: huggingartists/deep-purple --> 0 models
# dataset: huggingartists/denderty --> 0 models
# dataset: huggingartists/dermot-kennedy --> 0 models
# dataset: huggingartists/dj-artem-artemov --> 0 models
# dataset: huggingartists/doja-cat --> 0 models
# dataset: huggingartists/drake --> 0 models
# dataset: huggingartists/dua-lipa --> 0 models
# dataset: huggingartists/duran-duran --> 0 models
# dataset: huggingartists/dzhizus --> 0 models
# dataset: huggingartists/ed-sheeran --> 0 models
# dataset: huggingartists/egor-kreed --> 0 models
# dataset: huggingartists/egor-letov --> 0 models
# dataset: huggingartists/elton-john --> 0 models
# dataset: huggingartists/eminem --> 0 models
# dataset: huggingartists/enigma --> 0 models
# dataset: huggingartists/enya --> 0 models
# dataset: huggingartists/epic-rap-battles-of-history --> 0 models
# dataset: huggingartists/face --> 0 models
# dataset: huggingartists/fascinoma --> 0 models
# dataset: huggingartists/fear-factory --> 0 models
# dataset: huggingartists/florence-the-machine --> 0 models
# dataset: huggingartists/freddie-dredd --> 0 models
# dataset: huggingartists/freelancer --> 0 models
# dataset: huggingartists/galenskaparna-and-after-shave --> 0 models
# dataset: huggingartists/ghost --> 0 models
# dataset: huggingartists/ghostemane --> 0 models
# dataset: huggingartists/ghostmane --> 0 models
# dataset: huggingartists/gizmo --> 0 models
# dataset: huggingartists/gorillaz --> 0 models
# dataset: huggingartists/green-day --> 0 models
# dataset: huggingartists/grigory-leps --> 0 models
# dataset: huggingartists/grimes --> 0 models
# dataset: huggingartists/gspd --> 0 models
# dataset: huggingartists/gunna --> 0 models
# dataset: huggingartists/hillsong-worship --> 0 models
# dataset: huggingartists/hyuna --> 0 models
# dataset: huggingartists/i-dont-know-how-but-they-found-me --> 0 models
# dataset: huggingartists/idktime --> 0 models
# dataset: huggingartists/imagine-dragons --> 0 models
# dataset: huggingartists/jah-khalib --> 0 models
# dataset: huggingartists/jim-morrison --> 0 models
# dataset: huggingartists/john-k-samson --> 0 models
# dataset: huggingartists/john-lennon --> 0 models
# dataset: huggingartists/joji --> 0 models
# dataset: huggingartists/joni-mitchell --> 0 models
# dataset: huggingartists/justin-bieber --> 0 models
# dataset: huggingartists/kanye-west --> 0 models
# dataset: huggingartists/kasta --> 0 models
# dataset: huggingartists/katy-perry --> 0 models
# dataset: huggingartists/kehlani --> 0 models
# dataset: huggingartists/kendrick-lamar --> 0 models
# dataset: huggingartists/kesha --> 0 models
# dataset: huggingartists/king-krule --> 0 models
# dataset: huggingartists/kipelov --> 0 models
# dataset: huggingartists/kishlak --> 0 models
# dataset: huggingartists/kizaru --> 0 models
# dataset: huggingartists/kojey-radical --> 0 models
# dataset: huggingartists/krechet --> 0 models
# dataset: huggingartists/krept-and-konan-bugzy-malone-sl-morisson-abra-cadabra-rv-and-snap-capone --> 0 models
# dataset: huggingartists/kurt-cobain --> 0 models
# dataset: huggingartists/lady-gaga --> 0 models
# dataset: huggingartists/lazy-jay --> 0 models
# dataset: huggingartists/led-zeppelin --> 0 models
# dataset: huggingartists/lil-baby --> 0 models
# dataset: huggingartists/lil-nas-x --> 0 models
# dataset: huggingartists/lil-peep --> 0 models
# dataset: huggingartists/lil-skies --> 0 models
# dataset: huggingartists/lil-uzi-vert --> 0 models
# dataset: huggingartists/linkin-park --> 0 models
# dataset: huggingartists/little-big --> 0 models
# dataset: huggingartists/lizer --> 0 models
# dataset: huggingartists/logic --> 0 models
# dataset: huggingartists/lorde --> 0 models
# dataset: huggingartists/loud-luxury --> 0 models
# dataset: huggingartists/loverance --> 0 models
# dataset: huggingartists/lovv66 --> 0 models
# dataset: huggingartists/lumen --> 0 models
# dataset: huggingartists/lyapis-trubetskoy --> 0 models
# dataset: huggingartists/macan --> 0 models
# dataset: huggingartists/machine-gun-kelly --> 0 models
# dataset: huggingartists/madonna --> 0 models
# dataset: huggingartists/marillion --> 0 models
# dataset: huggingartists/maroon-5 --> 0 models
# dataset: huggingartists/mashina-vremeni --> 0 models
# dataset: huggingartists/mating-ritual --> 0 models
# dataset: huggingartists/max-korzh --> 0 models
# dataset: huggingartists/mayot --> 0 models
# dataset: huggingartists/mc-ride --> 0 models
# dataset: huggingartists/melanie-martinez --> 0 models
# dataset: huggingartists/metallica --> 0 models
# dataset: huggingartists/mf-doom --> 0 models
# dataset: huggingartists/michael-jackson --> 0 models
# dataset: huggingartists/mikhail-gorshenev --> 0 models
# dataset: huggingartists/mikhail-krug --> 0 models
# dataset: huggingartists/miyagi --> 0 models
# dataset: huggingartists/mnogoznaal --> 0 models
# dataset: huggingartists/morgenshtern --> 0 models
# dataset: huggingartists/mumiy-troll --> 0 models
# dataset: huggingartists/muse --> 0 models
# dataset: huggingartists/nautilus-pompilius --> 0 models
# dataset: huggingartists/nervy --> 0 models
# dataset: huggingartists/nicki-minaj --> 0 models
# dataset: huggingartists/nirvana --> 0 models
# dataset: huggingartists/noize-mc --> 0 models
# dataset: huggingartists/oasis --> 0 models
# dataset: huggingartists/obladaet --> 0 models
# dataset: huggingartists/og-buda --> 0 models
# dataset: huggingartists/ot-rus --> 0 models
# dataset: huggingartists/our-last-night --> 0 models
# dataset: huggingartists/oxxxymiron --> 0 models
# dataset: huggingartists/peter-paul-and-mary --> 0 models
# dataset: huggingartists/pharaoh --> 0 models
# dataset: huggingartists/phish --> 0 models
# dataset: huggingartists/pink-floyd --> 0 models
# dataset: huggingartists/placebo --> 0 models
# dataset: huggingartists/platina --> 0 models
# dataset: huggingartists/pop-smoke --> 0 models
# dataset: huggingartists/post-malone --> 0 models
# dataset: huggingartists/pyrokinesis --> 0 models
# dataset: huggingartists/queen --> 0 models
# dataset: huggingartists/radiohead --> 0 models
# dataset: huggingartists/rage-against-the-machine --> 0 models
# dataset: huggingartists/ramil --> 0 models
# dataset: huggingartists/rammstein --> 0 models
# dataset: huggingartists/red-hot-chili-peppers --> 0 models
# dataset: huggingartists/rex-orange-county --> 0 models
# dataset: huggingartists/rihanna --> 0 models
# dataset: huggingartists/rocket --> 0 models
# dataset: huggingartists/sam-kim --> 0 models
# dataset: huggingartists/scriptonite --> 0 models
# dataset: huggingartists/sektor-gaza --> 0 models
# dataset: huggingartists/selena-gomez --> 0 models
# dataset: huggingartists/sergei-letov --> 0 models
# dataset: huggingartists/shadowraze --> 0 models
# dataset: huggingartists/sia --> 0 models
# dataset: huggingartists/sid-sriram --> 0 models
# dataset: huggingartists/skillet --> 0 models
# dataset: huggingartists/slava-kpss --> 0 models
# dataset: huggingartists/slava-marlow --> 0 models
# dataset: huggingartists/snoop-dogg --> 0 models
# dataset: huggingartists/sqwore --> 0 models
# dataset: huggingartists/sugar-ray --> 0 models
# dataset: huggingartists/suicideoscope --> 0 models
# dataset: huggingartists/sum-41 --> 0 models
# dataset: huggingartists/sundara-karma --> 0 models
# dataset: huggingartists/system-of-a-down --> 0 models
# dataset: huggingartists/t-fest --> 0 models
# dataset: huggingartists/tanzy-minus --> 0 models
# dataset: huggingartists/taylor-swift --> 0 models
# dataset: huggingartists/tedeschi-trucks-band --> 0 models
# dataset: huggingartists/the-69-eyes --> 0 models
# dataset: huggingartists/the-avalanches --> 0 models
# dataset: huggingartists/the-beatles --> 0 models
# dataset: huggingartists/the-gazette --> 0 models
# dataset: huggingartists/the-grateful-dead --> 0 models
# dataset: huggingartists/the-king-and-the-jester --> 0 models
# dataset: huggingartists/the-notorious-big --> 0 models
# dataset: huggingartists/the-sugarcubes --> 0 models
# dataset: huggingartists/the-the-pigs --> 0 models
# dataset: huggingartists/the-velvet-underground --> 0 models
# dataset: huggingartists/the-weeknd --> 0 models
# dataset: huggingartists/tiamat --> 0 models
# dataset: huggingartists/till-lindemann --> 0 models
# dataset: huggingartists/tom-waits --> 0 models
# dataset: huggingartists/tony-raut-and-garry-topor --> 0 models
# dataset: huggingartists/tool --> 0 models
# dataset: huggingartists/totpoc --> 0 models
# dataset: huggingartists/travis-scott --> 0 models
# dataset: huggingartists/twenty-one-pilots --> 0 models
# dataset: huggingartists/tyler-the-creator --> 0 models
# dataset: huggingartists/upsahl --> 0 models
# dataset: huggingartists/v-x-v-prince --> 0 models
# dataset: huggingartists/van-morrison --> 0 models
# dataset: huggingartists/veggietales --> 0 models
# dataset: huggingartists/viktor-tsoi --> 0 models
# dataset: huggingartists/vladimir-vysotsky --> 0 models
# dataset: huggingartists/xxxtentacion --> 0 models
# dataset: huggingartists/young-thug --> 0 models
# dataset: huggingartists/yung-lean --> 0 models
# dataset: huggingartists/yung-plague --> 0 models
# dataset: huggingartists/zemfira --> 0 models
# dataset: huggingface/DataMeasurementsFiles --> 0 models
# dataset: huggingface/cats-image --> 0 models
# dataset: huggingface/documentation-images --> 0 models
# dataset: huggingface/label-files --> 0 models
# dataset: huggingface/task-page-images --> 0 models
# dataset: huggingface/transformers-metadata --> 0 models
# dataset: huggingface-course/codeparrot-ds-train --> 0 models
# dataset: huggingface-course/codeparrot-ds-valid --> 0 models
# dataset: husnu/tquad-v1v2 --> 0 models
# dataset: husnu/tquad2 --> 0 models
# dataset: huyongquan/d2 --> 0 models
# dataset: hyeonduck/whiteboard_abuse_dataset --> 0 models
# dataset: hyeonduck/your_dataset_name --> 0 models
# dataset: ia-bentebib/conv_ai_2_fr --> 0 models
# dataset: ia-bentebib/conv_ai_3_fr --> 0 models
# dataset: ia-bentebib/daily_dialog_fr --> 0 models
# dataset: ia-bentebib/diafrag --> 0 models
# dataset: ia-bentebib/dialog_re_fr --> 0 models
# dataset: ia-bentebib/doc2dial_fr --> 0 models
# dataset: ia-bentebib/empathetic_dialogues_fr --> 0 models
# dataset: iamshsdf/sssssssssss --> 0 models
# dataset: iarfmoose/qa_evaluator --> 0 models
# dataset: iarfmoose/question_generator --> 0 models
# dataset: image-search-2/unsplash_lite_image_dataset --> 0 models
# dataset: imthanhlv/binhvq_dedup --> 0 models
# dataset: imthanhlv/binhvq_news21_raw --> 0 models
# dataset: imvladikon/knesset_meetings_corpus --> 0 models
# dataset: indonesian-nlp/id_personachat --> 0 models
# dataset: iohadrubin/mtop --> 0 models
# dataset: iohadrubin/smcalflow --> 0 models
# dataset: ixxi/my_v1 --> 0 models
# dataset: jacobbieker/open-crab-sample --> 0 models
# dataset: jaimin/wav2vec2-large-xlsr-gujarati-demo --> 0 models
# dataset: jakeazcona/short-text-labeled-emotion-classification --> 0 models
# dataset: jakeazcona/short-text-multi-labeled-emotion-classification --> 0 models
# dataset: jakemarcus/MATH --> 0 models
# dataset: jamescalam/climate-fever-similarity --> 0 models
# dataset: jamol1741/test_dataset --> 0 models
# dataset: jcmc/ga-IE_opus_dgt_train --> 0 models
# dataset: jcmc/ga_mc4_processed --> 0 models
# dataset: jdepoix/junit_test_completion --> 0 models
# dataset: jeffboudier/testing3 --> 0 models
# dataset: jegorkitskerkin/dutch-snli --> 0 models
# dataset: jel/covid --> 0 models
# dataset: jeree/fr_corpora_parliament_processed --> 0 models
# dataset: jfarray/TFM --> 0 models
# dataset: jgammack/MTL-abstracts --> 0 models
# dataset: jgammack/SAE-door-abstracts --> 0 models
# dataset: jgammack/THESES-abstracts --> 0 models
# dataset: jglaser/binding_affinity --> 0 models
# dataset: jhonparra18/spanish_billion_words_clean --> 0 models
# dataset: jhqwqq/2 --> 0 models
# dataset: jianhong/dateset1 --> 0 models
# dataset: jianhong/dateset2 --> 0 models
# dataset: jimregan/clarinpl_sejmsenat --> 0 models
# dataset: jimregan/clarinpl_studio --> 0 models
# dataset: jimregan/foinse --> 0 models
# dataset: jimregan/lasid --> 0 models
# dataset: jinmang2/KorQuADv1 --> 0 models
# dataset: jinmang2/common-sense-mrc --> 0 models
# dataset: jinmang2/load_klue_re --> 0 models
# dataset: jinmang2/medical-mask --> 0 models
# dataset: jinmang2/pred --> 0 models
# dataset: jiyoojeong/targetizer --> 0 models
# dataset: jlh/coco --> 0 models
# dataset: jmamou/augmented-glue-sst2 --> 0 models
# dataset: joelito/ler --> 0 models
# dataset: joelito/sem_eval_2010_task_8 --> 0 models
# dataset: johnpaulbin/autonlp-data-asag-v2 --> 0 models
# dataset: jonfd/ICC --> 0 models
# dataset: jozierski/ecomwebtexts-pl --> 0 models
# dataset: jpcorb20/multidogo --> 0 models
# dataset: jsfactory/mental_health_reddit_posts --> 0 models
# dataset: ju-bezdek/conll2003-SK-NER --> 0 models
# dataset: julien-c/dummy-dataset-from-colab --> 0 models
# dataset: julien-c/persistent-space-dataset --> 0 models
# dataset: julien-c/reactiongif --> 0 models
# dataset: juliensimon/autonlp-data-song-lyrics-demo --> 0 models
# dataset: juliensimon/autonlp-data-song-lyrics --> 0 models
# dataset: juniorrios/roi_leish_test --> 0 models
# dataset: juny116/few_glue --> 0 models
# dataset: justinqbui/covid_fact_checked_google_api --> 0 models
# dataset: justinqbui/covid_fact_checked_polifact --> 0 models
# dataset: k-halid/ar --> 0 models
# dataset: k0t1k/test --> 0 models
# dataset: kaka10/fgfgfgfg --> 0 models
# dataset: karinev/lanuitdudroit --> 0 models
# dataset: kartikay/review-summarizer --> 0 models
# dataset: katanaml/cord --> 0 models
# dataset: katoensp/VR-OP --> 0 models
# dataset: kaushikacharya/github-issues --> 0 models
# dataset: kenlevine/CUAD --> 0 models
# dataset: keshan/clean-si-mc4 --> 0 models
# dataset: keshan/large-sinhala-asr-dataset --> 0 models
# dataset: keshan/multispeaker-tts-sinhala --> 0 models
# dataset: keshan/wit-dataset --> 0 models
# dataset: kevinassobo/sales_2015_dataset --> 0 models
# dataset: kevinjesse/ManyTypes4TypeScript --> 0 models
# dataset: kevinlu1248/personificationgen --> 0 models
# dataset: khalidsaifullaah/detecThreats --> 0 models
# dataset: khanbaba/online_love --> 0 models
# dataset: khursani8/sani --> 0 models
# dataset: kiamehr74/CoarseWSD-20 --> 0 models
# dataset: kingabzpro/Rick-bot-flags --> 0 models
# dataset: kingabzpro/ar_corpora_parliament_processed --> 0 models
# dataset: kingabzpro/ga_corpora_parliament_processed --> 0 models
# dataset: kingabzpro/pan_corpora_parliament_processed --> 0 models
# dataset: kingabzpro/savtadepth-flags --> 0 models
# dataset: kingabzpro/tt_corpora_parliament_processed --> 0 models
# dataset: kiyoung2/aistage-mrc --> 0 models
# dataset: kiyoung2/temp --> 0 models
# dataset: kleinay/qa_srl --> 0 models
# dataset: kmfoda/booksum --> 0 models
# dataset: kmfoda/name_finder_v1 --> 0 models
# dataset: kmyoo/klue-tc-dev --> 0 models
# dataset: knilakshan20/wikigold --> 0 models
# dataset: kowndinya23/bert-dataset --> 0 models
# dataset: krandiash/beethoven --> 0 models
# dataset: krandiash/sc09 --> 0 models
# dataset: krandiash/youtubemix --> 0 models
# dataset: kresnik/librispeech_asr_test --> 0 models
# dataset: kresnik/zeroth_korean --> 0 models
# dataset: kroshan/BioASQ --> 0 models
# dataset: kroshan/qa_evaluator --> 0 models
# dataset: kudo-research/mustc-en-es-text-only --> 0 models
# dataset: kyryl0s/ukbbc --> 0 models
# dataset: laion/filtered-wit --> 0 models
# dataset: laion/laion400m --> 0 models
# dataset: laion/laion_100m_vqgan_f8 --> 0 models
# dataset: lara-martin/Scifi_TV_Shows --> 0 models
# dataset: larcane/ko-WIT --> 0 models
# dataset: laugustyniak/abusive-clauses-pl --> 0 models
# dataset: lavis-nlp/german_legal_sentences --> 0 models
# dataset: layboard/layboard.in --> 0 models
# dataset: lc-col/sv_corpora_parliament_processed --> 0 models
# dataset: leiping/jj --> 0 models
# dataset: leiping/teeee --> 0 models
# dataset: leoapolonio/AMI_Meeting_Corpus --> 0 models
# dataset: lewtun/asr-preds-test --> 0 models
# dataset: lewtun/asr_dummy --> 0 models
# dataset: lewtun/benchmark-test --> 0 models
# dataset: lewtun/binary_classification_dummy --> 0 models
# dataset: lewtun/bulk-superb-s3p-superb-49606 --> 0 models
# dataset: lewtun/drug-reviews --> 0 models
# dataset: lewtun/gem-multi-dataset-predictions --> 0 models
# dataset: lewtun/gem-sub-03 --> 0 models
# dataset: lewtun/gem-test-predictions --> 0 models
# dataset: lewtun/gem-test-references --> 0 models
# dataset: lewtun/github-issues-test --> 0 models
# dataset: lewtun/github-issues --> 0 models
# dataset: lewtun/mnist-preds --> 0 models
# dataset: lewtun/my-awesome-dataset --> 0 models
# dataset: lewtun/s3prl-sd-dummy --> 0 models
# dataset: lewtun/test --> 0 models
# dataset: lewtun/text_classification_dummy --> 0 models
# dataset: lgrobol/openminuscule --> 0 models
# dataset: lhoestq/conll2003 --> 0 models
# dataset: lhoestq/custom_squad --> 0 models
# dataset: lhoestq/demo1 --> 0 models
# dataset: lhoestq/squad --> 0 models
# dataset: lhoestq/test --> 0 models
# dataset: lhoestq/test2 --> 0 models
# dataset: lhoestq/test_commit_descriptions --> 0 models
# dataset: lhoestq/test_zip_txt --> 0 models
# dataset: lhoestq/tmp --> 0 models
# dataset: lhoestq/wikipedia_bn --> 0 models
# dataset: liam168/nlp_c4_sentiment --> 0 models
# dataset: lidia/202111 --> 0 models
# dataset: lijingxin/github-issues --> 0 models
# dataset: lijingxin/squad_zen --> 0 models
# dataset: lijingxin/squad_zh_1 --> 0 models
# dataset: limjiayi/hateful_memes_expanded --> 0 models
# dataset: lincoln/newsquadfr --> 0 models
# dataset: linhd-postdata/pulpo --> 0 models
# dataset: linhd-postdata/stanzas --> 0 models
# dataset: liweili/c4_200m --> 0 models
# dataset: lkarjun/Malayalam-Articles --> 0 models
# dataset: lkiouiou/o9ui7877687 --> 0 models
# dataset: lkndsjkndgskjngkjsndkj/jsjdjsdvkjvszlhdskb --> 0 models
# dataset: lohanna/testedjkcxkf --> 0 models
# dataset: lorsorlah/Dadedadedam --> 0 models
# dataset: loveguruji609/dfdfsdfsdfsdfsdfsd --> 0 models
# dataset: lpsc-fiuba/melisa --> 0 models
# dataset: lsb/ancient-latin-passages --> 0 models
# dataset: lsb/million-english-numbers --> 0 models
# dataset: lucien/sciencemission --> 0 models
# dataset: lucien/voacantonesed --> 0 models
# dataset: lucien/wsaderfffjjjhhh --> 0 models
# dataset: lucio/common_voice_eval --> 0 models
# dataset: lukasmasuch/my-test-repo-3 --> 0 models
# dataset: lukasmasuch/my-test-repo-4 --> 0 models
# dataset: lukasmasuch/test-2 --> 0 models
# dataset: lukasmasuch/test-3 --> 0 models
# dataset: lukasmasuch/test --> 0 models
# dataset: lukesjordan/worldbank-project-documents --> 0 models
# dataset: luofengge/mydata --> 0 models
# dataset: luofengge/testDataset --> 0 models
# dataset: luomingshuang/GRID_audio --> 0 models
# dataset: luomingshuang/GRID_text --> 0 models
# dataset: luomingshuang/grid_lip_160_80 --> 0 models
# dataset: luozhouyang/dureader --> 0 models
# dataset: luozhouyang/kgclue-knowledge --> 0 models
# dataset: luozhouyang/question-answering-datasets --> 0 models
# dataset: lvwerra/codeparrot-clean-train --> 0 models
# dataset: lvwerra/codeparrot-clean-valid --> 0 models
# dataset: lvwerra/codeparrot-clean --> 0 models
# dataset: lvwerra/codeparrot-valid-clean-minimal --> 0 models
# dataset: lvwerra/codeparrot-valid --> 0 models
# dataset: lvwerra/github-alphacode --> 0 models
# dataset: lvwerra/github-code --> 0 models
# dataset: lvwerra/important_dataset --> 0 models
# dataset: lvwerra/lm_ar_wikipedia --> 0 models
# dataset: lvwerra/lm_nigercongo-ak_wikipedia --> 0 models
# dataset: lvwerra/red-wine --> 0 models
# dataset: lvwerra/repo-images --> 0 models
# dataset: lvwerra/test --> 0 models
# dataset: lysandre/image-to-text --> 0 models
# dataset: lysandre/my-cool-dataset --> 0 models
# dataset: m-newhauser/dataset-isi-200 --> 0 models
# dataset: m3hrdadfi/recipe_nlg_lite --> 0 models
# dataset: mad/IndonesiaNewsDataset --> 0 models
# dataset: maindadwitiya/weather_dataset --> 0 models
# dataset: maji/npo_mission_statement_ucf --> 0 models
# dataset: majod/CleanNaturalQuestionsDataset --> 0 models
# dataset: makanan/umich --> 0 models
# dataset: makarios19/neurips-paper --> 0 models
# dataset: malay-huggingface/jelapang-padi --> 0 models
# dataset: malay-huggingface/pembalakan --> 0 models
# dataset: mammut/mammut-corpus-venezuela-test-set --> 0 models
# dataset: mammut/mammut-corpus-venezuela --> 0 models
# dataset: manandey/OSCAR_Entity_Toy --> 0 models
# dataset: manandey/entity_experiments --> 0 models
# dataset: manifoldix/sg_testset_fhnw --> 0 models
# dataset: manifoldix/swg_parliament_fhnw --> 0 models
# dataset: manishk31/Demo --> 0 models
# dataset: manu/fr_corpora_parliament_processed-lowercased --> 0 models
# dataset: manu/fr_corpora_parliament_processed --> 0 models
# dataset: marinone94/nst_no --> 0 models
# dataset: marinone94/nst_sv --> 0 models
# dataset: mariosasko/PetImages --> 0 models
# dataset: mariosasko/dummy_test --> 0 models
# dataset: markscrivo/OddsOn --> 0 models
# dataset: martiwey/codesearchnet-go --> 0 models
# dataset: martiwey/codesearchnet-java --> 0 models
# dataset: martiwey/codesearchnet-javascript --> 0 models
# dataset: martiwey/codesearchnet-php --> 0 models
# dataset: martiwey/codesearchnet-python --> 0 models
# dataset: martiwey/codesearchnet-ruby --> 0 models
# dataset: martodaniel/terere --> 0 models
# dataset: masked-neuron/amazon --> 0 models
# dataset: masked-neuron/ccd --> 0 models
# dataset: masked-neuron/qb --> 0 models
# dataset: mattchurgin/sv_corpora_parliament_processed --> 0 models
# dataset: matteopilotto/github-issues --> 0 models
# dataset: maximedb/mcqa_light --> 0 models
# dataset: maximedb/mfaq_light --> 0 models
# dataset: maximedb/paws-x-all --> 0 models
# dataset: maximedb/vaccinchat --> 0 models
# dataset: maximedb/vaccinchat_retrieval --> 0 models
# dataset: maximedb/wow --> 0 models
# dataset: maxmoynan/SemEval2017-Task4aEnglish --> 0 models
# dataset: mbateman/github-issues --> 0 models
# dataset: medzaf/test --> 0 models
# dataset: meghanabhange/chaii --> 0 models
# dataset: meghanabhange/hilm141021 --> 0 models
# dataset: meghanabhange/hitalm141021 --> 0 models
# dataset: meghanabhange/hitalmsandbox --> 0 models
# dataset: meghanabhange/talm141021 --> 0 models
# dataset: merty/nateraw-food101-copy --> 0 models
# dataset: merve/coco --> 0 models
# dataset: merve/folk-mythology-tales --> 0 models
# dataset: merve/poetry --> 0 models
# dataset: merve/qqp --> 0 models
# dataset: metaeval/blimp_classification --> 0 models
# dataset: metaeval/colors --> 0 models
# dataset: metaeval/crowdflower --> 0 models
# dataset: metaeval/ethics --> 0 models
# dataset: metaeval/linguisticprobing --> 0 models
# dataset: metaeval/recast --> 0 models
# dataset: metalearning/kaggale-nlp-tutorial --> 0 models
# dataset: metamong1/summarization_optimization --> 0 models
# dataset: metopedia/autonlp-data-Multiple-Source-Language-Consensus-Reconstruction-o --> 0 models
# dataset: michaelbenayoun/wikipedia-bert-128 --> 0 models
# dataset: microsoft/codexglue_method_generation --> 0 models
# dataset: midas/citeulike180 --> 0 models
# dataset: midas/cstr --> 0 models
# dataset: midas/duc2001 --> 0 models
# dataset: midas/inspec --> 0 models
# dataset: midas/inspec_ke_tagged --> 0 models
# dataset: midas/kdd --> 0 models
# dataset: midas/kp20k --> 0 models
# dataset: midas/kpcrowd --> 0 models
# dataset: midas/kptimes --> 0 models
# dataset: midas/krapivin --> 0 models
# dataset: midas/ldke3k_medium --> 0 models
# dataset: midas/ldke3k_small --> 0 models
# dataset: midas/ldkp10k --> 0 models
# dataset: midas/ldkp3k --> 0 models
# dataset: midas/ldkp3k_small --> 0 models
# dataset: midas/nus --> 0 models
# dataset: midas/oagkx --> 0 models
# dataset: midas/openkp --> 0 models
# dataset: midas/pubmed --> 0 models
# dataset: midas/semeval2010 --> 0 models
# dataset: midas/semeval2010_ke_tagged --> 0 models
# dataset: midas/semeval2017 --> 0 models
# dataset: midas/semeval2017_ke_tagged --> 0 models
# dataset: midas/test_ldkp --> 0 models
# dataset: midas/www --> 0 models
# dataset: mideind/icelandic-common-crawl-corpus-IC3 --> 0 models
# dataset: mideind/icelandic-error-corpus-IceEC --> 0 models
# dataset: mikeee/model-z --> 0 models
# dataset: mirari/sv_corpora_parliament_processed --> 0 models
# dataset: mishig/sample_images --> 0 models
# dataset: mksaad/Arabic_news --> 0 models
# dataset: ml6team/cnn_dailymail_nl --> 0 models
# dataset: ml6team/xsum_nl --> 0 models
# dataset: mldmm/glass_alloy_composition --> 0 models
# dataset: mmcquade11-test/reuters-for-summarization-two --> 0 models
# dataset: mmm-da/rutracker_anime_torrent_titles --> 0 models
# dataset: mnaylor/evaluating-student-writing --> 0 models
# dataset: mnemlaghi/widdd --> 0 models
# dataset: mohamed-illiyas/wav2vec2-base-lj-demo-colab --> 0 models
# dataset: morganchen1007/1215 --> 0 models
# dataset: morganchen1007/1216 --> 0 models
# dataset: morganchen1007/1216_00 --> 0 models
# dataset: morganchen1007/test_1213_00 --> 0 models
# dataset: moshew/my_raft --> 0 models
# dataset: mostol/wiktionary-ipa --> 0 models
# dataset: moumeneb1/French_arpa_lm --> 0 models
# dataset: moumeneb1/filtered --> 0 models
# dataset: moumeneb1/filtered_300 --> 0 models
# dataset: moumeneb1/fr_lm_dataset --> 0 models
# dataset: moumeneb1/large_vocabulary_dataset --> 0 models
# dataset: moumeneb1/osc_processed_lm --> 0 models
# dataset: moumeneb1/testing --> 0 models
# dataset: moxi43/github-issues --> 0 models
# dataset: mozilla-foundation/common_voice_1_0 --> 0 models
# dataset: mozilla-foundation/common_voice_2_0 --> 0 models
# dataset: mozilla-foundation/common_voice_3_0 --> 0 models
# dataset: mozilla-foundation/common_voice_4_0 --> 0 models
# dataset: mozilla-foundation/common_voice_5_0 --> 0 models
# dataset: mozilla-foundation/common_voice_5_1 --> 0 models
# dataset: mozilla-foundation/common_voice_6_0 --> 0 models
# dataset: mozilla-foundation/common_voice_6_1 --> 0 models
# dataset: mozilla-foundation/common_voice_7_0 --> 0 models
# dataset: mozilla-foundation/common_voice_8_0 --> 0 models
# dataset: mpierrau/sv_corpora_parliament_processed --> 0 models
# dataset: mr-robot/ec --> 0 models
# dataset: mrm8488/fake-news --> 0 models
# dataset: mrm8488/goemotions --> 0 models
# dataset: mrojas/abbreviation --> 0 models
# dataset: mrojas/body --> 0 models
# dataset: mrojas/disease --> 0 models
# dataset: mrojas/family --> 0 models
# dataset: mrojas/finding --> 0 models
# dataset: mrojas/medication --> 0 models
# dataset: mrojas/procedure --> 0 models
# dataset: mrp/Thai-Semantic-Textual-Similarity-Benchmark --> 0 models
# dataset: msarmi9/korean-english-multitarget-ted-talks-task --> 0 models
# dataset: msivanes/github-issues --> 0 models
# dataset: mswedrowski/multiwiki_90k --> 0 models
# dataset: mtfelix/datasetdemo --> 0 models
# dataset: mtlew/0001_Angry_test --> 0 models
# dataset: muhtasham/autonlp-data-Doctor_DE --> 0 models
# dataset: mulcyber/europarl-mono --> 0 models
# dataset: munggok/mc4-id --> 0 models
# dataset: mustafa12/db_ee --> 0 models
# dataset: mustafa12/edaaaas --> 0 models
# dataset: mustafa12/thors --> 0 models
# dataset: mvarma/medwiki --> 0 models
# dataset: nateraw/auto-cats-and-dogs --> 0 models
# dataset: nateraw/auto-exp-2 --> 0 models
# dataset: nateraw/beans --> 0 models
# dataset: nateraw/beans_old --> 0 models
# dataset: nateraw/blahblah --> 0 models
# dataset: nateraw/bulk-dummy --> 0 models
# dataset: nateraw/cats-and-dogs --> 0 models
# dataset: nateraw/cats_vs_dogs --> 0 models
# dataset: nateraw/dummy-csv-dataset --> 0 models
# dataset: nateraw/filings-10k --> 0 models
# dataset: nateraw/food101 --> 0 models
# dataset: nateraw/food101_old --> 0 models
# dataset: nateraw/huggingpics-data-2 --> 0 models
# dataset: nateraw/huggingpics-data --> 0 models
# dataset: nateraw/image-folder --> 0 models
# dataset: nateraw/imagefolder --> 0 models
# dataset: nateraw/imagenette --> 0 models
# dataset: nateraw/img-demo --> 0 models
# dataset: nateraw/rock_paper_scissors --> 0 models
# dataset: nateraw/sync_food101 --> 0 models
# dataset: nateraw/test --> 0 models
# dataset: nateraw/wit --> 0 models
# dataset: nathanlsl/news --> 0 models
# dataset: naver-clova-conversation/klue-tc-dev-tsv --> 0 models
# dataset: naver-clova-conversation/klue-tc-tsv --> 0 models
# dataset: naver-clova-conversation-ul/klue-tc-dev --> 0 models
# dataset: navjordj/nak_nb --> 0 models
# dataset: ncats/EpiSet4BinaryClassification --> 0 models
# dataset: ncats/EpiSet4NER-v1 --> 0 models
# dataset: ncats/GARD_EpiSet4TextClassification --> 0 models
# dataset: ncduy/github-issues --> 0 models
# dataset: ncduy/mt-en-vi --> 0 models
# dataset: ncoop57/athena_data --> 0 models
# dataset: ncoop57/csnc_human_judgement --> 0 models
# dataset: ncoop57/rico_captions --> 0 models
# dataset: neelalex/raft-predictions --> 0 models
# dataset: newsha/PQuAD --> 0 models
# dataset: nferruz/UR50_2021_04 --> 0 models
# dataset: nferruz/UR50_2021_04_text --> 0 models
# dataset: ngdiana/hu_severity --> 0 models
# dataset: ngdiana/uaspeech --> 0 models
# dataset: ngdiana/uaspeech_severity --> 0 models
# dataset: ngdiana/uaspeech_severity_high --> 0 models
# dataset: ngdiana/uaspeech_severity_low --> 0 models
# dataset: nickmuchi/fin_dataset --> 0 models
# dataset: nickmuchi/financial-classification --> 0 models
# dataset: nickmuchi/trade-the-event-finance --> 0 models
# dataset: nid989/FNC-1 --> 0 models
# dataset: nielsr/FUNSD_layoutlmv2 --> 0 models
# dataset: nielsr/XFUN --> 0 models
# dataset: nielsr/funsd --> 0 models
# dataset: nlpaueb/test --> 0 models
# dataset: nlpconnect/dpr-nq-reader-v2 --> 0 models
# dataset: nlpconnect/dpr-nq-reader --> 0 models
# dataset: nlpconnect/ms_marco_subset_v2.1 --> 0 models
# dataset: nlpufg/brwac-pt --> 0 models
# dataset: nlpufg/brwac --> 0 models
# dataset: nlpufg/oscar-pt --> 0 models
# dataset: nlpyeditepe/tr-qnli --> 0 models
# dataset: nlpyeditepe/tr_rte --> 0 models
# dataset: nntadotzip/iuQAchatbot --> 0 models
# dataset: notional/notional-python --> 0 models
# dataset: nouamanetazi/ar_common_voice_processed --> 0 models
# dataset: nouamanetazi/ar_opus100_processed --> 0 models
# dataset: nsi319/figures-dataset --> 0 models
# dataset: ntagg/data1 --> 0 models
# dataset: nthngdy/bananas --> 0 models
# dataset: nthngdy/ccnews_split --> 0 models
# dataset: nthngdy/openwebtext_split --> 0 models
# dataset: ntutexas/amazon --> 0 models
# dataset: nucklehead/ht-voice-dataset --> 0 models
# dataset: oelkrise/CRT --> 0 models
# dataset: openclimatefix/eumetsat_uk_hrv --> 0 models
# dataset: openclimatefix/gfs --> 0 models
# dataset: openclimatefix/goes-l2 --> 0 models
# dataset: openclimatefix/goes-mrms --> 0 models
# dataset: openclimatefix/goes --> 0 models
# dataset: openclimatefix/hrrr --> 0 models
# dataset: openclimatefix/mrms --> 0 models
# dataset: openclimatefix/nimrod-uk-1km --> 0 models
# dataset: osanseviero/codeparrot-train --> 0 models
# dataset: osanseviero/llama_test --> 0 models
# dataset: osanseviero/test --> 0 models
# dataset: oscar-corpus/OSCAR-2109 --> 0 models
# dataset: ought/raft-submission --> 0 models
# dataset: ought/raft --> 0 models
# dataset: outman/test --> 0 models
# dataset: papluca/language-identification --> 0 models
# dataset: pariajm/sharif_emotional_speech_dataset --> 0 models
# dataset: parivartanayurveda/Malesexproblemsayurvedictreatment --> 0 models
# dataset: pasinit/scotus --> 0 models
# dataset: pasinit/xlwic --> 0 models
# dataset: patrickvonplaten/ami_single_headset_segmented_and_chunked --> 0 models
# dataset: patrickvonplaten/common_voice_6_tr --> 0 models
# dataset: patrickvonplaten/common_voice_processed_turkish --> 0 models
# dataset: patrickvonplaten/helena_coworking --> 0 models
# dataset: patrickvonplaten/librispeech_asr_dummy --> 0 models
# dataset: patrickvonplaten/librispeech_local --> 0 models
# dataset: patrickvonplaten/librispeech_local_dummy --> 0 models
# dataset: patrickvonplaten/scientific_papers_dummy --> 0 models
# dataset: patrickvonplaten/sensitive_data_sv --> 0 models
# dataset: pdesoyres/test --> 0 models
# dataset: peixian/equity_evaluation_corpus --> 0 models
# dataset: peixian/rtGender --> 0 models
# dataset: pelican/test_100 --> 0 models
# dataset: persiannlp/parsinlu_entailment --> 0 models
# dataset: persiannlp/parsinlu_query_paraphrasing --> 0 models
# dataset: persiannlp/parsinlu_reading_comprehension --> 0 models
# dataset: persiannlp/parsinlu_sentiment --> 0 models
# dataset: persiannlp/parsinlu_translation_en_fa --> 0 models
# dataset: persiannlp/parsinlu_translation_fa_en --> 0 models
# dataset: peterbonnesoeur/autonlp-data-test_text_summarization --> 0 models
# dataset: peterhsu/github-issues --> 0 models
# dataset: philschmid/prompted-germanquad --> 0 models
# dataset: philschmid/test_german_squad --> 0 models
# dataset: phoelti/squad_dev --> 0 models
# dataset: phongdtd/VinDataVLSP --> 0 models
# dataset: phongdtd/youtube_casual_audio --> 0 models
# dataset: phonlab-tcd/cngv1 --> 0 models
# dataset: phonlab-tcd/corpuscrawler-ga --> 0 models
# dataset: piEsposito/br-quad-2.0 --> 0 models
# dataset: piEsposito/br_quad_20 --> 0 models
# dataset: piEsposito/squad_20_ptbr --> 0 models
# dataset: pierreant-p/jcvd-or-linkedin --> 0 models
# dataset: pierreguillou/lener_br_finetuning_language_model --> 0 models
# dataset: pierreguillou/test_datasetdict --> 0 models
# dataset: pierresi/cord --> 0 models
# dataset: pietrolesci/ag_news --> 0 models
# dataset: pmc/open_access --> 0 models
# dataset: polinaeterna/dummy_dataset --> 0 models
# dataset: polinaeterna/ml_spoken_words --> 0 models
# dataset: polinaeterna/test_opus --> 0 models
# dataset: poperson1205/mrtydi-v1.1-korean-fixed --> 0 models
# dataset: prajin/ne_corpora_parliament_processed --> 0 models
# dataset: princeton-nlp/datasets-for-simcse --> 0 models
# dataset: pritamdeka/cord-19-abstract --> 0 models
# dataset: pritamdeka/cord-19-fulltext --> 0 models
# dataset: priya3301/Graduation_admission --> 0 models
# dataset: priya3301/tes --> 0 models
# dataset: priya3301/test --> 0 models
# dataset: proffttega/ILLUMINATI --> 0 models
# dataset: proffttega/doc --> 0 models
# dataset: proffttega/join_illuminati_to_become_rich --> 0 models
# dataset: proffttega/persian_daily_news --> 0 models
# dataset: project2you/asr --> 0 models
# dataset: projecte-aina/ancora-ca-ner --> 0 models
# dataset: projecte-aina/casum --> 0 models
# dataset: projecte-aina/catalan_general_crawling --> 0 models
# dataset: projecte-aina/catalan_government_crawling --> 0 models
# dataset: projecte-aina/catalan_textual_corpus --> 0 models
# dataset: projecte-aina/parlament_parla --> 0 models
# dataset: projecte-aina/sts-ca --> 0 models
# dataset: projecte-aina/teca --> 0 models
# dataset: projecte-aina/tecla --> 0 models
# dataset: projecte-aina/vilaquad --> 0 models
# dataset: projecte-aina/vilasum --> 0 models
# dataset: projecte-aina/viquiquad --> 0 models
# dataset: projecte-aina/xquad-ca --> 0 models
# dataset: psrpsj/stop_words --> 0 models
# dataset: pstroe/cc100-latin --> 0 models
# dataset: pulmo/chest_xray --> 0 models
# dataset: qa4pc/QA4PC --> 0 models
# dataset: qanastek/ANTILLES --> 0 models
# dataset: qanastek/ELRC-Medical-V2 --> 0 models
# dataset: qfortier/instagram_ny --> 0 models
# dataset: quarter100/boolq_log --> 0 models
# dataset: quis/vnexpress-train --> 0 models
# dataset: qwant/squad_fr --> 0 models
# dataset: radhakri119/sv_corpora_parliament_processed --> 0 models
# dataset: ragarwal/args-me-pairs --> 0 models
# dataset: rahular/itihasa --> 0 models
# dataset: rajeshradhakrishnan/malayalam_2020_wiki --> 0 models
# dataset: rajeshradhakrishnan/malayalam_news --> 0 models
# dataset: rajeshradhakrishnan/malayalam_wiki --> 0 models
# dataset: ramitsurana/sanskrit --> 0 models
# dataset: ramybaly/conll2012 --> 0 models
# dataset: ramybaly/nerd --> 0 models
# dataset: ranim/Algerian-Arabic --> 0 models
# dataset: ranpox/xfund --> 0 models
# dataset: rays2pix/example --> 0 models
# dataset: rays2pix/example_dataset --> 0 models
# dataset: readerbench/ChatLinks --> 0 models
# dataset: rewardsignal/reddit_writing_prompts --> 0 models
# dataset: rgismondi/code-fill-dataset --> 0 models
# dataset: robz/test --> 0 models
# dataset: rocca/sims4-faces --> 0 models
# dataset: ronaldvanos/testdata --> 0 models
# dataset: rony/soccer-dialogues --> 0 models
# dataset: rookieguy12/dataset --> 0 models
# dataset: rosettarandd/rosetta_balcanica --> 0 models
# dataset: roskoN/dailydialog --> 0 models
# dataset: roskoN/dstc8-reddit-corpus --> 0 models
# dataset: rubenwol/multi_news_qasrl --> 0 models
# dataset: rubrix/cleanlab-label_errors --> 0 models
# dataset: rubrix/gutenberg_spacy-ner --> 0 models
# dataset: rubrix/gutenberg_spacy-ner_smaller --> 0 models
# dataset: rubrix/imdb_spacy-ner --> 0 models
# dataset: rubrix/news --> 0 models
# dataset: rubrix/sentiment-banking-2 --> 0 models
# dataset: rubrix/sentiment-banking --> 0 models
# dataset: rucyang/sales --> 0 models
# dataset: rwebe/rwebe --> 0 models
# dataset: s-myk/test --> 0 models
# dataset: s3h/arabic-gec --> 0 models
# dataset: s3h/arabic-grammar-corrections --> 0 models
# dataset: s3h/custom-qalb-classification --> 0 models
# dataset: s3h/customized-qalb-v2 --> 0 models
# dataset: s3h/customized-qalb --> 0 models
# dataset: s3h/gec-arabic --> 0 models
# dataset: s3h/gec-cleaned --> 0 models
# dataset: s3h/gec-token-classification --> 0 models
# dataset: s3h/poc-gec --> 0 models
# dataset: safik/github-issues-comments --> 0 models
# dataset: safik/github-issues --> 0 models
# dataset: sagnikrayc/mctest --> 0 models
# dataset: sagnikrayc/quasar --> 0 models
# dataset: sagteam/author_profiling --> 0 models
# dataset: sajadk/IranianCarLicencePlate --> 0 models
# dataset: salesken/Paraphrase_category_detection --> 0 models
# dataset: samarlune/Holy_Coran --> 0 models
# dataset: samgin/FooReview --> 0 models
# dataset: samgin/star_tagging --> 0 models
# dataset: samirt8/fr_corpora_parliament_processed --> 0 models
# dataset: samjgorman/sample --> 0 models
# dataset: sammy786/finnish_traindata --> 0 models
# dataset: sanyu/aw --> 0 models
# dataset: sanyu/er --> 0 models
# dataset: sanyu/hh --> 0 models
# dataset: sanyu/vb --> 0 models
# dataset: sc2qa/sc2q_commoncrawl --> 0 models
# dataset: sc2qa/sc2q_commoncrawl_large --> 0 models
# dataset: sc2qa/sc2qa_commoncrawl --> 0 models
# dataset: sdfufygvjh/fgghuviugviu --> 0 models
# dataset: sduong/genwiki --> 0 models
# dataset: sduong/wikigraphs --> 0 models
# dataset: seamew/ChnSentiCorp --> 0 models
# dataset: seamew/Hotel --> 0 models
# dataset: seamew/THUCNews --> 0 models
# dataset: seamew/THUCNewsText --> 0 models
# dataset: seamew/THUCNewsTitle --> 0 models
# dataset: seamew/Weibo --> 0 models
# dataset: seanbethard/autonlp-data-summarization_model --> 0 models
# dataset: sebastiaan/test-cefr --> 0 models
# dataset: sebastian-hofstaetter/tripclick-training --> 0 models
# dataset: segments-bert/image-upload-test --> 0 models
# dataset: segments-bert/logo_dataset --> 0 models
# dataset: segments-bert/pets --> 0 models
# dataset: sentence-transformers/embedding-training-data --> 0 models
# dataset: sentence-transformers/msmarco-hard-negatives --> 0 models
# dataset: sentence-transformers/parallel-sentences --> 0 models
# dataset: sentence-transformers/reddit-title-body --> 0 models
# dataset: seregadgl/test_set --> 0 models
# dataset: sevbqewre/vebdesbdty --> 0 models
# dataset: severo/autonlp-data-sentiment_detection-3c8bcd36 --> 0 models
# dataset: severo/dummy_gated --> 0 models
# dataset: severo/embellishments --> 0 models
# dataset: severo/wit --> 0 models
# dataset: seyia92coding/steam_games_2019.csv --> 0 models
# dataset: sh110495/klue-nli --> 0 models
# dataset: sh110495/korquad --> 0 models
# dataset: shahp7575/sia_pile_sample --> 0 models
# dataset: shahp7575/sia_tp_sample --> 0 models
# dataset: shahrukhx01/questions-vs-statements --> 0 models
# dataset: shaina/covid19 --> 0 models
# dataset: shanya/website_metadata_c4_toy --> 0 models
# dataset: sharejing/BiPaR --> 0 models
# dataset: sheryylli/utr_total_reads --> 0 models
# dataset: shibing624/python-source-code --> 0 models
# dataset: shivam/hindi_pib_processed --> 0 models
# dataset: shivam/marathi_pib_processed --> 0 models
# dataset: shivam/marathi_samanantar_processed --> 0 models
# dataset: shivam/test-translation-2 --> 0 models
# dataset: shivam/test-translation --> 0 models
# dataset: shivam/test --> 0 models
# dataset: shivkumarganesh/CoLA --> 0 models
# dataset: shivmoha/squad-unanswerable --> 0 models
# dataset: shivmoha/squad_adversarial_manual --> 0 models
# dataset: shpotes/ms_coco --> 0 models
# dataset: shpotes/tfcol --> 0 models
# dataset: sia-precision-education/pile_cpp --> 0 models
# dataset: sia-precision-education/pile_js --> 0 models
# dataset: sia-precision-education/pile_python --> 0 models
# dataset: sia-precision-education/sia_pile_sample --> 0 models
# dataset: sijpapi/batch13 --> 0 models
# dataset: sijpapi/funsd --> 0 models
# dataset: sijpapi/funsds --> 0 models
# dataset: silentzone/test --> 0 models
# dataset: sine/zzz --> 0 models
# dataset: sismetanin/rureviews --> 0 models
# dataset: smallv0221/my-test --> 0 models
# dataset: softcatala/Europarl-catalan --> 0 models
# dataset: softcatala/Softcatala-Web-Texts-Dataset --> 0 models
# dataset: softcatala/Tilde-MODEL-Catalan --> 0 models
# dataset: softcatala/ca_text_corpus --> 0 models
# dataset: softcatala/catalan-dictionary --> 0 models
# dataset: softcatala/open-source-english-catalan-corpus --> 0 models
# dataset: solomonk/reddit_mental_health_posts --> 0 models
# dataset: somaimanguyat/Genjer --> 0 models
# dataset: somaimanguyat/Koboy --> 0 models
# dataset: somaimanguyat/Movieonline2021 --> 0 models
# dataset: somaimanguyat/Salome --> 0 models
# dataset: somaimanguyat/movie21 --> 0 models
# dataset: somaimanguyat/xiomay --> 0 models
# dataset: spacemanidol/ms_marco_doc2query --> 0 models
# dataset: spacemanidol/msmarco_passage_ranking --> 0 models
# dataset: spasis/datasets-github-issues --> 0 models
# dataset: spasis/github-issues --> 0 models
# dataset: ssasaa/gghghgh --> 0 models
# dataset: sshleifer/pseudo_bart_xsum --> 0 models
# dataset: stas/c4-en-10k --> 0 models
# dataset: stas/openwebtext-10k --> 0 models
# dataset: stas/oscar-en-10k --> 0 models
# dataset: stas/wmt14-en-de-pre-processed --> 0 models
# dataset: stas/wmt16-en-ro-pre-processed --> 0 models
# dataset: stevhliu/demo --> 0 models
# dataset: stiel/skjdhjkasdhasjkd --> 0 models
# dataset: subiksha/OwnDataset --> 0 models
# dataset: superb/superb-data --> 0 models
# dataset: susumu2357/squad_v2_sv --> 0 models
# dataset: svakulenk0/qrecc --> 0 models
# dataset: svakulenk0/spoken_kgqa --> 0 models
# dataset: svalabs/all-nli-german-translation-wmt19 --> 0 models
# dataset: svalabs/ms-marco-german-translation-wmt19 --> 0 models
# dataset: svanhvit/iceErrorCorpus --> 0 models
# dataset: svanhvit/icelandic-ner-MIM-GOLD-NER --> 0 models
# dataset: tals/test --> 0 models
# dataset: tanay/embed --> 0 models
# dataset: tanfiona/causenet_wiki --> 0 models
# dataset: tarudesu/UIT-ViCTSD --> 0 models
# dataset: tasosk/airlines --> 0 models
# dataset: tau/fs --> 0 models
# dataset: tau/mrqa --> 0 models
# dataset: tau/scientific_papers --> 0 models
# dataset: tau/scrolls --> 0 models
# dataset: tesemnikov-av/toxic_dataset_classification --> 0 models
# dataset: tesemnikov-av/toxic_dataset_ner --> 0 models
# dataset: testOrganization01/test05 --> 0 models
# dataset: teven/all_wikipedia_passages --> 0 models
# dataset: teven/c4_15M --> 0 models
# dataset: teven/github_all_lang_filtered --> 0 models
# dataset: teven/matched_passages_wikidata --> 0 models
# dataset: teven/mpww --> 0 models
# dataset: teven/mpww_all_passages --> 0 models
# dataset: teven/prompted_examples --> 0 models
# dataset: teven/pseudo_crawl_en_seeds --> 0 models
# dataset: teven/stackexchange --> 0 models
# dataset: tharindu/MOLD --> 0 models
# dataset: tharindu/SOLID --> 0 models
# dataset: thiemowa/argumentationreviewcorpus --> 0 models
# dataset: thiemowa/empathyreviewcorpus --> 0 models
# dataset: thomwolf/codeparrot-train --> 0 models
# dataset: thomwolf/codeparrot-valid --> 0 models
# dataset: thomwolf/codeparrot --> 0 models
# dataset: thomwolf/github-dataset --> 0 models
# dataset: thomwolf/github-python --> 0 models
# dataset: thomwolf/very-good-dataset --> 0 models
# dataset: thomwolf/very-test-dataset-2 --> 0 models
# dataset: thomwolf/very-test-dataset --> 0 models
# dataset: tianxing1994/temp --> 0 models
# dataset: toddmorrill/github-issues --> 0 models
# dataset: toloka/CrowdSpeech --> 0 models
# dataset: toloka/VoxDIY-RusNews --> 0 models
# dataset: tommy19970714/common_voice --> 0 models
# dataset: toriving/kosimcse --> 0 models
# dataset: toriving/talktalk-sentiment-210713-multi-singleturn-custom-multiturn --> 0 models
# dataset: tranduyquang2205/vietnamese_dataset --> 0 models
# dataset: transformersbook/codeparrot-train --> 0 models
# dataset: transformersbook/codeparrot-valid --> 0 models
# dataset: transformersbook/codeparrot --> 0 models
# dataset: trnt/github-issues --> 0 models
# dataset: ttj/metadata_arxiv --> 0 models
# dataset: turingbench/TuringBench --> 0 models
# dataset: uasoyasser/rgfes --> 0 models
# dataset: ubamba98/ro_cv7_processed --> 0 models
# dataset: ucberkeley-dlab/measuring-hate-speech --> 0 models
# dataset: uit-nlp/vietnamese_students_feedback --> 0 models
# dataset: ujjawal1612/quora --> 0 models
# dataset: umangchaudhry/demo_data_raw --> 0 models
# dataset: unicamp-dl/mmarco --> 0 models
# dataset: unicamp-dl/mrobust --> 0 models
# dataset: usc-isi/WikiConvert --> 0 models
# dataset: uva-irlab/canard_quretec --> 0 models
# dataset: uva-irlab/trec-cast-2019-multi-turn --> 0 models
# dataset: uyeongjae/load_klue_re_agmented --> 0 models
# dataset: valurank/hate-multi --> 0 models
# dataset: valurank/offensive-multi --> 0 models
# dataset: vanadhi/finlitqa --> 0 models
# dataset: vannacute/AmazonReviewHelpfulness --> 0 models
# dataset: vannora/pdata --> 0 models
# dataset: vannynakamura/leish --> 0 models
# dataset: vasilis/et_corpora_parliament_processed --> 0 models
# dataset: vasudevgupta/amazon-ml-hack --> 0 models
# dataset: vasudevgupta/bigbird-tokenized-natural-questions --> 0 models
# dataset: vasudevgupta/data --> 0 models
# dataset: vasudevgupta/fairseq-ljspeech --> 0 models
# dataset: vasudevgupta/gsoc-librispeech --> 0 models
# dataset: vasudevgupta/natural-questions-validation --> 0 models
# dataset: vasudevgupta/prml_data_contest --> 0 models
# dataset: vasudevgupta/temperature-distribution-2d-plate --> 0 models
# dataset: vasudevgupta/temperature-distribution-3d-cylinder --> 0 models
# dataset: vblagoje/lfqa --> 0 models
# dataset: vblagoje/lfqa_support_docs --> 0 models
# dataset: vblagoje/wikipedia_snippets_streamed --> 0 models
# dataset: vctc92/sdsd --> 0 models
# dataset: vctc92/test --> 0 models
# dataset: vera-pro/ShadowLink --> 0 models
# dataset: versae/bibles --> 0 models
# dataset: versae/modernisa --> 0 models
# dataset: versae/norwegian-t5-dataset-debug --> 0 models
# dataset: versae/norwegian-t5-dataset-debug2 --> 0 models
# dataset: versae/norwegian-t5-dataset-debug3 --> 0 models
# dataset: vershasaxena91/datasets --> 0 models
# dataset: vershasaxena91/squad_multitask --> 0 models
# dataset: vesteinn/IC3 --> 0 models
# dataset: vesteinn/icelandic-ner-MIM-GOLD-NER --> 0 models
# dataset: vesteinn/icelandic-qa-NQiI --> 0 models
# dataset: vidhur2k/multilingual-hate-speech --> 0 models
# dataset: vishnun/huggingpics-data --> 0 models
# dataset: vivekverma239/question-generation --> 0 models
# dataset: vkhangpham/github-issues --> 0 models
# dataset: vs4vijay/VizDS --> 0 models
# dataset: vumichien/common_voice_large --> 0 models
# dataset: vumichien/common_voice_large_jsut_jsss_css10 --> 0 models
# dataset: vumichien/ja_opus100_processed --> 0 models
# dataset: w-nicole/childes_data --> 0 models
# dataset: w-nicole/childes_data_no_tags --> 0 models
# dataset: w-nicole/childes_data_no_tags_ --> 0 models
# dataset: w-nicole/childes_data_with_tags --> 0 models
# dataset: w-nicole/childes_data_with_tags_ --> 0 models
# dataset: w11wo/imdb-javanese --> 0 models
# dataset: wanagenst/maslow-six-choices --> 0 models
# dataset: wanagenst/maslow-stories --> 0 models
# dataset: wanagenst/plutchik-nine-choices --> 0 models
# dataset: wanagenst/plutchik-stories --> 0 models
# dataset: wanagenst/reiss-stories --> 0 models
# dataset: wanagenst/reiss-twenty-choices --> 0 models
# dataset: wardenga/lsoie --> 0 models
# dataset: |size_categories:unknown|source_datasets:extended|qa_srl|task_categories:text-retrieval|task_ids:text-retrieval-other-Open --> 0 models
# dataset: warwickai/financial_phrasebank_mirror --> 0 models
# dataset: webek18735/ddvoacantonesed --> 0 models
# dataset: webek18735/dhikhscook --> 0 models
# dataset: webimmunization/COVID-19-vaccine-attitude-tweets --> 0 models
# dataset: webis/args_me --> 0 models
# dataset: webis/conclugen --> 0 models
# dataset: webis/ms-marco-anchor-text --> 0 models
# dataset: weijieliu/senteval_cn --> 0 models
# dataset: wesamhaddad14/testdata --> 0 models
# dataset: wifis/ouivirtual --> 0 models
# dataset: wikilee/ADFA_Mapping --> 0 models
# dataset: wikimedia/wikipedia --> 0 models
# dataset: wikimedia/wikisource --> 0 models
# dataset: winvoker/turkish-sentiment-analysis-dataset --> 0 models
# dataset: wisdomify/story --> 0 models
# dataset: wmt/europarl --> 0 models
# dataset: wmt/news-commentary --> 0 models
# dataset: wmt/uncorpus --> 0 models
# dataset: wmt/wikititles --> 0 models
# dataset: wmt/wmt10 --> 0 models
# dataset: wmt/wmt13 --> 0 models
# dataset: wmt/wmt14 --> 0 models
# dataset: wmt/wmt15 --> 0 models
# dataset: wmt/wmt16 --> 0 models
# dataset: wmt/wmt17 --> 0 models
# dataset: wmt/wmt18 --> 0 models
# dataset: wmt/wmt19 --> 0 models
# dataset: wpicard/nostradamus-propheties --> 0 models
# dataset: wza/USTT --> 0 models
# dataset: wzkariampuzha/EpiClassifySet --> 0 models
# dataset: wzkariampuzha/EpiExtract4GARD --> 0 models
# dataset: wzywzy/telegram_summary --> 0 models
# dataset: x-tech/cantonese-mandarin-translations --> 0 models
# dataset: xiaj/ds_test --> 0 models
# dataset: xiaj/test0919 --> 0 models
# dataset: xiaobendanyn/demo --> 0 models
# dataset: xiaobendanyn/nyt10 --> 0 models
# dataset: xiaobendanyn/tacred --> 0 models
# dataset: xkang/github-issues --> 0 models
# dataset: xuyeliu/notebookCDG --> 0 models
# dataset: yannobla/Sunshine --> 0 models
# dataset: yazdipour/text-to-sparql-kdwd --> 0 models
# dataset: ydshieh/coco_dataset_script --> 0 models
# dataset: yharyarias/tirads_tiroides --> 0 models
# dataset: yhavinga/mc4_nl_cleaned --> 0 models
# dataset: yluisfern/PBU --> 0 models
# dataset: yo/devparty --> 0 models
# dataset: yonesuke/Ising2D --> 0 models
# dataset: yonesuke/Vicsek --> 0 models
# dataset: yonesuke/kuramoto --> 0 models
# dataset: ysharma/rickandmorty --> 0 models
# dataset: ytsaig/news-12factor --> 0 models
# dataset: yuanchuan/annotated_reference_strings --> 0 models
# dataset: yuchenlin/OntoRock --> 0 models
# dataset: yuvalkirstain/asset --> 0 models
# dataset: yuvalkirstain/contract_nli-debug --> 0 models
# dataset: yuvalkirstain/contract_nli_t5 --> 0 models
# dataset: yuvalkirstain/contract_nli_t5_lm --> 0 models
# dataset: yuvalkirstain/qasper_t5 --> 0 models
# dataset: yuvalkirstain/qasper_t5_lm --> 0 models
# dataset: yuvalkirstain/qmsum_t5 --> 0 models
# dataset: yuvalkirstain/qmsum_t5_lm --> 0 models
# dataset: yuvalkirstain/quality --> 0 models
# dataset: yuvalkirstain/quality_debug --> 0 models
# dataset: yuvalkirstain/quality_squad --> 0 models
# dataset: yuvalkirstain/quality_squad_debug --> 0 models
# dataset: yuvalkirstain/quality_t5 --> 0 models
# dataset: yuvalkirstain/quality_t5_lm --> 0 models
# dataset: yuvalkirstain/scrolls_t5 --> 0 models
# dataset: yuvalkirstain/squad_full_doc --> 0 models
# dataset: yuvalkirstain/squad_seq2seq --> 0 models
# dataset: yuvalkirstain/squad_t5 --> 0 models
# dataset: yuvalkirstain/summ_screen_fd_t5 --> 0 models
# dataset: yuvalkirstain/summ_screen_fd_t5_lm --> 0 models
# dataset: yxchar/ag-tlm --> 0 models
# dataset: yxchar/amazon-tlm --> 0 models
# dataset: yxchar/chemprot-tlm --> 0 models
# dataset: yxchar/citation_intent-tlm --> 0 models
# dataset: yxchar/hyp-tlm --> 0 models
# dataset: yxchar/imdb-tlm --> 0 models
# dataset: yxchar/rct-20k-tlm --> 0 models
# dataset: yxchar/sciie-tlm --> 0 models
# dataset: z-uo/female-LJSpeech-italian --> 0 models
# dataset: z-uo/male-LJSpeech-italian --> 0 models
# dataset: z-uo/squad-it --> 0 models
# dataset: zapsdcn/ag --> 0 models
# dataset: zapsdcn/amazon --> 0 models
# dataset: zapsdcn/chemprot --> 0 models
# dataset: zapsdcn/citation_intent --> 0 models
# dataset: zapsdcn/hyperpartisan_news --> 0 models
# dataset: zapsdcn/imdb --> 0 models
# dataset: zapsdcn/rct-20k --> 0 models
# dataset: zapsdcn/sciie --> 0 models
# dataset: zf-org/org_dataset --> 0 models
# dataset: zfaB4Hmm/test --> 0 models
# dataset: zhangruihan1/face-recognition-validation --> 0 models
# dataset: zhangruihan1/face-recognition --> 0 models
# dataset: zhangruihan1/fr-cfp_fp --> 0 models
# dataset: zhoujun/hitab --> 0 models
# dataset: zhufy/xquad_split --> 0 models
# dataset: zj88zj/PubMed_200k_RCT --> 0 models
# dataset: zj88zj/SCIERC --> 0 models
# dataset: zloelias/kinopoisk-reviews-short --> 0 models
# dataset: zloelias/kinopoisk-reviews --> 0 models
# dataset: zloelias/lenta-ru-short --> 0 models
# dataset: zloelias/lenta-ru --> 0 models
# dataset: zlucia/casehold --> 0 models
# dataset: zwang199/autonlp-data-traffic_nlp_binary --> 0 models
