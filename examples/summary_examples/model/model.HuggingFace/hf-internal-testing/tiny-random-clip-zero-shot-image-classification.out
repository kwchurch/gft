model: hf-internal-testing/tiny-random-clip-zero-shot-image-classification	model: hf-internal-testing/tiny-random-clip-zero-shot-image-classification	downloads: 2600	likes: 0	task: zero-shot-image-classification
model: hf-internal-testing/tiny-random-clip-zero-shot-image-classification	labels: LABEL_0, LABEL_1
CLIPModel(
  (text_model): CLIPTextTransformer(
    (embeddings): CLIPTextEmbeddings(
      (token_embedding): Embedding(99, 32)
      (position_embedding): Embedding(512, 32)
    )
    (encoder): CLIPEncoder(
      (layers): ModuleList(
        (0): CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=32, out_features=32, bias=True)
            (v_proj): Linear(in_features=32, out_features=32, bias=True)
            (q_proj): Linear(in_features=32, out_features=32, bias=True)
            (out_proj): Linear(in_features=32, out_features=32, bias=True)
          )
          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (fc1): Linear(in_features=32, out_features=37, bias=True)
            (fc2): Linear(in_features=37, out_features=32, bias=True)
          )
          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        )
        (1): CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=32, out_features=32, bias=True)
            (v_proj): Linear(in_features=32, out_features=32, bias=True)
            (q_proj): Linear(in_features=32, out_features=32, bias=True)
            (out_proj): Linear(in_features=32, out_features=32, bias=True)
          )
          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (fc1): Linear(in_features=32, out_features=37, bias=True)
            (fc2): Linear(in_features=37, out_features=32, bias=True)
          )
          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        )
        (2): CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=32, out_features=32, bias=True)
            (v_proj): Linear(in_features=32, out_features=32, bias=True)
            (q_proj): Linear(in_features=32, out_features=32, bias=True)
            (out_proj): Linear(in_features=32, out_features=32, bias=True)
          )
          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (fc1): Linear(in_features=32, out_features=37, bias=True)
            (fc2): Linear(in_features=37, out_features=32, bias=True)
          )
          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        )
        (3): CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=32, out_features=32, bias=True)
            (v_proj): Linear(in_features=32, out_features=32, bias=True)
            (q_proj): Linear(in_features=32, out_features=32, bias=True)
            (out_proj): Linear(in_features=32, out_features=32, bias=True)
          )
          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (fc1): Linear(in_features=32, out_features=37, bias=True)
            (fc2): Linear(in_features=37, out_features=32, bias=True)
          )
          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        )
        (4): CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=32, out_features=32, bias=True)
            (v_proj): Linear(in_features=32, out_features=32, bias=True)
            (q_proj): Linear(in_features=32, out_features=32, bias=True)
            (out_proj): Linear(in_features=32, out_features=32, bias=True)
          )
          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (fc1): Linear(in_features=32, out_features=37, bias=True)
            (fc2): Linear(in_features=37, out_features=32, bias=True)
          )
          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (final_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (vision_model): CLIPVisionTransformer(
    (embeddings): CLIPVisionEmbeddings(
      (patch_embedding): Conv2d(3, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)
      (position_embedding): Embedding(226, 32)
    )
    (pre_layrnorm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (encoder): CLIPEncoder(
      (layers): ModuleList(
        (0): CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=32, out_features=32, bias=True)
            (v_proj): Linear(in_features=32, out_features=32, bias=True)
            (q_proj): Linear(in_features=32, out_features=32, bias=True)
            (out_proj): Linear(in_features=32, out_features=32, bias=True)
          )
          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (fc1): Linear(in_features=32, out_features=37, bias=True)
            (fc2): Linear(in_features=37, out_features=32, bias=True)
          )
          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        )
        (1): CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=32, out_features=32, bias=True)
            (v_proj): Linear(in_features=32, out_features=32, bias=True)
            (q_proj): Linear(in_features=32, out_features=32, bias=True)
            (out_proj): Linear(in_features=32, out_features=32, bias=True)
          )
          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (fc1): Linear(in_features=32, out_features=37, bias=True)
            (fc2): Linear(in_features=37, out_features=32, bias=True)
          )
          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        )
        (2): CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=32, out_features=32, bias=True)
            (v_proj): Linear(in_features=32, out_features=32, bias=True)
            (q_proj): Linear(in_features=32, out_features=32, bias=True)
            (out_proj): Linear(in_features=32, out_features=32, bias=True)
          )
          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (fc1): Linear(in_features=32, out_features=37, bias=True)
            (fc2): Linear(in_features=37, out_features=32, bias=True)
          )
          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        )
        (3): CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=32, out_features=32, bias=True)
            (v_proj): Linear(in_features=32, out_features=32, bias=True)
            (q_proj): Linear(in_features=32, out_features=32, bias=True)
            (out_proj): Linear(in_features=32, out_features=32, bias=True)
          )
          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (fc1): Linear(in_features=32, out_features=37, bias=True)
            (fc2): Linear(in_features=37, out_features=32, bias=True)
          )
          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        )
        (4): CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=32, out_features=32, bias=True)
            (v_proj): Linear(in_features=32, out_features=32, bias=True)
            (q_proj): Linear(in_features=32, out_features=32, bias=True)
            (out_proj): Linear(in_features=32, out_features=32, bias=True)
          )
          (layer_norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (fc1): Linear(in_features=32, out_features=37, bias=True)
            (fc2): Linear(in_features=37, out_features=32, bias=True)
          )
          (layer_norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (post_layernorm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
  )
  (visual_projection): Linear(in_features=32, out_features=64, bias=False)
  (text_projection): Linear(in_features=32, out_features=64, bias=False)
)
