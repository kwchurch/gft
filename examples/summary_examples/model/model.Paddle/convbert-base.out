name: conv_bert_model_0	labels (NA): NA	ConvBertModel(
  (embeddings): ConvBertEmbeddings(
    (word_embeddings): Embedding(30522, 768, sparse=False)
    (position_embeddings): Embedding(512, 768, sparse=False)
    (token_type_embeddings): Embedding(2, 768, sparse=False)
    (layer_norm): LayerNorm(normalized_shape=[768], epsilon=1e-12)
    (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
  )
  (encoder): TransformerEncoder(
    (layers): LayerList(
      (0): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
      (1): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
      (2): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
      (3): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
      (4): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
      (5): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
      (6): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
      (7): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
      (8): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
      (9): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
      (10): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
      (11): TransformerEncoderLayerWithConv(
        (self_attn): MultiHeadAttentionWithConv(
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (q_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (k_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (v_proj): Linear(in_features=768, out_features=384, dtype=float32)
          (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          (key_conv_attn_layer): SeparableConv1D(
            (depthwise): Conv1D(768, 768, kernel_size=[9], padding=4, groups=768, data_format=NLC)
            (pointwise): Conv1D(768, 384, kernel_size=[1], data_format=NLC)
          )
          (conv_kernel_layer): Linear(in_features=384, out_features=54, dtype=float32)
          (conv_out_layer): Linear(in_features=768, out_features=384, dtype=float32)
        )
        (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
        (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
        (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-12)
        (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      )
    )
  )
)
