name: ctrl_model_0	labels (NA): NA	CTRLModel(
  (pos_encoding): SinusoidalPositionalEmbedding(50000, 1280, sparse=False)
  (w): Embedding(246534, 1280, sparse=False)
  (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
  (h): LayerList(
    (0): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (1): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (2): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (3): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (4): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (5): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (6): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (7): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (8): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (9): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (10): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (11): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (12): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (13): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (14): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (15): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (16): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (17): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (18): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (19): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (20): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (21): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (22): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (23): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (24): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (25): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (26): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (27): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (28): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (29): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (30): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (31): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (32): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (33): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (34): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (35): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (36): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (37): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (38): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (39): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (40): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (41): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (42): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (43): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (44): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (45): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (46): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (47): EncoderLayer(
      (multi_head_attention): MultiHeadAttention(
        (Wq): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wk): Linear(in_features=1280, out_features=1280, dtype=float32)
        (Wv): Linear(in_features=1280, out_features=1280, dtype=float32)
        (dense): Linear(in_features=1280, out_features=1280, dtype=float32)
      )
      (ffn): Sequential(
        (0): Linear(in_features=1280, out_features=8192, dtype=float32)
        (1): ReLU()
        (2): Linear(in_features=8192, out_features=1280, dtype=float32)
      )
      (layernorm1): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (layernorm2): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
      (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
      (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
  )
  (layernorm): LayerNorm(normalized_shape=[1280], epsilon=1e-06)
)
