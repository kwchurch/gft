name: layout_xlm_model_0	labels (NA): NA	LayoutXLMModel(
  (embeddings): LayoutXLMEmbeddings(
    (word_embeddings): Embedding(250002, 768, padding_idx=0, sparse=False)
    (position_embeddings): Embedding(514, 768, sparse=False)
    (x_position_embeddings): Embedding(1024, 128, sparse=False)
    (y_position_embeddings): Embedding(1024, 128, sparse=False)
    (h_position_embeddings): Embedding(1024, 128, sparse=False)
    (w_position_embeddings): Embedding(1024, 128, sparse=False)
    (token_type_embeddings): Embedding(1, 768, sparse=False)
    (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
    (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
  )
  (visual): VisualBackbone(
    (backbone): FPN(
      (fpn_lateral2): Conv2d(256, 256, kernel_size=[1, 1], data_format=NCHW)
      (fpn_output2): Conv2d(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (fpn_lateral3): Conv2d(512, 256, kernel_size=[1, 1], data_format=NCHW)
      (fpn_output3): Conv2d(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (fpn_lateral4): Conv2d(1024, 256, kernel_size=[1, 1], data_format=NCHW)
      (fpn_output4): Conv2d(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (fpn_lateral5): Conv2d(2048, 256, kernel_size=[1, 1], data_format=NCHW)
      (fpn_output5): Conv2d(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (top_block): LastLevelMaxPool()
      (bottom_up): ResNet(
        (stem): BasicStem(
          (conv1): Conv2d(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW
            (norm): FrozenBatchNorm()
          )
        )
        (res2): Sequential(
          (0): BottleneckBlock(
            (shortcut): Conv2d(64, 256, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv1): Conv2d(64, 256, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(256, 256, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(256, 256, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (1): BottleneckBlock(
            (conv1): Conv2d(256, 256, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(256, 256, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(256, 256, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (2): BottleneckBlock(
            (conv1): Conv2d(256, 256, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(256, 256, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(256, 256, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
        )
        (res3): Sequential(
          (0): BottleneckBlock(
            (shortcut): Conv2d(256, 512, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv1): Conv2d(256, 512, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(512, 512, kernel_size=[3, 3], stride=[2, 2], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(512, 512, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (1): BottleneckBlock(
            (conv1): Conv2d(512, 512, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(512, 512, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(512, 512, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (2): BottleneckBlock(
            (conv1): Conv2d(512, 512, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(512, 512, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(512, 512, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (3): BottleneckBlock(
            (conv1): Conv2d(512, 512, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(512, 512, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(512, 512, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
        )
        (res4): Sequential(
          (0): BottleneckBlock(
            (shortcut): Conv2d(512, 1024, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv1): Conv2d(512, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], stride=[2, 2], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (1): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (2): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (3): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (4): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (5): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (6): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (7): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (8): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (9): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (10): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (11): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (12): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (13): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (14): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (15): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (16): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (17): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (18): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (19): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (20): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (21): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (22): BottleneckBlock(
            (conv1): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(1024, 1024, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(1024, 1024, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
        )
        (res5): Sequential(
          (0): BottleneckBlock(
            (shortcut): Conv2d(1024, 2048, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv1): Conv2d(1024, 2048, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(2048, 2048, kernel_size=[3, 3], stride=[2, 2], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(2048, 2048, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (1): BottleneckBlock(
            (conv1): Conv2d(2048, 2048, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(2048, 2048, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(2048, 2048, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
          (2): BottleneckBlock(
            (conv1): Conv2d(2048, 2048, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv2): Conv2d(2048, 2048, kernel_size=[3, 3], padding=1, groups=32, data_format=NCHW
              (norm): FrozenBatchNorm()
            )
            (conv3): Conv2d(2048, 2048, kernel_size=[1, 1], data_format=NCHW
              (norm): FrozenBatchNorm()
            )
          )
        )
      )
    )
    (pool): AdaptiveAvgPool2D(output_size=[7, 7])
  )
  (visual_proj): Linear(in_features=256, out_features=768, dtype=float32)
  (visual_LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
  (visual_dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
  (encoder): LayoutXLMEncoder(
    (layer): LayerList(
      (0): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
      (1): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
      (2): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
      (3): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
      (4): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
      (5): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
      (6): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
      (7): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
      (8): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
      (9): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
      (10): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
      (11): LayoutXLMLayer(
        (attention): LayoutXLMAttention(
          (self): LayoutXLMSelfAttention(
            (query): Linear(in_features=768, out_features=768, dtype=float32)
            (key): Linear(in_features=768, out_features=768, dtype=float32)
            (value): Linear(in_features=768, out_features=768, dtype=float32)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
          (output): LayoutXLMSelfOutput(
            (dense): Linear(in_features=768, out_features=768, dtype=float32)
            (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
            (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          )
        )
        (intermediate): LayoutXLMIntermediate(
          (dense): Linear(in_features=768, out_features=3072, dtype=float32)
          (intermediate_act_fn): GELU(approximate=False)
        )
        (output): LayoutXLMOutput(
          (dense): Linear(in_features=3072, out_features=768, dtype=float32)
          (LayerNorm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
    )
  )
  (pooler): LayoutXLMPooler(
    (dense): Linear(in_features=768, out_features=768, dtype=float32)
    (activation): Tanh()
  )
)
